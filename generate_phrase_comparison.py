#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_phrase_comparison.py (v2.3 - ä¿®æ­£è·¯å¾‘çµæ§‹ç‰ˆæœ¬)

ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison.xlsx æª”æ¡ˆï¼ŒåŒ…å«æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©å°ç…§è¡¨
æ”¯æ´èªè¨€å€å¡Šåˆ†é›¢ï¼Œåœ¨åŒä¸€å€‹ Excel ä¸­çµ±ä¸€ç®¡ç†æ‰€æœ‰èªè¨€å’Œæ¥­æ…‹

ä¿®æ­£å…§å®¹ï¼š
1. é©é…æ–°çš„è·¯å¾‘çµæ§‹ï¼šJSON åœ¨èªè¨€æ ¹ç›®éŒ„ï¼ŒPO åœ¨ LC_MESSAGES å­ç›®éŒ„
2. ä½¿ç”¨æ–°çš„ config_loader æ–¹æ³•
"""

import json
import re
import itertools
import sys
import shutil
import datetime
from pathlib import Path
from collections import defaultdict
from config_loader import get_config

try:
    import polib
    from openpyxl import Workbook
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    from openpyxl.utils import get_column_letter
    from openpyxl.cell.cell import MergedCell
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install polib openpyxl")
    sys.exit(1)


def auto_adjust_column_widths(worksheet, max_width=50):
    """
    è‡ªå‹•èª¿æ•´åˆ—å¯¬ï¼Œé¿å… MergedCell éŒ¯èª¤
    
    Args:
        worksheet: openpyxl å·¥ä½œè¡¨å°è±¡
        max_width: æœ€å¤§åˆ—å¯¬
    """
    try:
        for col_idx in range(1, worksheet.max_column + 1):
            column_letter = get_column_letter(col_idx)
            max_length = 0
            
            # éæ­·è©²åˆ—çš„æ‰€æœ‰å–®å…ƒæ ¼
            for row_idx in range(1, worksheet.max_row + 1):
                cell = worksheet.cell(row=row_idx, column=col_idx)
                
                # è·³é MergedCell
                if isinstance(cell, MergedCell):
                    continue
                    
                if cell.value:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            
            # è¨­ç½®åˆ—å¯¬ï¼ˆæœ€å°12ï¼Œæœ€å¤§max_widthï¼‰
            adjusted_width = min(max(max_length + 4, 12), max_width)
            worksheet.column_dimensions[column_letter].width = adjusted_width
            
    except Exception as e:
        print(f"âš ï¸  åˆ—å¯¬èª¿æ•´ç™¼ç”ŸéŒ¯èª¤ï¼ˆä¸å½±éŸ¿åŠŸèƒ½ï¼‰: {e}")


def safe_adjust_column_widths_for_summary(worksheet):
    """
    ç‚ºç¸½è¦½å·¥ä½œè¡¨å®‰å…¨åœ°èª¿æ•´åˆ—å¯¬
    """
    try:
        for col_idx in range(1, worksheet.max_column + 1):
            column_letter = get_column_letter(col_idx)
            max_length = 0
            
            for row_idx in range(1, worksheet.max_row + 1):
                cell = worksheet.cell(row=row_idx, column=col_idx)
                
                if isinstance(cell, MergedCell):
                    continue
                    
                if cell.value:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            
            adjusted_width = min(max(max_length + 2, 10), 50)
            worksheet.column_dimensions[column_letter].width = adjusted_width
            
    except Exception as e:
        print(f"âš ï¸  ç¸½è¦½å·¥ä½œè¡¨åˆ—å¯¬èª¿æ•´ç™¼ç”ŸéŒ¯èª¤: {e}")


# åŸºç¤æ•æ„Ÿè©å­—å…¸ - å¾ JSON æª”æ¡ˆåˆ†æå’Œæ•™è‚²åŸ¹è¨“é ˜åŸŸç¶“é©—æ•´ç†
BASE_SENSITIVE_WORDS = {
    "å­¸å“¡ç›¸é—œ": [
        "å­¸ç”Ÿ", "å­¸å“¡", "åƒèˆ‡è€…", "å—è¨“è€…", "åŒå­¸", "ç­ç´š", "çµ„åˆ¥"
    ],
    "å¸«è³‡ç›¸é—œ": [
        "è€å¸«", "æ•™å¸«", "è¬›å¸«", "æ•™æˆ", "åŠ©æ•™", "æŒ‡å°å“¡", "è¼”å°å“¡"
    ],
    "æ™‚é–“ç›¸é—œ": [
        "å­¸æœŸ", "å­¸å¹´", "å¹´åº¦", "å­£åº¦", "æœˆä»½", "é€±æ¬¡", "ç¯€æ¬¡"
    ]
}


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison.xlsx æª”æ¡ˆ")
    
    # è¼‰å…¥é…ç½®
    config = get_config()
    config.print_config_summary()
    
    # æª¢æ¸¬å¯ç”¨èªè¨€
    available_languages = config.detect_available_languages()
    print(f"\nğŸŒ å°‡è™•ç† {len(available_languages)} å€‹èªè¨€ï¼š{', '.join(available_languages)}")
    
    # å‚™ä»½é…ç½®
    backup_config = config.get_backup_config()
    backup_dir = config.get_backup_dir()
    backup_dir.mkdir(exist_ok=True)
    
    timestamp_format = backup_config.get('timestamp_format', '%Y%m%d_%H%M%S')
    timestamp = datetime.datetime.now().strftime(timestamp_format)
    
    # ç²å–çµ±ä¸€ Excel æª”æ¡ˆè·¯å¾‘
    excel_path = config.get_comparison_excel_path()
    
    print(f"   ç›®æ¨™æª”æ¡ˆï¼š{excel_path}")
    
    # å‚™ä»½ç¾æœ‰æª”æ¡ˆ
    if excel_path.exists():
        backup_filename = f"{excel_path.stem}_{timestamp}{excel_path.suffix}"
        backup_path = backup_dir / backup_filename
        
        shutil.copy2(excel_path, backup_path)
        print(f"   âœ… å·²å‚™ä»½ç¾æœ‰æª”æ¡ˆï¼š{backup_filename}")
    
    # æ”¶é›†æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©
    all_language_keywords = {}
    
    for language in available_languages:
        print(f"\nğŸ“‹ åˆ†æèªè¨€ï¼š{language}")
        try:
            language_files = config.get_language_files(language)
            detected_keywords = detect_sensitive_words(language_files, config, language)
            
            if not detected_keywords:
                print(f"   âš ï¸  åœ¨ {language} ä¸­æœªæª¢æ¸¬åˆ°æ•æ„Ÿè©ï¼Œä½¿ç”¨åŸºç¤è©å½™")
                detected_keywords = BASE_SENSITIVE_WORDS.copy()
            
            all_language_keywords[language] = detected_keywords
            
            total_words = sum(len(words) for words in detected_keywords.values())
            print(f"   ğŸ“Š æª¢æ¸¬åˆ° {total_words} å€‹æ•æ„Ÿè©ï¼Œ{len(detected_keywords)} å€‹åˆ†é¡")
            for category, words in detected_keywords.items():
                print(f"      {category}: {len(words)} å€‹è©")
                
        except Exception as e:
            print(f"   âŒ è™•ç†èªè¨€ {language} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            print(f"   âš ï¸  å°‡ä½¿ç”¨åŸºç¤è©å½™ä½œç‚ºå¾Œå‚™æ–¹æ¡ˆ")
            all_language_keywords[language] = BASE_SENSITIVE_WORDS.copy()
    
    # ç”Ÿæˆçµ±ä¸€ Excel
    generate_unified_excel(config, all_language_keywords, excel_path)
    print(f"\nâœ… çµ±ä¸€å°ç…§è¡¨ç”Ÿæˆå®Œæˆï¼š{excel_path}")
    
    # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    total_languages = len(all_language_keywords)
    total_categories = len(set().union(*[keywords.keys() for keywords in all_language_keywords.values()]))
    total_words = sum(sum(len(words) for words in keywords.values()) for keywords in all_language_keywords.values())
    
    print(f"\nğŸ“Š çµ±è¨ˆå ±å‘Šï¼š")
    print(f"   èªè¨€æ•¸é‡ï¼š{total_languages}")
    print(f"   åˆ†é¡ç¸½æ•¸ï¼š{total_categories}")
    print(f"   æ•æ„Ÿè©ç¸½æ•¸ï¼š{total_words}")
    print(f"   å¹³å‡æ¯èªè¨€ï¼š{total_words // total_languages if total_languages else 0} å€‹æ•æ„Ÿè©")


def detect_sensitive_words(language_files: dict, config, language: str) -> dict:
    """
    å¾èªè¨€æª”æ¡ˆä¸­æª¢æ¸¬æ•æ„Ÿè© - ä¿®æ­£ç‰ˆæœ¬ï¼Œé©é…æ–°çš„è·¯å¾‘çµæ§‹
    
    Args:
        language_files: èªè¨€æª”æ¡ˆè·¯å¾‘å­—å…¸
        config: é…ç½®ç‰©ä»¶
        language: èªè¨€ä»£ç¢¼
    
    Returns:
        æª¢æ¸¬åˆ°çš„æ•æ„Ÿè©å­—å…¸ {åˆ†é¡: [è©å½™åˆ—è¡¨]}
    """
    
    # æ”¶é›†æ‰€æœ‰æ–‡æœ¬å…§å®¹
    all_texts = []
    
    # è®€å– PO æª”æ¡ˆ
    if 'po_file' in language_files:
        try:
            po_file_path = language_files['po_file']
            print(f"      ğŸ“– è®€å– PO æª”æ¡ˆï¼š{po_file_path}")
            po_file = polib.pofile(str(po_file_path))
            for entry in po_file:
                if entry.msgid:
                    all_texts.append(entry.msgid)
                if entry.msgstr:
                    all_texts.append(entry.msgstr)
            print(f"      âœ… PO æª”æ¡ˆï¼š{len(po_file)} å€‹æ¢ç›®")
        except Exception as e:
            print(f"      âš ï¸  è®€å– PO æª”æ¡ˆå¤±æ•—ï¼š{e}")
    
    # è®€å– JSON æª”æ¡ˆ
    if 'json_file' in language_files:
        try:
            json_file_path = language_files['json_file']
            print(f"      ğŸ“– è®€å– JSON æª”æ¡ˆï¼š{json_file_path}")
            with open(json_file_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            def extract_json_values(obj):
                """éè¿´æå– JSON ä¸­çš„æ‰€æœ‰å­—ç¬¦ä¸²å€¼"""
                if isinstance(obj, dict):
                    for value in obj.values():
                        yield from extract_json_values(value)
                elif isinstance(obj, list):
                    for item in obj:
                        yield from extract_json_values(item)
                elif isinstance(obj, str):
                    yield obj
            
            json_texts = list(extract_json_values(json_data))
            all_texts.extend(json_texts)
            print(f"      âœ… JSON æª”æ¡ˆï¼š{len(json_texts)} å€‹æ–‡æœ¬")
            
        except Exception as e:
            print(f"      âš ï¸  è®€å– JSON æª”æ¡ˆå¤±æ•—ï¼š{e}")
    
    if not all_texts:
        print(f"      âš ï¸  ç„¡æ³•å¾æª”æ¡ˆä¸­æå–æ–‡æœ¬å…§å®¹")
        return {}
    
    # æª¢æ¸¬æ•æ„Ÿè©
    print(f"      ğŸ” å¾ {len(all_texts)} å€‹æ–‡æœ¬æ¢ç›®ä¸­æª¢æ¸¬æ•æ„Ÿè©...")
    
    detected_words = defaultdict(set)
    detection_config = config.get_keyword_detection_config()
    case_sensitive = detection_config.get('case_sensitive', False)
    
    # åˆä½µæ‰€æœ‰æ–‡æœ¬
    combined_text = ' '.join(all_texts)
    if not case_sensitive:
        combined_text = combined_text.lower()
    
    # å°æ¯å€‹åŸºç¤åˆ†é¡çš„æ•æ„Ÿè©é€²è¡Œæª¢æ¸¬
    for category, base_words in BASE_SENSITIVE_WORDS.items():
        for word in base_words:
            search_word = word.lower() if not case_sensitive else word
            if search_word in combined_text:
                detected_words[category].add(word)
    
    # è½‰æ›ç‚ºæ™®é€šå­—å…¸ï¼Œä¸¦æŒ‰åŸå§‹é †åºæ’åˆ—
    result = {}
    for category, words in detected_words.items():
        # ä¿æŒèˆ‡åŸºç¤è©å…¸ç›¸åŒçš„é †åº
        ordered_words = []
        for base_word in BASE_SENSITIVE_WORDS[category]:
            if base_word in words:
                ordered_words.append(base_word)
        if ordered_words:
            result[category] = ordered_words
    
    return result


def generate_unified_excel(config, all_language_keywords: dict, output_path: Path):
    """
    ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison Excel æª”æ¡ˆ - èªè¨€ç¨ç«‹æ©«å‘åˆ†å€å¡Šç‰ˆæœ¬
    
    Args:
        config: é…ç½®ç‰©ä»¶
        all_language_keywords: æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©å­—å…¸
        output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    """
    
    # å‰µå»ºå·¥ä½œç°¿
    wb = Workbook()
    
    # è¨­ç½®ä¸»å·¥ä½œè¡¨
    ws = wb.active
    excel_config = config.get_excel_config()
    ws.title = excel_config.get('worksheets', {}).get('comparison', 'phrase_comparison')
    
    # æ¨£å¼è¨­å®š
    styling = excel_config.get('styling', {})
    language_header_color = styling.get('language_header_color', '4472C4')
    category_header_color = styling.get('category_header_color', '70AD47')
    business_header_color = styling.get('business_header_color', 'FFC000')
    data_row_color = styling.get('data_row_color', 'F2F2F2')
    
    # å­—é«”å’Œé‚Šæ¡†æ¨£å¼
    header_font = Font(bold=True, color="FFFFFF", size=12)
    language_font = Font(bold=True, color="FFFFFF", size=14)
    business_font = Font(bold=True, color="FFFFFF", size=10)
    data_font = Font(size=10)
    
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    thick_border = Border(
        left=Side(style='thick'),
        right=Side(style='thick'),
        top=Side(style='thick'),
        bottom=Side(style='thick')
    )
    
    # å»ºç«‹èªè¨€ç¨ç«‹çš„æ©«å‘çµæ§‹
    business_types = config.get_business_types()
    
    # æ©«å‘é…ç½®
    horizontal_config = excel_config.get('horizontal_layout', {})
    block_separator = horizontal_config.get('block_separator_columns', 1)
    
    # è¨ˆç®—æ¯å€‹èªè¨€å€å¡Šçš„å¯¬åº¦ï¼šæ•æ„Ÿè©é¡å‹ + æ•æ„Ÿè© + æ¥­æ…‹æ•¸é‡
    block_width = 2 + len(business_types)  # 2 æ˜¯åŸºç¤åˆ—æ•¸
    
    # å¯«å…¥ç¸½æ¨™é¡Œï¼ˆç¬¬1è¡Œï¼‰
    total_columns = len(all_language_keywords) * block_width + (len(all_language_keywords) - 1) * block_separator
    
    ws.merge_cells(f'A1:{get_column_letter(total_columns)}1')
    title_cell = ws['A1']
    title_cell.value = "å¤šèªè¨€æ•æ„Ÿè©å°ç…§è¡¨ï¼ˆèªè¨€ç¨ç«‹æ©«å‘åˆ†å€å¡Šç‰ˆï¼‰"
    title_cell.font = Font(bold=True, size=16, color="FFFFFF")
    title_cell.fill = PatternFill(start_color="2F4F4F", end_color="2F4F4F", fill_type="solid")
    title_cell.alignment = Alignment(horizontal="center", vertical="center")
    
    # ç‚ºæ¯å€‹èªè¨€å‰µå»ºç¨ç«‹å€å¡Š
    current_col = 1
    
    for lang_index, (language, keywords_dict) in enumerate(all_language_keywords.items()):
        block_start_col = current_col
        block_end_col = current_col + block_width - 1
        
        # èªè¨€æ¨™é¡Œï¼ˆç¬¬2è¡Œï¼Œè·¨è¶Šæ•´å€‹å€å¡Šï¼‰
        ws.merge_cells(f'{get_column_letter(block_start_col)}2:{get_column_letter(block_end_col)}2')
        lang_cell = ws.cell(row=2, column=block_start_col, value=f"{language}")
        lang_cell.font = language_font
        lang_cell.fill = PatternFill(start_color=language_header_color, end_color=language_header_color, fill_type="solid")
        lang_cell.alignment = Alignment(horizontal="center", vertical="center")
        lang_cell.border = thick_border
        
        # å€å¡Šå…§æ¨™é¡Œåˆ—ï¼ˆç¬¬3è¡Œï¼‰
        block_headers = ["æ•æ„Ÿè©é¡å‹", "æ•æ„Ÿè©"]
        for bt_code, bt_config in business_types.items():
            block_headers.append(bt_config['display_name'])
        
        for i, header in enumerate(block_headers):
            col = block_start_col + i
            cell = ws.cell(row=3, column=col, value=header)
            
            if i < 2:  # åŸºç¤åˆ—
                cell.font = header_font
                cell.fill = PatternFill(start_color=category_header_color, end_color=category_header_color, fill_type="solid")
            else:  # æ¥­æ…‹åˆ—
                cell.font = business_font
                cell.fill = PatternFill(start_color=business_header_color, end_color=business_header_color, fill_type="solid")
            
            cell.alignment = Alignment(horizontal="center", vertical="center")
            cell.border = thin_border
        
        # å¯«å…¥è©²èªè¨€çš„æ•æ„Ÿè©è³‡æ–™ï¼ˆå¾ç¬¬4è¡Œé–‹å§‹ï¼‰
        current_row = 4
        
        for category, keywords in keywords_dict.items():
            for keyword_index, keyword in enumerate(keywords):
                # æ•æ„Ÿè©é¡å‹å’Œæ•æ„Ÿè©
                ws.cell(row=current_row, column=block_start_col, value=category if keyword_index == 0 else "")
                ws.cell(row=current_row, column=block_start_col + 1, value=keyword)
                
                # ç‚ºæ¯å€‹æ¥­æ…‹æ·»åŠ ç©ºç™½æ–¹æ¡ˆæ¬„ä½
                for bt_index in range(len(business_types)):
                    col = block_start_col + 2 + bt_index
                    cell = ws.cell(row=current_row, column=col, value="")
                    cell.border = thin_border
                    # è¨­ç½®èƒŒæ™¯è‰²ï¼ˆå¥‡å¶è¡Œï¼‰
                    if current_row % 2 == 0:
                        cell.fill = PatternFill(start_color=data_row_color, end_color=data_row_color, fill_type="solid")
                
                # è¨­ç½®åŸºç¤åˆ—çš„æ¨£å¼
                for base_col_offset in [0, 1]:
                    col = block_start_col + base_col_offset
                    cell = ws.cell(row=current_row, column=col)
                    cell.font = data_font
                    cell.border = thin_border
                    cell.alignment = Alignment(horizontal="left", vertical="center")
                    if current_row % 2 == 0:
                        cell.fill = PatternFill(start_color=data_row_color, end_color=data_row_color, fill_type="solid")
                
                current_row += 1
        
        # ç§»å‹•åˆ°ä¸‹å€‹èªè¨€å€å¡Š
        current_col = block_end_col + 1 + block_separator
    
    # è‡ªå‹•èª¿æ•´æ¬„å¯¬
    auto_adjust_column_widths(ws, max_width=25)
    
    # å‰µå»ºç¸½è¦½å·¥ä½œè¡¨
    create_summary_worksheet(wb, config, all_language_keywords)
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æª”æ¡ˆ
    wb.save(output_path)
    
    total_languages = len(all_language_keywords)
    total_keywords = sum(sum(len(words) for words in keywords.values()) for keywords in all_language_keywords.values())
    print(f"      ğŸ“Š Excel çµ±è¨ˆï¼š{total_languages} å€‹èªè¨€ï¼Œæ¯å€‹èªè¨€ç¨ç«‹å€å¡Š")
    print(f"      ğŸ“ ç¸½æ•æ„Ÿè©æ•¸ï¼š{total_keywords} å€‹")
    print(f"      ğŸ“ è¡¨æ ¼å¯¬åº¦ï¼š{total_columns} åˆ—")


def create_summary_worksheet(wb, config, all_language_keywords: dict):
    """
    å‰µå»ºèªè¨€ç¸½è¦½å·¥ä½œè¡¨
    
    Args:
        wb: å·¥ä½œç°¿ç‰©ä»¶
        config: é…ç½®ç‰©ä»¶
        all_language_keywords: æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©å­—å…¸
    """
    
    # å‰µå»ºç¸½è¦½å·¥ä½œè¡¨
    excel_config = config.get_excel_config()
    summary_sheet_name = excel_config.get('worksheets', {}).get('summary', 'èªè¨€ç¸½è¦½')
    summary_ws = wb.create_sheet(title=summary_sheet_name)
    
    # æ¨£å¼è¨­å®š
    header_font = Font(bold=True, color="FFFFFF", size=12)
    data_font = Font(size=10)
    
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    # æ¨™é¡Œ
    summary_ws['A1'] = "èªè¨€ç¸½è¦½çµ±è¨ˆ"
    title_cell = summary_ws['A1']
    title_cell.font = Font(bold=True, size=14)
    title_cell.alignment = Alignment(horizontal="center")
    
    # çµ±è¨ˆè¡¨é ­
    headers = ["èªè¨€", "æª”æ¡ˆé¡å‹", "åˆ†é¡æ•¸é‡", "æ•æ„Ÿè©æ•¸é‡", "å‚™è¨»"]
    for col_num, header in enumerate(headers, 1):
        cell = summary_ws.cell(row=3, column=col_num, value=header)
        cell.font = header_font
        cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        cell.alignment = Alignment(horizontal="center", vertical="center")
        cell.border = thin_border
    
    # çµ±è¨ˆè³‡æ–™
    current_row = 4
    business_types = config.get_business_types()
    
    for language, keywords_dict in all_language_keywords.items():
        # ç²å–èªè¨€æª”æ¡ˆè³‡è¨Š
        try:
            language_files = config.get_language_files(language)
            file_types = []
            if 'po_file' in language_files:
                file_types.append('PO')
            if 'json_file' in language_files:
                file_types.append('JSON')
        except Exception:
            file_types = []
        
        file_type_str = '+'.join(file_types) if file_types else "ç„¡æª”æ¡ˆ"
        category_count = len(keywords_dict)
        keyword_count = sum(len(words) for words in keywords_dict.values())
        
        # å‚™è¨»è³‡è¨Š
        notes = []
        if keyword_count == 0:
            notes.append("ç„¡æ•æ„Ÿè©")
        elif keyword_count < 20:
            notes.append("æ•æ„Ÿè©è¼ƒå°‘")
        
        row_data = [
            language,
            file_type_str,
            category_count,
            keyword_count,
            'ï¼›'.join(notes) if notes else "æ­£å¸¸"
        ]
        
        for col_num, value in enumerate(row_data, 1):
            cell = summary_ws.cell(row=current_row, column=col_num, value=value)
            cell.font = data_font
            cell.border = thin_border
            cell.alignment = Alignment(horizontal="center" if col_num != 5 else "left", vertical="center")
        
        current_row += 1
    
    # ç¸½è¨ˆè¡Œ
    total_languages = len(all_language_keywords)
    total_categories = len(set().union(*[keywords.keys() for keywords in all_language_keywords.values()]))
    total_keywords = sum(sum(len(words) for words in keywords.values()) for keywords in all_language_keywords.values())
    
    total_row_data = [
        f"ç¸½è¨ˆ ({total_languages} å€‹èªè¨€)",
        "-",
        total_categories,
        total_keywords,
        f"å¹³å‡æ¯èªè¨€ {total_keywords // total_languages if total_languages else 0} å€‹æ•æ„Ÿè©"
    ]
    
    for col_num, value in enumerate(total_row_data, 1):
        cell = summary_ws.cell(row=current_row, column=col_num, value=value)
        cell.font = Font(bold=True, size=10)
        cell.border = thin_border
        cell.fill = PatternFill(start_color="F0F0F0", end_color="F0F0F0", fill_type="solid")
        cell.alignment = Alignment(horizontal="center" if col_num != 5 else "left", vertical="center")
    
    # æ¥­æ…‹è³‡è¨Š
    current_row += 3
    summary_ws.cell(row=current_row, column=1, value="æ”¯æ´çš„æ¥­æ…‹ï¼š").font = Font(bold=True)
    current_row += 1
    
    for bt_code, bt_config in business_types.items():
        summary_ws.cell(row=current_row, column=1, value=f"â€¢ {bt_config['display_name']}")
        summary_ws.cell(row=current_row, column=2, value=bt_config['description'])
        current_row += 1
    
    # ä½¿ç”¨èªªæ˜
    current_row += 2
    summary_ws.cell(row=current_row, column=1, value="ä½¿ç”¨èªªæ˜ï¼š").font = Font(bold=True)
    current_row += 1
    
    instructions = [
        "1. åœ¨ã€Œphrase_comparisonã€å·¥ä½œè¡¨ä¸­ç·¨è¼¯å„æ¥­æ…‹çš„å°æ‡‰æ–¹æ¡ˆ",
        "2. ç©ºç™½æ¬„ä½è¡¨ç¤ºä½¿ç”¨åŸå§‹æ•æ„Ÿè©ï¼Œç„¡éœ€æ›¿æ›",
        "3. ç·¨è¼¯å®Œæˆå¾Œï¼ŒåŸ·è¡Œ script_01_generate_xlsx.py ç”Ÿæˆå¾…ä¿®æ­£æ¸…å–®",
        "4. æœ€å¾ŒåŸ·è¡Œ script_02_apply_fixes.py å¥—ç”¨ä¿®æ­£çµæœ"
    ]
    
    for instruction in instructions:
        summary_ws.cell(row=current_row, column=1, value=instruction)
        current_row += 1
    
    # è‡ªå‹•èª¿æ•´æ¬„å¯¬ï¼ˆä½¿ç”¨å®‰å…¨æ–¹æ³•ï¼‰
    safe_adjust_column_widths_for_summary(summary_ws)


def test_detection():
    """æ¸¬è©¦æ•æ„Ÿè©æª¢æ¸¬åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦æ•æ„Ÿè©æª¢æ¸¬åŠŸèƒ½...")
    
    # å‰µå»ºæ¸¬è©¦æ–‡æœ¬
    test_texts = [
        "å­¸ç”Ÿæˆç¸¾ç®¡ç†ç³»çµ±ä¸­çš„èª²ç¨‹è³‡æ–™",
        "æ•™å¸«å¯ä»¥æŸ¥çœ‹ç­ç´šå­¸å“¡çš„å­¸ç¿’é€²åº¦",
        "åŸ¹è¨“æ©Ÿæ§‹éœ€è¦çµ±è¨ˆå­¸å“¡çš„å‡ºå¸­ç‡",
        "ç³»çµ±ç®¡ç†å“¡è² è²¬ç¶­è­·ç”¨æˆ¶å¸³è™Ÿæ¬Šé™"
    ]
    
    # æ¨¡æ“¬æª¢æ¸¬
    combined_text = ' '.join(test_texts).lower()
    
    detected = defaultdict(list)
    for category, words in BASE_SENSITIVE_WORDS.items():
        for word in words:
            if word in combined_text:
                detected[category].append(word)
    
    print("æª¢æ¸¬çµæœï¼š")
    for category, words in detected.items():
        if words:
            print(f"  {category}: {', '.join(words)}")
    
    print(f"\nç¸½è¨ˆæª¢æ¸¬åˆ° {sum(len(words) for words in detected.values())} å€‹æ•æ„Ÿè©")
    return dict(detected)


def extract_keywords_from_json(json_file_path: str) -> dict:
    """
    å¾ JSON æª”æ¡ˆä¸­æå–æ•æ„Ÿè©ï¼ˆå‚™ç”¨åŠŸèƒ½ï¼‰
    
    Args:
        json_file_path: JSON æª”æ¡ˆè·¯å¾‘
    
    Returns:
        æå–çš„æ•æ„Ÿè©å­—å…¸
    """
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # é€™è£¡å¯ä»¥æ ¹æ“š JSON çš„å…·é«”çµæ§‹ä¾†æå–æ•æ„Ÿè©
        # ç›®å‰ä½¿ç”¨é è¨­çš„åŸºç¤è©å…¸
        return BASE_SENSITIVE_WORDS.copy()
        
    except Exception as e:
        print(f"âš ï¸  å¾ JSON æª”æ¡ˆæå–æ•æ„Ÿè©å¤±æ•—ï¼š{e}")
        return BASE_SENSITIVE_WORDS.copy()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison Excel æª”æ¡ˆ')
    parser.add_argument('--test', action='store_true', help='åŸ·è¡Œæª¢æ¸¬æ¸¬è©¦')
    parser.add_argument('--extract-json', help='å¾æŒ‡å®š JSON æª”æ¡ˆæå–æ•æ„Ÿè©')
    
    args = parser.parse_args()
    
    if args.test:
        test_detection()
    elif args.extract_json:
        # å¾ JSON æª”æ¡ˆæå–æ•æ„Ÿè©çš„åŠŸèƒ½
        if Path(args.extract_json).exists():
            extracted = extract_keywords_from_json(args.extract_json)
            print(f"å¾ {args.extract_json} æå–çš„æ•æ„Ÿè©ï¼š")
            for category, words in extracted.items():
                print(f"  {category}: {len(words)} å€‹è©")
        else:
            print(f"âŒ JSON æª”æ¡ˆä¸å­˜åœ¨ï¼š{args.extract_json}")
    else:
        # æ­£å¸¸åŸ·è¡Œ
        main()