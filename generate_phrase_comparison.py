#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_phrase_comparison.py (v2.3 - Unified Excel Version)

ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison.xlsx æª”æ¡ˆï¼ŒåŒ…å«æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©å°ç…§è¡¨
æ”¯æ´èªè¨€å€å¡Šåˆ†é›¢ï¼Œåœ¨åŒä¸€å€‹ Excel ä¸­çµ±ä¸€ç®¡ç†æ‰€æœ‰èªè¨€å’Œæ¥­æ…‹

åŠŸèƒ½ï¼š
1. è‡ªå‹•æƒæ i18n_input ç›®éŒ„ä¸­çš„æ‰€æœ‰èªè¨€
2. å¾å„èªè¨€æª”æ¡ˆä¸­æª¢æ¸¬æ•æ„Ÿè©
3. ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison.xlsxï¼ŒæŒ‰èªè¨€åˆ†å€å¡Š
4. ä½¿ç”¨å¾ JSON æå–çš„åŸºç¤æ•æ„Ÿè©å­—å…¸
5. è‡ªå‹•å‚™ä»½ç¾æœ‰æª”æ¡ˆ
"""

import json
import re
import itertools
import sys
import shutil
import datetime
from pathlib import Path
from collections import defaultdict
from config_loader import get_config

try:
    import polib
    from openpyxl import Workbook
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    from openpyxl.utils import get_column_letter
    from openpyxl.cell.cell import MergedCell
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install polib openpyxl")
    sys.exit(1)


def auto_adjust_column_widths(worksheet, max_width=50):
    """
    è‡ªå‹•èª¿æ•´åˆ—å¯¬ï¼Œé¿å… MergedCell éŒ¯èª¤
    
    Args:
        worksheet: openpyxl å·¥ä½œè¡¨å°è±¡
        max_width: æœ€å¤§åˆ—å¯¬
    """
    try:
        for col_idx in range(1, worksheet.max_column + 1):
            column_letter = get_column_letter(col_idx)
            max_length = 0
            
            # éæ­·è©²åˆ—çš„æ‰€æœ‰å–®å…ƒæ ¼
            for row_idx in range(1, worksheet.max_row + 1):
                cell = worksheet.cell(row=row_idx, column=col_idx)
                
                # è·³é MergedCell
                if isinstance(cell, MergedCell):
                    continue
                    
                if cell.value:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            
            # è¨­ç½®åˆ—å¯¬ï¼ˆæœ€å°12ï¼Œæœ€å¤§max_widthï¼‰
            adjusted_width = min(max(max_length + 4, 12), max_width)
            worksheet.column_dimensions[column_letter].width = adjusted_width
            
    except Exception as e:
        print(f"âš ï¸  åˆ—å¯¬èª¿æ•´ç™¼ç”ŸéŒ¯èª¤ï¼ˆä¸å½±éŸ¿åŠŸèƒ½ï¼‰: {e}")


def safe_adjust_column_widths_for_summary(worksheet):
    """
    ç‚ºç¸½è¦½å·¥ä½œè¡¨å®‰å…¨åœ°èª¿æ•´åˆ—å¯¬
    """
    try:
        for col_idx in range(1, worksheet.max_column + 1):
            column_letter = get_column_letter(col_idx)
            max_length = 0
            
            for row_idx in range(1, worksheet.max_row + 1):
                cell = worksheet.cell(row=row_idx, column=col_idx)
                
                if isinstance(cell, MergedCell):
                    continue
                    
                if cell.value:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            
            adjusted_width = min(max(max_length + 2, 10), 50)
            worksheet.column_dimensions[column_letter].width = adjusted_width
            
    except Exception as e:
        print(f"âš ï¸  ç¸½è¦½å·¥ä½œè¡¨åˆ—å¯¬èª¿æ•´ç™¼ç”ŸéŒ¯èª¤: {e}")


# åŸºç¤æ•æ„Ÿè©å­—å…¸ - å¾ JSON æª”æ¡ˆåˆ†æå’Œæ•™è‚²åŸ¹è¨“é ˜åŸŸç¶“é©—æ•´ç†
BASE_SENSITIVE_WORDS = {
    "å­¸å“¡ç›¸é—œ": [
        "å­¸ç”Ÿ", "å­¸å“¡", "åƒèˆ‡è€…", "å—è¨“è€…", "åŒå­¸", "ç­ç´š", "çµ„åˆ¥",
        "å­¸è™Ÿ", "å§“å", "è¯çµ¡æ–¹å¼", "å‡ºå¸­", "è«‹å‡", "ç¼ºå¸­", "é€€é¸"
    ],
    "å¸«è³‡ç›¸é—œ": [
        "è€å¸«", "æ•™å¸«", "è¬›å¸«", "æ•™æˆ", "åŠ©æ•™", "æŒ‡å°å“¡", "è¼”å°å“¡",
        "å°ˆå®¶", "é¡§å•", "ä¸»è¬›", "å”åŒ", "ä»£èª²", "å…¼ä»»", "å°ˆä»»", "å®¢åº§"
    ],
    "æ™‚é–“ç›¸é—œ": [
        "å­¸æœŸ", "å­¸å¹´", "å¹´åº¦", "å­£åº¦", "æœˆä»½", "é€±æ¬¡", "ç¯€æ¬¡",
        "æ™‚é–“", "æ—¥æœŸ", "æœŸé–“", "é–‹å§‹", "çµæŸ", "æˆªæ­¢", "å»¶æœŸ", "æ’ç¨‹"
    ]
}


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison.xlsx æª”æ¡ˆ")
    
    # è¼‰å…¥é…ç½®
    config = get_config()
    config.print_config_summary()
    
    # æª¢æ¸¬å¯ç”¨èªè¨€
    available_languages = config.detect_available_languages()
    print(f"\nğŸŒ å°‡è™•ç† {len(available_languages)} å€‹èªè¨€ï¼š{', '.join(available_languages)}")
    
    # å‚™ä»½é…ç½®
    backup_config = config.get_backup_config()
    backup_dir = config.get_backup_dir()
    backup_dir.mkdir(exist_ok=True)
    
    timestamp_format = backup_config.get('timestamp_format', '%Y%m%d_%H%M%S')
    timestamp = datetime.datetime.now().strftime(timestamp_format)
    
    # ç²å–çµ±ä¸€ Excel æª”æ¡ˆè·¯å¾‘
    file_patterns = config.get_file_patterns()
    excel_path = Path(file_patterns.get('phrase_comparison', 'phrase_comparison.xlsx'))
    
    print(f"   ç›®æ¨™æª”æ¡ˆï¼š{excel_path}")
    
    # å‚™ä»½ç¾æœ‰æª”æ¡ˆ
    if excel_path.exists():
        backup_filename = f"{excel_path.stem}_{timestamp}{excel_path.suffix}"
        backup_path = backup_dir / backup_filename
        
        shutil.copy2(excel_path, backup_path)
        print(f"   âœ… å·²å‚™ä»½ç¾æœ‰æª”æ¡ˆï¼š{backup_filename}")
    
    # æ”¶é›†æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©
    all_language_keywords = {}
    
    for language in available_languages:
        print(f"\nğŸ“‹ åˆ†æèªè¨€ï¼š{language}")
        language_files = config.get_language_files(language)
        detected_keywords = detect_sensitive_words(language_files, config, language)
        
        if not detected_keywords:
            print(f"   âš ï¸  åœ¨ {language} ä¸­æœªæª¢æ¸¬åˆ°æ•æ„Ÿè©ï¼Œä½¿ç”¨åŸºç¤è©å½™")
            detected_keywords = BASE_SENSITIVE_WORDS.copy()
        
        all_language_keywords[language] = detected_keywords
        
        total_words = sum(len(words) for words in detected_keywords.values())
        print(f"   ğŸ“Š æª¢æ¸¬åˆ° {total_words} å€‹æ•æ„Ÿè©ï¼Œ{len(detected_keywords)} å€‹åˆ†é¡")
        for category, words in detected_keywords.items():
            print(f"      {category}: {len(words)} å€‹è©")
    
    # ç”Ÿæˆçµ±ä¸€ Excel
    generate_unified_excel(config, all_language_keywords, excel_path)
    print(f"\nâœ… çµ±ä¸€å°ç…§è¡¨ç”Ÿæˆå®Œæˆï¼š{excel_path}")
    
    # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    total_languages = len(all_language_keywords)
    total_categories = len(set().union(*[keywords.keys() for keywords in all_language_keywords.values()]))
    total_words = sum(sum(len(words) for words in keywords.values()) for keywords in all_language_keywords.values())
    
    print(f"\nğŸ“Š çµ±è¨ˆå ±å‘Šï¼š")
    print(f"   èªè¨€æ•¸é‡ï¼š{total_languages}")
    print(f"   åˆ†é¡ç¸½æ•¸ï¼š{total_categories}")
    print(f"   æ•æ„Ÿè©ç¸½æ•¸ï¼š{total_words}")
    print(f"   å¹³å‡æ¯èªè¨€ï¼š{total_words // total_languages if total_languages else 0} å€‹æ•æ„Ÿè©")


def detect_sensitive_words(language_files: dict, config, language: str) -> dict:
    """
    å¾èªè¨€æª”æ¡ˆä¸­æª¢æ¸¬æ•æ„Ÿè©
    
    Args:
        language_files: èªè¨€æª”æ¡ˆè·¯å¾‘å­—å…¸
        config: é…ç½®ç‰©ä»¶
        language: èªè¨€ä»£ç¢¼
    
    Returns:
        æª¢æ¸¬åˆ°çš„æ•æ„Ÿè©å­—å…¸ {åˆ†é¡: [è©å½™åˆ—è¡¨]}
    """
    
    # æ”¶é›†æ‰€æœ‰æ–‡æœ¬å…§å®¹
    all_texts = []
    
    # è®€å– PO æª”æ¡ˆ
    if 'po_file' in language_files:
        try:
            po_file = polib.pofile(str(language_files['po_file']))
            for entry in po_file:
                if entry.msgid:
                    all_texts.append(entry.msgid)
                if entry.msgstr:
                    all_texts.append(entry.msgstr)
            print(f"      âœ… è®€å– PO æª”æ¡ˆï¼š{len(po_file)} å€‹æ¢ç›®")
        except Exception as e:
            print(f"      âš ï¸  è®€å– PO æª”æ¡ˆå¤±æ•—ï¼š{e}")
    
    # è®€å– JSON æª”æ¡ˆ
    if 'json_file' in language_files:
        try:
            with open(language_files['json_file'], 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            def extract_json_values(obj):
                """éè¿´æå– JSON ä¸­çš„æ‰€æœ‰å­—ç¬¦ä¸²å€¼"""
                if isinstance(obj, dict):
                    for value in obj.values():
                        yield from extract_json_values(value)
                elif isinstance(obj, list):
                    for item in obj:
                        yield from extract_json_values(item)
                elif isinstance(obj, str):
                    yield obj
            
            json_texts = list(extract_json_values(json_data))
            all_texts.extend(json_texts)
            print(f"      âœ… è®€å– JSON æª”æ¡ˆï¼š{len(json_texts)} å€‹æ–‡æœ¬")
            
        except Exception as e:
            print(f"      âš ï¸  è®€å– JSON æª”æ¡ˆå¤±æ•—ï¼š{e}")
    
    if not all_texts:
        print(f"      âš ï¸  ç„¡æ³•å¾æª”æ¡ˆä¸­æå–æ–‡æœ¬å…§å®¹")
        return {}
    
    # æª¢æ¸¬æ•æ„Ÿè©
    print(f"      ğŸ” å¾ {len(all_texts)} å€‹æ–‡æœ¬æ¢ç›®ä¸­æª¢æ¸¬æ•æ„Ÿè©...")
    
    detected_words = defaultdict(set)
    detection_config = config.get_keyword_detection_config()
    case_sensitive = detection_config.get('case_sensitive', False)
    
    # åˆä½µæ‰€æœ‰æ–‡æœ¬
    combined_text = ' '.join(all_texts)
    if not case_sensitive:
        combined_text = combined_text.lower()
    
    # å°æ¯å€‹åŸºç¤åˆ†é¡çš„æ•æ„Ÿè©é€²è¡Œæª¢æ¸¬
    for category, base_words in BASE_SENSITIVE_WORDS.items():
        for word in base_words:
            search_word = word.lower() if not case_sensitive else word
            if search_word in combined_text:
                detected_words[category].add(word)
    
    # è½‰æ›ç‚ºæ™®é€šå­—å…¸ï¼Œä¸¦æŒ‰åŸå§‹é †åºæ’åˆ—
    result = {}
    for category, words in detected_words.items():
        # ä¿æŒèˆ‡åŸºç¤è©å…¸ç›¸åŒçš„é †åº
        ordered_words = []
        for base_word in BASE_SENSITIVE_WORDS[category]:
            if base_word in words:
                ordered_words.append(base_word)
        if ordered_words:
            result[category] = ordered_words
    
    return result


def generate_unified_excel(config, all_language_keywords: dict, output_path: Path):
    """
    ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison Excel æª”æ¡ˆ
    
    Args:
        config: é…ç½®ç‰©ä»¶
        all_language_keywords: æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©å­—å…¸
        output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    """
    
    # å‰µå»ºå·¥ä½œç°¿
    wb = Workbook()
    
    # è¨­ç½®ä¸»å·¥ä½œè¡¨
    ws = wb.active
    excel_config = config.get_excel_config()
    ws.title = excel_config.get('worksheets', {}).get('comparison', 'phrase_comparison')
    
    # æ¨£å¼è¨­å®š
    styling = excel_config.get('styling', {})
    language_header_color = styling.get('language_header_color', '366092')
    category_header_color = styling.get('category_header_color', '70AD47')
    data_row_color = styling.get('data_row_color', 'F2F2F2')
    
    # å­—é«”å’Œé‚Šæ¡†æ¨£å¼
    header_font = Font(bold=True, color="FFFFFF", size=12)
    category_font = Font(bold=True, color="FFFFFF", size=11)
    data_font = Font(size=10)
    
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    # å»ºç«‹æ¬„ä½æ¨™é¡Œ
    business_types = config.get_business_types()
    headers = ["èªè¨€", "æ•æ„Ÿè©é¡å‹", "æ•æ„Ÿè©"]
    
    for bt_code, bt_config in business_types.items():
        display_name = bt_config['display_name']
        business_columns = excel_config.get('business_columns', {})
        solution_template = business_columns.get('solution_template', 'å°æ‡‰æ–¹æ¡ˆ({display_name})')
        column_name = solution_template.format(display_name=display_name)
        headers.append(column_name)
    
    # å¯«å…¥ä¸»æ¨™é¡Œ
    current_row = 1
    
    # ç¸½æ¨™é¡Œ
    ws.merge_cells(f'A{current_row}:{get_column_letter(len(headers))}{current_row}')
    title_cell = ws[f'A{current_row}']
    title_cell.value = "å¤šèªè¨€æ•æ„Ÿè©å°ç…§è¡¨"
    title_cell.font = Font(bold=True, size=14, color="FFFFFF")
    title_cell.fill = PatternFill(start_color="2F4F4F", end_color="2F4F4F", fill_type="solid")
    title_cell.alignment = Alignment(horizontal="center", vertical="center")
    
    current_row += 1
    
    # æ¬„ä½æ¨™é¡Œ
    for col_num, header in enumerate(headers, 1):
        cell = ws.cell(row=current_row, column=col_num, value=header)
        cell.font = header_font
        cell.fill = PatternFill(start_color=language_header_color, end_color=language_header_color, fill_type="solid")
        cell.alignment = Alignment(horizontal="center", vertical="center")
        cell.border = thin_border
    
    current_row += 1
    
    # èªè¨€å€å¡Šè¨­å®š
    language_blocks = excel_config.get('language_blocks', {})
    separator_rows = language_blocks.get('separator_rows', 1)
    
    # å¯«å…¥å„èªè¨€çš„è³‡æ–™
    for lang_index, (language, keywords_dict) in enumerate(all_language_keywords.items()):
        if lang_index > 0:
            # èªè¨€é–“åˆ†éš”è¡Œ
            for _ in range(separator_rows):
                current_row += 1
        
        # èªè¨€å€å¡Šé–‹å§‹è¡Œ
        language_start_row = current_row
        
        # è™•ç†æ¯å€‹åˆ†é¡
        for category_index, (category, keywords) in enumerate(keywords_dict.items()):
            for keyword_index, keyword in enumerate(keywords):
                row_data = [
                    language if category_index == 0 and keyword_index == 0 else "",  # åªåœ¨ç¬¬ä¸€è¡Œé¡¯ç¤ºèªè¨€
                    category if keyword_index == 0 else "",  # åªåœ¨åˆ†é¡ç¬¬ä¸€è¡Œé¡¯ç¤ºåˆ†é¡å
                    keyword
                ]
                
                # ç‚ºæ¯å€‹æ¥­æ…‹æ·»åŠ ç©ºç™½çš„å°æ‡‰æ–¹æ¡ˆæ¬„ä½
                for bt_code in business_types.keys():
                    row_data.append("")  # ç©ºç™½ï¼Œè®“ä½¿ç”¨è€…æ‰‹å‹•å¡«å¯«
                
                # å¯«å…¥è³‡æ–™è¡Œ
                for col_num, value in enumerate(row_data, 1):
                    cell = ws.cell(row=current_row, column=col_num, value=value)
                    cell.font = data_font
                    cell.border = thin_border
                    cell.alignment = Alignment(horizontal="left", vertical="center")
                    
                    # è¨­ç½®èƒŒæ™¯è‰²ï¼ˆå¥‡å¶è¡Œï¼‰
                    if current_row % 2 == 0:
                        cell.fill = PatternFill(start_color=data_row_color, end_color=data_row_color, fill_type="solid")
                
                current_row += 1
        
        # èªè¨€å€å¡ŠçµæŸå¾Œï¼Œç‚ºèªè¨€åç¨±è¨­ç½®åˆä½µå„²å­˜æ ¼
        if language_start_row < current_row - 1:
            ws.merge_cells(f'A{language_start_row}:A{current_row - 1}')
            language_cell = ws[f'A{language_start_row}']
            language_cell.alignment = Alignment(horizontal="center", vertical="center")
            language_cell.font = Font(bold=True, size=11)
            language_cell.fill = PatternFill(start_color="E6F3FF", end_color="E6F3FF", fill_type="solid")
    
    # è‡ªå‹•èª¿æ•´æ¬„å¯¬ï¼ˆä¿®å¾© MergedCell éŒ¯èª¤ï¼‰
    auto_adjust_column_widths(ws, max_width=40)
    
    # å‰µå»ºç¸½è¦½å·¥ä½œè¡¨
    create_summary_worksheet(wb, config, all_language_keywords)
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æª”æ¡ˆ
    wb.save(output_path)
    
    total_rows = current_row - 1
    total_keywords = sum(sum(len(words) for words in keywords.values()) for keywords in all_language_keywords.values())
    print(f"      ğŸ“Š Excel çµ±è¨ˆï¼š{total_keywords} å€‹æ•æ„Ÿè©ï¼Œ{len(business_types)} å€‹æ¥­æ…‹æ¬„ä½ï¼Œ{total_rows} è¡Œè³‡æ–™")


def create_summary_worksheet(wb, config, all_language_keywords: dict):
    """
    å‰µå»ºèªè¨€ç¸½è¦½å·¥ä½œè¡¨
    
    Args:
        wb: å·¥ä½œç°¿ç‰©ä»¶
        config: é…ç½®ç‰©ä»¶
        all_language_keywords: æ‰€æœ‰èªè¨€çš„æ•æ„Ÿè©å­—å…¸
    """
    
    # å‰µå»ºç¸½è¦½å·¥ä½œè¡¨
    excel_config = config.get_excel_config()
    summary_sheet_name = excel_config.get('worksheets', {}).get('summary', 'èªè¨€ç¸½è¦½')
    summary_ws = wb.create_sheet(title=summary_sheet_name)
    
    # æ¨£å¼è¨­å®š
    header_font = Font(bold=True, color="FFFFFF", size=12)
    data_font = Font(size=10)
    
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    # æ¨™é¡Œ
    summary_ws['A1'] = "èªè¨€ç¸½è¦½çµ±è¨ˆ"
    title_cell = summary_ws['A1']
    title_cell.font = Font(bold=True, size=14)
    title_cell.alignment = Alignment(horizontal="center")
    
    # çµ±è¨ˆè¡¨é ­
    headers = ["èªè¨€", "æª”æ¡ˆé¡å‹", "åˆ†é¡æ•¸é‡", "æ•æ„Ÿè©æ•¸é‡", "å‚™è¨»"]
    for col_num, header in enumerate(headers, 1):
        cell = summary_ws.cell(row=3, column=col_num, value=header)
        cell.font = header_font
        cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        cell.alignment = Alignment(horizontal="center", vertical="center")
        cell.border = thin_border
    
    # çµ±è¨ˆè³‡æ–™
    current_row = 4
    business_types = config.get_business_types()
    
    for language, keywords_dict in all_language_keywords.items():
        # ç²å–èªè¨€æª”æ¡ˆè³‡è¨Š
        language_files = config.get_language_files(language)
        file_types = []
        if 'po_file' in language_files:
            file_types.append('PO')
        if 'json_file' in language_files:
            file_types.append('JSON')
        
        file_type_str = '+'.join(file_types) if file_types else "ç„¡æª”æ¡ˆ"
        category_count = len(keywords_dict)
        keyword_count = sum(len(words) for words in keywords_dict.values())
        
        # å‚™è¨»è³‡è¨Š
        notes = []
        if keyword_count == 0:
            notes.append("ç„¡æ•æ„Ÿè©")
        elif keyword_count < 20:
            notes.append("æ•æ„Ÿè©è¼ƒå°‘")
        
        row_data = [
            language,
            file_type_str,
            category_count,
            keyword_count,
            'ï¼›'.join(notes) if notes else "æ­£å¸¸"
        ]
        
        for col_num, value in enumerate(row_data, 1):
            cell = summary_ws.cell(row=current_row, column=col_num, value=value)
            cell.font = data_font
            cell.border = thin_border
            cell.alignment = Alignment(horizontal="center" if col_num != 5 else "left", vertical="center")
        
        current_row += 1
    
    # ç¸½è¨ˆè¡Œ
    total_languages = len(all_language_keywords)
    total_categories = len(set().union(*[keywords.keys() for keywords in all_language_keywords.values()]))
    total_keywords = sum(sum(len(words) for words in keywords.values()) for keywords in all_language_keywords.values())
    
    total_row_data = [
        f"ç¸½è¨ˆ ({total_languages} å€‹èªè¨€)",
        "-",
        total_categories,
        total_keywords,
        f"å¹³å‡æ¯èªè¨€ {total_keywords // total_languages if total_languages else 0} å€‹æ•æ„Ÿè©"
    ]
    
    for col_num, value in enumerate(total_row_data, 1):
        cell = summary_ws.cell(row=current_row, column=col_num, value=value)
        cell.font = Font(bold=True, size=10)
        cell.border = thin_border
        cell.fill = PatternFill(start_color="F0F0F0", end_color="F0F0F0", fill_type="solid")
        cell.alignment = Alignment(horizontal="center" if col_num != 5 else "left", vertical="center")
    
    # æ¥­æ…‹è³‡è¨Š
    current_row += 3
    summary_ws.cell(row=current_row, column=1, value="æ”¯æ´çš„æ¥­æ…‹ï¼š").font = Font(bold=True)
    current_row += 1
    
    for bt_code, bt_config in business_types.items():
        summary_ws.cell(row=current_row, column=1, value=f"â€¢ {bt_config['display_name']}")
        summary_ws.cell(row=current_row, column=2, value=bt_config['description'])
        current_row += 1
    
    # ä½¿ç”¨èªªæ˜
    current_row += 2
    summary_ws.cell(row=current_row, column=1, value="ä½¿ç”¨èªªæ˜ï¼š").font = Font(bold=True)
    current_row += 1
    
    instructions = [
        "1. åœ¨ã€Œphrase_comparisonã€å·¥ä½œè¡¨ä¸­ç·¨è¼¯å„æ¥­æ…‹çš„å°æ‡‰æ–¹æ¡ˆ",
        "2. ç©ºç™½æ¬„ä½è¡¨ç¤ºä½¿ç”¨åŸå§‹æ•æ„Ÿè©ï¼Œç„¡éœ€æ›¿æ›",
        "3. ç·¨è¼¯å®Œæˆå¾Œï¼ŒåŸ·è¡Œ script_01_generate_xlsx.py ç”Ÿæˆå¾…ä¿®æ­£æ¸…å–®",
        "4. æœ€å¾ŒåŸ·è¡Œ script_02_apply_fixes.py å¥—ç”¨ä¿®æ­£çµæœ"
    ]
    
    for instruction in instructions:
        summary_ws.cell(row=current_row, column=1, value=instruction)
        current_row += 1
    
    # è‡ªå‹•èª¿æ•´æ¬„å¯¬ï¼ˆä½¿ç”¨å®‰å…¨æ–¹æ³•ï¼‰
    safe_adjust_column_widths_for_summary(summary_ws)


def test_detection():
    """æ¸¬è©¦æ•æ„Ÿè©æª¢æ¸¬åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦æ•æ„Ÿè©æª¢æ¸¬åŠŸèƒ½...")
    
    # å‰µå»ºæ¸¬è©¦æ–‡æœ¬
    test_texts = [
        "å­¸ç”Ÿæˆç¸¾ç®¡ç†ç³»çµ±ä¸­çš„èª²ç¨‹è³‡æ–™",
        "æ•™å¸«å¯ä»¥æŸ¥çœ‹ç­ç´šå­¸å“¡çš„å­¸ç¿’é€²åº¦",
        "åŸ¹è¨“æ©Ÿæ§‹éœ€è¦çµ±è¨ˆå­¸å“¡çš„å‡ºå¸­ç‡",
        "ç³»çµ±ç®¡ç†å“¡è² è²¬ç¶­è­·ç”¨æˆ¶å¸³è™Ÿæ¬Šé™"
    ]
    
    # æ¨¡æ“¬æª¢æ¸¬
    combined_text = ' '.join(test_texts).lower()
    
    detected = defaultdict(list)
    for category, words in BASE_SENSITIVE_WORDS.items():
        for word in words:
            if word in combined_text:
                detected[category].append(word)
    
    print("æª¢æ¸¬çµæœï¼š")
    for category, words in detected.items():
        if words:
            print(f"  {category}: {', '.join(words)}")
    
    print(f"\nç¸½è¨ˆæª¢æ¸¬åˆ° {sum(len(words) for words in detected.values())} å€‹æ•æ„Ÿè©")
    return dict(detected)


def extract_keywords_from_json(json_file_path: str) -> dict:
    """
    å¾ JSON æª”æ¡ˆä¸­æå–æ•æ„Ÿè©ï¼ˆå‚™ç”¨åŠŸèƒ½ï¼‰
    
    Args:
        json_file_path: JSON æª”æ¡ˆè·¯å¾‘
    
    Returns:
        æå–çš„æ•æ„Ÿè©å­—å…¸
    """
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # é€™è£¡å¯ä»¥æ ¹æ“š JSON çš„å…·é«”çµæ§‹ä¾†æå–æ•æ„Ÿè©
        # ç›®å‰ä½¿ç”¨é è¨­çš„åŸºç¤è©å…¸
        return BASE_SENSITIVE_WORDS.copy()
        
    except Exception as e:
        print(f"âš ï¸  å¾ JSON æª”æ¡ˆæå–æ•æ„Ÿè©å¤±æ•—ï¼š{e}")
        return BASE_SENSITIVE_WORDS.copy()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ç”Ÿæˆçµ±ä¸€çš„ phrase_comparison Excel æª”æ¡ˆ')
    parser.add_argument('--test', action='store_true', help='åŸ·è¡Œæª¢æ¸¬æ¸¬è©¦')
    parser.add_argument('--extract-json', help='å¾æŒ‡å®š JSON æª”æ¡ˆæå–æ•æ„Ÿè©')
    
    args = parser.parse_args()
    
    if args.test:
        test_detection()
    elif args.extract_json:
        # å¾ JSON æª”æ¡ˆæå–æ•æ„Ÿè©çš„åŠŸèƒ½
        if Path(args.extract_json).exists():
            extracted = extract_keywords_from_json(args.extract_json)
            print(f"å¾ {args.extract_json} æå–çš„æ•æ„Ÿè©ï¼š")
            for category, words in extracted.items():
                print(f"  {category}: {len(words)} å€‹è©")
        else:
            print(f"âŒ JSON æª”æ¡ˆä¸å­˜åœ¨ï¼š{args.extract_json}")
    else:
        # æ­£å¸¸åŸ·è¡Œ
        main()