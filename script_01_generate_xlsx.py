#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
script_01_generate_xlsx.py (v2.5 - åŒ…å®¹é—œä¿‚å„ªå…ˆè™•ç†ç‰ˆæœ¬)

æ–°å¢åŠŸèƒ½ï¼š
1. æª¢æ¸¬æ•æ„Ÿè©ä¹‹é–“çš„åŒ…å®¹é—œä¿‚
2. æ ¹æ“šåŒ…å®¹é—œä¿‚ç¢ºå®šå„ªå…ˆé †åº
3. æŒ‰å„ªå…ˆé †åºé€²è¡ŒåŒ¹é…ï¼Œé¿å…é‡è¤‡æª¢æ¸¬è¢«åŒ…å®¹è©

ä¿®å¾©å…§å®¹ï¼š
1. ä¿®å¾©Excelèªè¨€å€å¡Šè§£æé‚è¼¯ï¼Œæ­£ç¢ºè™•ç†åˆä½µå„²å­˜æ ¼
2. æ”¹å–„èªè¨€åç¨±æª¢æ¸¬ï¼Œé¿å…å°‡è¡¨é ­èª¤èªç‚ºèªè¨€
3. å¢å¼·éŒ¯èª¤è™•ç†å’Œèª¿è©¦è³‡è¨Š
"""

import json
import re
import itertools
import sys
import shutil
import datetime
from pathlib import Path
from collections import defaultdict
from config_loader import get_config

try:
    import polib
    from openpyxl import load_workbook
    from openpyxl.cell.cell import MergedCell
    from openpyxl.utils import get_column_letter
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install polib openpyxl")
    sys.exit(1)


class InclusionDetector:
    """è™•ç†æ•æ„Ÿè©åŒ…å®¹é—œä¿‚å’Œå„ªå…ˆé †åºçš„é¡"""
    
    def __init__(self, sensitive_words_dict):
        """
        åˆå§‹åŒ–åŒ…å®¹é—œä¿‚æª¢æ¸¬å™¨
        
        Args:
            sensitive_words_dict: æ•æ„Ÿè©å­—å…¸ {category: {keyword: {business_type: replacement}}}
        """
        self.sensitive_words_dict = sensitive_words_dict
        self.flat_words = self._flatten_words()
        self.inclusion_relationships = self._detect_inclusions()
        self.priority_sorted_words = self._sort_by_priority()
        
        # èª¿è©¦è¼¸å‡º
        self._print_analysis()
    
    def _flatten_words(self):
        """å°‡åˆ†å±¤çš„æ•æ„Ÿè©å­—å…¸å±•å¹³ç‚º {keyword: word_info} æ ¼å¼"""
        flat_words = {}
        for category, keywords in self.sensitive_words_dict.items():
            for keyword, business_replacements in keywords.items():
                flat_words[keyword] = {
                    'category': category,
                    'replacements': business_replacements,
                    'keyword': keyword
                }
        return flat_words
    
    def _detect_inclusions(self):
        """
        æª¢æ¸¬æ•æ„Ÿè©ä¹‹é–“çš„åŒ…å®¹é—œä¿‚
        
        Returns:
            dict: {åŒ…å®¹è©: [è¢«åŒ…å®¹è©åˆ—è¡¨]}
        """
        inclusions = defaultdict(list)
        words = list(self.flat_words.keys())
        
        for i, word1 in enumerate(words):
            for j, word2 in enumerate(words):
                if i != j and word2 in word1 and len(word2) < len(word1):
                    inclusions[word1].append(word2)
        
        # æŒ‰è¢«åŒ…å®¹è©çš„é•·åº¦æ’åºï¼ˆé•·çš„å„ªå…ˆï¼‰
        for key in inclusions:
            inclusions[key].sort(key=len, reverse=True)
        
        return dict(inclusions)
    
    def _sort_by_priority(self):
        """
        æ ¹æ“šåŒ…å®¹é—œä¿‚ç¢ºå®šå„ªå…ˆé †åº
        
        Returns:
            list: æŒ‰å„ªå…ˆé †åºæ’åºçš„æ•æ„Ÿè©åˆ—è¡¨
        """
        words = list(self.flat_words.keys())
        
        # è¨ˆç®—æ¯å€‹è©çš„å„ªå…ˆç´šæ¬Šé‡
        word_weights = {}
        
        for word in words:
            # åŸºç¤æ¬Šé‡ = è©é•·åº¦
            weight = len(word)
            
            # å¦‚æœè©²è©åŒ…å®¹å…¶ä»–è©ï¼Œå¢åŠ æ¬Šé‡
            if word in self.inclusion_relationships:
                weight += len(self.inclusion_relationships[word]) * 10
                
            # å¦‚æœè©²è©è¢«å…¶ä»–è©åŒ…å®¹ï¼Œé™ä½æ¬Šé‡
            for parent_word, included_words in self.inclusion_relationships.items():
                if word in included_words:
                    weight -= 5
            
            word_weights[word] = weight
        
        # æŒ‰æ¬Šé‡é™åºæ’åºï¼ˆæ¬Šé‡é«˜çš„å„ªå…ˆï¼‰
        sorted_words = sorted(words, key=lambda w: word_weights[w], reverse=True)
        
        return sorted_words
    
    def _print_analysis(self):
        """è¼¸å‡ºåŒ…å®¹é—œä¿‚åˆ†æçµæœ - ç°¡åŒ–ç‰ˆ"""
        inclusion_count = len(self.inclusion_relationships)
        total_words = len(self.flat_words)
        
        if inclusion_count > 0:
            print(f"   ğŸ” åŒ…å®¹é—œä¿‚ï¼š{inclusion_count} çµ„ï¼Œç¸½è©æ•¸ï¼š{total_words}")
        else:
            print(f"   ğŸ“ ç¸½è©æ•¸ï¼š{total_words}ï¼ˆç„¡åŒ…å®¹é—œä¿‚ï¼‰")
    
    def detect_with_priority(self, text, log_detail=None):
        """
        æŒ‰å„ªå…ˆé †åºæª¢æ¸¬æ•æ„Ÿè©ï¼Œé¿å…é‡è¤‡åŒ¹é…è¢«åŒ…å®¹è©
        
        Args:
            text: è¦æª¢æ¸¬çš„æ–‡æœ¬
            log_detail: æ—¥èªŒè¨˜éŒ„å‡½æ•¸ï¼ˆå¯é¸ï¼‰
            
        Returns:
            list: æª¢æ¸¬åˆ°çš„æ•æ„Ÿè©åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å« {keyword, category, replacements, positions}
        """
        detected_items = []
        processed_positions = set()  # è¨˜éŒ„å·²è™•ç†çš„å­—ç¬¦ä½ç½®
        
        for keyword in self.priority_sorted_words:
            word_info = self.flat_words[keyword]
            
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…ä½ç½®
            pattern = re.escape(keyword)
            matches = list(re.finditer(pattern, text))
            
            for match in matches:
                start_pos = match.start()
                end_pos = match.end()
                
                # æª¢æŸ¥è©²ä½ç½®æ˜¯å¦å·²è¢«è™•ç†
                positions = set(range(start_pos, end_pos))
                if not positions.intersection(processed_positions):
                    # è¨˜éŒ„æª¢æ¸¬çµæœ
                    detected_items.append({
                        'keyword': keyword,
                        'category': word_info['category'],
                        'replacements': word_info['replacements'],
                        'start_pos': start_pos,
                        'end_pos': end_pos,
                        'matched_text': text[start_pos:end_pos]
                    })
                    
                    # æ¨™è¨˜é€™äº›ä½ç½®å·²è™•ç†
                    processed_positions.update(positions)
                    
                    # åªè¨˜éŒ„åˆ°æ—¥èªŒï¼Œä¸æ‰“å°åˆ°æ§åˆ¶å°
                    if log_detail:
                        log_detail(f"æª¢æ¸¬åˆ°ï¼šã€Œ{keyword}ã€ä½ç½® {start_pos}-{end_pos}")
        
        return detected_items


def parse_language_blocks_from_excel(excel_path: Path, config):
    """
    ä¿®å¾©ç‰ˆï¼šè§£æèªè¨€ç¨ç«‹æ©«å‘åˆ†å€å¡Š Excelï¼Œæ­£ç¢ºè™•ç†åˆä½µå„²å­˜æ ¼
    
    Args:
        excel_path: Excel æª”æ¡ˆè·¯å¾‘
        config: é…ç½®ç‰©ä»¶
        
    Returns:
        dict: æ¯å€‹èªè¨€çš„æ•æ„Ÿè©å’Œæ›¿æ›æ–¹æ¡ˆå­—å…¸
    """
    
    print(f"ğŸ“– è¼‰å…¥èªè¨€ç¨ç«‹æ©«å‘åˆ†å€å¡Šå°ç…§è¡¨ï¼š{excel_path.name}")
    
    # è¼‰å…¥å·¥ä½œç°¿
    wb = load_workbook(excel_path, data_only=True)
    
    # ç²å–ä¸»å·¥ä½œè¡¨
    excel_config = config.get_excel_config()
    worksheet_name = excel_config.get('worksheets', {}).get('comparison', 'phrase_comparison')
    
    if worksheet_name not in wb.sheetnames:
        available_sheets = ', '.join(wb.sheetnames)
        raise ValueError(f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨ '{worksheet_name}'ï¼Œå¯ç”¨å·¥ä½œè¡¨ï¼š{available_sheets}")
    
    ws = wb[worksheet_name]
    
    # ç²å–æ¥­æ…‹é…ç½®
    business_types = config.get_business_types()
    business_count = len(business_types)
    business_names = [bt_config['display_name'] for bt_config in business_types.values()]
    
    # æ©«å‘é…ç½®
    horizontal_config = excel_config.get('horizontal_layout', {})
    block_separator = horizontal_config.get('block_separator_columns', 1)
    
    # è¨ˆç®—æ¯å€‹èªè¨€å€å¡Šçš„å¯¬åº¦ï¼šæ•æ„Ÿè©é¡å‹ + æ•æ„Ÿè© + æ¥­æ…‹æ•¸é‡
    block_width = 2 + business_count
    
    language_data = {}
    warnings = []
    
    # ä¿®å¾©ç‰ˆï¼šæ”¹é€²èªè¨€å€å¡Šæª¢æ¸¬é‚è¼¯
    current_col = 1
    max_col = ws.max_column
    
    print(f"   Excel æœ€å¤§åˆ—æ•¸ï¼š{max_col}")
    print(f"   æ¯å€‹å€å¡Šå¯¬åº¦ï¼š{block_width}")
    print(f"   å€å¡Šåˆ†éš”ï¼š{block_separator}")
    
    while current_col <= max_col:
        # æª¢æŸ¥ç¬¬1è¡Œæ˜¯å¦æœ‰åˆä½µå„²å­˜æ ¼ï¼ˆèªè¨€æ¨™é¡Œï¼‰
        lang_cell = ws.cell(row=1, column=current_col)
        
        # è·³éç©ºç™½å„²å­˜æ ¼
        if not lang_cell.value:
            current_col += 1
            continue
        
        language_name = str(lang_cell.value).strip()
        
        # ä¿®å¾©ï¼šæ’é™¤è¡¨é ­é—œéµå­—ï¼Œåªæ¥å—çœŸæ­£çš„èªè¨€ä»£ç¢¼
        excluded_headers = ['æ•æ„Ÿè©é¡å‹', 'æ•æ„Ÿè©', 'é¡å‹', 'type', 'keyword', 'category']
        if language_name.lower() in [h.lower() for h in excluded_headers]:
            print(f"   è·³éè¡¨é ­ï¼š{language_name} (åˆ— {current_col})")
            current_col += 1
            continue
        
        # ä¿®å¾©ï¼šæª¢æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„èªè¨€ä»£ç¢¼æ ¼å¼
        # èªè¨€ä»£ç¢¼é€šå¸¸æ˜¯ xx_XX, xx-XX æˆ– xx æ ¼å¼
        if not re.match(r'^[a-z]{2}([_-][A-Z]{2})?$', language_name):
            print(f"   è·³éç„¡æ•ˆèªè¨€æ ¼å¼ï¼š{language_name} (åˆ— {current_col})")
            current_col += 1
            continue
        
        print(f"   è§£æèªè¨€å€å¡Šï¼š{language_name} (åˆ— {current_col}-{current_col + block_width - 1})")
        
        # æª¢æŸ¥ç¬¬2è¡Œçš„æ¨™é¡Œæ˜¯å¦æ­£ç¢º
        expected_headers = ["æ•æ„Ÿè©é¡å‹", "æ•æ„Ÿè©"] + business_names
        header_valid = True
        
        for i, expected_header in enumerate(expected_headers):
            col = current_col + i
            if col <= max_col:
                header_cell = ws.cell(row=2, column=col)
                actual_header = str(header_cell.value).strip() if header_cell.value else ""
                
                if actual_header != expected_header:
                    warnings.append(f"èªè¨€ {language_name} å€å¡Šåˆ— {col} æ¨™é¡Œä¸ç¬¦ï¼šæœŸæœ› '{expected_header}'ï¼Œå¯¦éš› '{actual_header}'")
                    
                    # å¦‚æœåŸºç¤æ¨™é¡Œéƒ½ä¸å°ï¼Œå¯èƒ½ä¸æ˜¯èªè¨€å€å¡Š
                    if i < 2 and actual_header not in ["æ•æ„Ÿè©é¡å‹", "æ•æ„Ÿè©"]:
                        header_valid = False
                        break
        
        if not header_valid:
            print(f"   è·³éç„¡æ•ˆå€å¡Šï¼š{language_name} (æ¨™é¡Œæ ¼å¼ä¸ç¬¦)")
            current_col += 1
            continue
        
        # è§£æè©²èªè¨€çš„æ•æ„Ÿè©å’Œæ›¿æ›æ–¹æ¡ˆ
        language_keywords = defaultdict(lambda: defaultdict(list))
        category_counts = defaultdict(int)
        
        # å¾ç¬¬3è¡Œé–‹å§‹è®€å–æ•¸æ“š
        current_row = 3
        current_category = None
        
        while current_row <= ws.max_row:
            # è®€å–æ•æ„Ÿè©é¡å‹
            category_cell = ws.cell(row=current_row, column=current_col)
            category_value = str(category_cell.value).strip() if category_cell.value else ""
            
            if category_value:
                current_category = category_value
            
            # è®€å–æ•æ„Ÿè©
            keyword_cell = ws.cell(row=current_row, column=current_col + 1)
            keyword_value = str(keyword_cell.value).strip() if keyword_cell.value else ""
            
            # å¦‚æœæ²’æœ‰æ•æ„Ÿè©ï¼ŒçµæŸè©²èªè¨€å€å¡Š
            if not keyword_value:
                current_row += 1
                continue
            
            if not current_category:
                current_row += 1
                continue
            
            # è®€å–å„æ¥­æ…‹çš„æ›¿æ›æ–¹æ¡ˆ
            business_replacements = {}
            
            for bt_index, (bt_code, bt_config) in enumerate(business_types.items()):
                col = current_col + 2 + bt_index
                if col <= max_col:
                    replacement_cell = ws.cell(row=current_row, column=col)
                    replacement_value = str(replacement_cell.value).strip() if replacement_cell.value else ""
                    
                    if replacement_value:
                        business_replacements[bt_code] = replacement_value
            
            # å„²å­˜åˆ°èªè¨€æ•¸æ“šä¸­
            language_keywords[current_category][keyword_value] = business_replacements
            category_counts[current_category] += 1
            
            current_row += 1
            
            # å¦‚æœè®€å–äº†è¶³å¤ å¤šçš„è¡Œä¸”æ²’æœ‰æ›´å¤šæ•¸æ“šï¼Œé€€å‡º
            if current_row > ws.max_row or current_row - 3 > 50:  # é™åˆ¶æœ€å¤šè®€50è¡Œ
                break
        
        # åªæœ‰ç•¶æ‰¾åˆ°æœ‰æ•ˆæ•¸æ“šæ™‚æ‰åŠ å…¥çµæœ
        if language_keywords:
            language_data[language_name] = dict(language_keywords)
            
            total_keywords = sum(category_counts.values())
            replacement_counts = {}
            
            for bt_code in business_types.keys():
                count = 0
                for category_data in language_keywords.values():
                    for keyword_data in category_data.values():
                        if bt_code in keyword_data:
                            count += 1
                replacement_counts[bt_code] = count
            
            print(f"     ç™¼ç¾èªè¨€å€å¡Šï¼š{language_name}")
            print(f"       {language_name}: {total_keywords} å€‹æ•æ„Ÿè©")
            
            for category, count in category_counts.items():
                print(f"         {category}: {count} å€‹æ•æ„Ÿè©")
                
            for bt_code, bt_config in business_types.items():
                count = replacement_counts.get(bt_code, 0)
                print(f"         {bt_config['display_name']}: {count} å€‹æœ‰æ›¿æ›æ–¹æ¡ˆ")
        else:
            print(f"   èªè¨€å€å¡Š {language_name} æœªæ‰¾åˆ°æœ‰æ•ˆæ•¸æ“š")
        
        # ç§»å‹•åˆ°ä¸‹å€‹å¯èƒ½çš„èªè¨€å€å¡Š
        current_col += block_width + block_separator
    
    # è¼¸å‡ºè­¦å‘Š
    if warnings:
        print("âš ï¸  è§£æè­¦å‘Šï¼š")
        for i, warning in enumerate(warnings[:30]):  # é™åˆ¶é¡¯ç¤ºå‰30å€‹è­¦å‘Š
            print(f"     {warning}")
        if len(warnings) > 30:
            print(f"     ... é‚„æœ‰ {len(warnings) - 30} å€‹è­¦å‘Š")
    
    # ä¿®å¾©ï¼šç¸½çµå¯¦éš›ç™¼ç¾çš„èªè¨€
    if language_data:
        total_languages = len(language_data)
        total_categories = len(set().union(*[keywords.keys() for keywords in language_data.values()]))
        total_keywords = sum(sum(len(category.keys()) for category in keywords.values()) for keywords in language_data.values())
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {total_languages} å€‹èªè¨€å€å¡Š")
        for language_name, keywords in language_data.items():
            keyword_count = sum(len(category.keys()) for category in keywords.values())
            category_count = len(keywords.keys())
            print(f"   {language_name}: {keyword_count} å€‹æ•æ„Ÿè©ï¼Œ{category_count} å€‹åˆ†é¡")
            
            # çµ±è¨ˆå„æ¥­æ…‹çš„æ›¿æ›æ–¹æ¡ˆæ•¸é‡
            for bt_code, bt_config in business_types.items():
                count = 0
                for category_data in keywords.values():
                    for keyword_data in category_data.values():
                        if bt_code in keyword_data:
                            count += 1
                print(f"     {bt_config['display_name']}: {count} å€‹æœ‰æ›¿æ›æ–¹æ¡ˆ")
    else:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„èªè¨€å€å¡Š")
    
    return language_data


def detect_sensitive_phrases_in_files_with_priority(config, language: str, sensitive_words: dict):
    """
    ä½¿ç”¨å„ªå…ˆé †åºé‚è¼¯åœ¨æŒ‡å®šèªè¨€çš„ç¿»è­¯æª”æ¡ˆä¸­æª¢æ¸¬æ•æ„Ÿè©
    
    Args:
        config: é…ç½®ç‰©ä»¶
        language: èªè¨€ä»£ç¢¼
        sensitive_words: æ•æ„Ÿè©å­—å…¸ {category: {keyword: {business_type: replacement, ...}, ...}}
        
    Returns:
        list: æª¢æ¸¬åˆ°çš„æ•æ„Ÿè©é …ç›®åˆ—è¡¨
    """
    
    print(f"   ğŸ” æª¢æ¸¬æ•æ„Ÿè©...")
    
    # åˆå§‹åŒ–åŒ…å®¹é—œä¿‚æª¢æ¸¬å™¨
    detector = InclusionDetector(sensitive_words)
    
    detected_items = []
    
    # å‰µå»ºæ—¥èªŒè¨˜éŒ„å‡½æ•¸
    def log_detail(message):
        # é€™è£¡å¯ä»¥å¯«å…¥æ—¥èªŒæª”æ¡ˆï¼Œä½†ä¸æ‰“å°åˆ°æ§åˆ¶å°
        pass
    
    try:
        # ç²å–èªè¨€æª”æ¡ˆ
        language_files = config.get_language_files(language)
        
        # æª¢æ¸¬ PO æª”æ¡ˆ
        if 'po_file' in language_files:
            po_path = language_files['po_file']
            if po_path.exists():
                try:
                    po_data = polib.pofile(str(po_path))
                    
                    for entry in po_data:
                        if not entry.msgstr:  # è·³éæœªç¿»è­¯çš„é …ç›®
                            continue
                        
                        # ä½¿ç”¨å„ªå…ˆé †åºæª¢æ¸¬
                        detected = detector.detect_with_priority(entry.msgstr, log_detail)
                        
                        for item in detected:
                            detected_items.append({
                                'file_type': 'po',
                                'file_path': po_path,
                                'entry_id': entry.msgid,
                                'entry_context': entry.msgctxt or "",
                                'original_text': entry.msgstr,
                                'sensitive_word': item['keyword'],
                                'category': item['category'],
                                'replacements': item['replacements'],
                                'line_number': entry.linenum if hasattr(entry, 'linenum') else 0,
                                'match_positions': (item['start_pos'], item['end_pos'])
                            })
                
                except Exception as e:
                    print(f"   âš ï¸  è®€å– PO æª”æ¡ˆå¤±æ•—ï¼š{e}")
        
        # æª¢æ¸¬ JSON æª”æ¡ˆ
        if 'json_file' in language_files:
            json_path = language_files['json_file']
            if json_path.exists():
                try:
                    with open(json_path, 'r', encoding='utf-8') as f:
                        json_data = json.load(f)
                    
                    def check_json_recursive(obj, path=""):
                        """éæ­¸æª¢æŸ¥ JSON ç‰©ä»¶ä¸­çš„æ•æ„Ÿè©"""
                        if isinstance(obj, dict):
                            for key, value in obj.items():
                                new_path = f"{path}.{key}" if path else key
                                check_json_recursive(value, new_path)
                        elif isinstance(obj, list):
                            for i, item in enumerate(obj):
                                new_path = f"{path}[{i}]"
                                check_json_recursive(item, new_path)
                        elif isinstance(obj, str):
                            # ä½¿ç”¨å„ªå…ˆé †åºæª¢æ¸¬
                            detected = detector.detect_with_priority(obj, log_detail)
                            
                            for item in detected:
                                detected_items.append({
                                    'file_type': 'json',
                                    'file_path': json_path,
                                    'entry_id': path,
                                    'entry_context': "",
                                    'original_text': obj,
                                    'sensitive_word': item['keyword'],
                                    'category': item['category'],
                                    'replacements': item['replacements'],
                                    'line_number': 0,
                                    'match_positions': (item['start_pos'], item['end_pos'])
                                })
                    
                    check_json_recursive(json_data)
                
                except Exception as e:
                    print(f"   âš ï¸  è®€å– JSON æª”æ¡ˆå¤±æ•—ï¼š{e}")
        
        # ç°¡åŒ–çµ±è¨ˆè¼¸å‡º
        category_stats = defaultdict(int)
        for item in detected_items:
            category_stats[item['category']] += 1
        
        if detected_items:
            print(f"   ğŸ“Š æª¢æ¸¬åˆ° {len(detected_items)} å€‹æ•æ„Ÿè©")
            for category, count in category_stats.items():
                print(f"     {category}: {count} å€‹")
        else:
            print(f"   âœ… ç„¡æ•æ„Ÿè©")
    
    except Exception as e:
        print(f"   âŒ æª¢æ¸¬éŒ¯èª¤ï¼š{e}")
    
    return detected_items


def generate_tobemodified_excel(config, language: str, detected_items: list, output_dir: Path):
    """
    ç”Ÿæˆå¾…ä¿®æ­£ Excel æª”æ¡ˆ
    
    Args:
        config: é…ç½®ç‰©ä»¶
        language: èªè¨€ä»£ç¢¼
        detected_items: æª¢æ¸¬åˆ°çš„æ•æ„Ÿè©é …ç›®åˆ—è¡¨
        output_dir: è¼¸å‡ºç›®éŒ„
    """
    
    from openpyxl import Workbook
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    from openpyxl.utils import get_column_letter
    
    if not detected_items:
        print(f"   âœ… ç„¡éœ€ä¿®æ­£é …ç›®")
        return
    
    # å»ºç«‹è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    output_file = output_dir / f"{language}_tobemodified.xlsx"
    
    # å‰µå»ºå·¥ä½œç°¿
    wb = Workbook()
    ws = wb.active
    ws.title = f"{language}_å¾…ä¿®æ­£æ¸…å–®"
    
    # æ¨£å¼è¨­å®š
    header_font = Font(bold=True, color="FFFFFF", size=12)
    data_font = Font(size=10)
    header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
    alt_row_fill = PatternFill(start_color="F2F2F2", end_color="F2F2F2", fill_type="solid")
    
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    # å–å¾—æ¥­æ…‹é¡å‹
    business_types = config.get_business_types()
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ åŒ¹é…ä½ç½®æ¬„ä½
    keyword_config = config.get_keyword_detection_config()
    inclusion_config = keyword_config.get('inclusion_handling', {})
    add_position_column = inclusion_config.get('add_position_column', False)
    
    # å®šç¾©æ¨™é¡Œåˆ—
    headers = [
        "æª”æ¡ˆé¡å‹", "æª”æ¡ˆè·¯å¾‘", "é …ç›®ID", "é …ç›®å…§å®¹", "æ•æ„Ÿè©", "æ•æ„Ÿè©åˆ†é¡"
    ]
    
    # å¯é¸æ·»åŠ åŒ¹é…ä½ç½®æ¬„ä½
    if add_position_column:
        headers.append("åŒ¹é…ä½ç½®")
    
    # ç‚ºæ¯å€‹æ¥­æ…‹æ·»åŠ æ›¿æ›æ–¹æ¡ˆåˆ—å’Œæ›¿æ›çµæœåˆ—
    for bt_code, bt_config in business_types.items():
        headers.append(f"{bt_config['display_name']}_æ›¿æ›æ–¹æ¡ˆ")
        headers.append(f"{bt_config['display_name']}_æ›¿æ›çµæœ")
    
    # å¯«å…¥æ¨™é¡Œåˆ—
    for col_num, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col_num, value=header)
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = Alignment(horizontal="center", vertical="center")
        cell.border = thin_border
    
    # å¯«å…¥æ•¸æ“š
    for row_num, item in enumerate(detected_items, 2):
        col_num = 1
        
        # åŸºæœ¬è³‡è¨Š
        basic_data = [
            item['file_type'].upper(),
            str(item['file_path'].name),
            item['entry_id'],
            item['original_text'][:100] + "..." if len(item['original_text']) > 100 else item['original_text'],
            item['sensitive_word'],
            item['category']
        ]
        
        # å¯é¸æ·»åŠ åŒ¹é…ä½ç½®
        if add_position_column:
            match_pos = f"{item['match_positions'][0]}-{item['match_positions'][1]}" if 'match_positions' in item else ""
            basic_data.append(match_pos)
        
        for data in basic_data:
            cell = ws.cell(row=row_num, column=col_num, value=data)
            cell.font = data_font
            cell.border = thin_border
            cell.alignment = Alignment(horizontal="left", vertical="center")
            
            if row_num % 2 == 0:
                cell.fill = alt_row_fill
            
            col_num += 1
        
        # å„æ¥­æ…‹æ›¿æ›æ–¹æ¡ˆå’Œæ›¿æ›çµæœ
        for bt_code, bt_config in business_types.items():
            # æ›¿æ›æ–¹æ¡ˆåˆ—
            replacement = item['replacements'].get(bt_code, "")
            cell = ws.cell(row=row_num, column=col_num, value=replacement)
            cell.font = data_font
            cell.border = thin_border
            cell.alignment = Alignment(horizontal="left", vertical="center")
            
            if row_num % 2 == 0:
                cell.fill = alt_row_fill
            
            col_num += 1
            
            # æ›¿æ›çµæœåˆ—
            sensitive_word = item['sensitive_word']
            original_text = item['original_text']
            result_value = ""
            
            if replacement and replacement.strip():
                # ä½¿ç”¨ç²¾ç¢ºä½ç½®æ›¿æ›ï¼Œè€Œä¸æ˜¯ç°¡å–®çš„ replace
                if 'match_positions' in item:
                    start_pos, end_pos = item['match_positions']
                    predicted_result = original_text[:start_pos] + replacement + original_text[end_pos:]
                else:
                    # å¾Œå‚™æ–¹æ¡ˆï¼šä½¿ç”¨æ™®é€šæ›¿æ›
                    predicted_result = original_text.replace(sensitive_word, replacement)
                
                result_value = predicted_result
            
            cell = ws.cell(row=row_num, column=col_num, value=result_value)
            cell.font = data_font
            cell.border = thin_border
            cell.alignment = Alignment(horizontal="left", vertical="center")
            
            if result_value:
                edit_fill = PatternFill(start_color="FFFFCC", end_color="FFFFCC", fill_type="solid")
                cell.fill = edit_fill
            elif row_num % 2 == 0:
                cell.fill = alt_row_fill
            
            col_num += 1
    
    # è‡ªå‹•èª¿æ•´åˆ—å¯¬
    for col_idx in range(1, len(headers) + 1):
        column_letter = get_column_letter(col_idx)
        max_length = 0
        
        for row_idx in range(1, min(ws.max_row + 1, 100)):
            cell = ws.cell(row=row_idx, column=col_idx)
            if cell.value:
                cell_length = len(str(cell.value))
                if cell_length > max_length:
                    max_length = cell_length
        
        adjusted_width = min(max(max_length + 2, 10), 50)
        ws.column_dimensions[column_letter].width = adjusted_width
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æª”æ¡ˆ
    wb.save(output_file)
    
    print(f"   ğŸ“„ å·²ç”Ÿæˆï¼š{output_file.name} ({len(detected_items)} å€‹é …ç›®)")
    
    # è‡ªå‹•èª¿æ•´åˆ—å¯¬
    for col_idx in range(1, len(headers) + 1):
        column_letter = get_column_letter(col_idx)
        max_length = 0
        
        for row_idx in range(1, min(ws.max_row + 1, 100)):
            cell = ws.cell(row=row_idx, column=col_idx)
            if cell.value:
                cell_length = len(str(cell.value))
                if cell_length > max_length:
                    max_length = cell_length
        
        adjusted_width = min(max(max_length + 2, 10), 50)
        ws.column_dimensions[column_letter].width = adjusted_width
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æª”æ¡ˆ
    wb.save(output_file)
    
    print(f"   ğŸ“„ å·²ç”Ÿæˆï¼š{output_file.name} ({len(detected_items)} å€‹é …ç›®)")


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸ - ç°¡åŒ–è¼¸å‡ºç‰ˆæœ¬"""
    print("ğŸš€ é–‹å§‹ç”Ÿæˆå„èªè¨€ tobemodified æª”æ¡ˆ (åŒ…å®¹é—œä¿‚è™•ç†)")
    
    # è¼‰å…¥é…ç½®
    config = get_config()
    
    # æª¢æ¸¬å¯ç”¨èªè¨€
    available_languages = config.detect_available_languages()
    
    # å–å¾—çµ±ä¸€å°ç…§è¡¨è·¯å¾‘
    excel_path = config.get_comparison_excel_path()
    
    if not excel_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°å°ç…§è¡¨æª”æ¡ˆï¼š{excel_path}")
        print("   è«‹å…ˆåŸ·è¡Œ generate_phrase_comparison.py ç”Ÿæˆå°ç…§è¡¨")
        return
    
    # è§£æèªè¨€ç¨ç«‹æ©«å‘åˆ†å€å¡Š Excel
    try:
        language_blocks = parse_language_blocks_from_excel(excel_path, config)
    except Exception as e:
        print(f"âŒ è§£æ Excel æª”æ¡ˆå¤±æ•—ï¼š{e}")
        return
    
    if not language_blocks:
        print("âŒ Excel ä¸­æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„èªè¨€å€å¡Š")
        return
    
    # æª¢æŸ¥èªè¨€åŒ¹é…
    excel_languages = set(language_blocks.keys())
    input_languages = set(available_languages)
    
    common_languages = excel_languages & input_languages
    
    if not common_languages:
        print("âŒ æ²’æœ‰èªè¨€åŒæ™‚å­˜åœ¨æ–¼èªè¨€ç¨ç«‹ Excel å’Œè¼¸å…¥æª”æ¡ˆä¸­")
        print(f"   Excel ä¸­çš„èªè¨€ï¼š{list(excel_languages)}")
        print(f"   è¼¸å…¥æª”æ¡ˆèªè¨€ï¼š{list(input_languages)}")
        return
    
    print(f"âœ… å°‡è™•ç† {len(common_languages)} å€‹èªè¨€ï¼š{', '.join(sorted(common_languages))}")
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    try:
        if hasattr(config, 'get_output_dir'):
            output_dir = config.get_output_dir()
        elif hasattr(config, 'output_dir'):
            output_dir = config.output_dir
        elif hasattr(config, 'get_config'):
            config_data = config.get_config()
            output_dir = Path(config_data.get('output_dir', 'i18n_output'))
        else:
            output_dir = Path('i18n_output')
    except Exception as e:
        output_dir = Path('i18n_output')
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è™•ç†æ¯å€‹èªè¨€
    total_detected = 0
    processed_languages = 0
    
    for language in sorted(common_languages):
        print(f"\nğŸ“‹ è™•ç†èªè¨€ï¼š{language}")
        
        sensitive_words = language_blocks[language]
        
        # ä½¿ç”¨æ–°çš„å„ªå…ˆé †åºæª¢æ¸¬é‚è¼¯
        detected_items = detect_sensitive_phrases_in_files_with_priority(config, language, sensitive_words)
        total_detected += len(detected_items)
        
        # ç”Ÿæˆå¾…ä¿®æ­£æª”æ¡ˆ
        generate_tobemodified_excel(config, language, detected_items, output_dir)
        processed_languages += 1
    
    # ç”Ÿæˆç¸½çµå ±å‘Š
    print(f"\nğŸ“Š è™•ç†å®Œæˆï¼š")
    print(f"   è™•ç†èªè¨€ï¼š{processed_languages} å€‹")
    print(f"   æª¢æ¸¬é …ç›®ï¼š{total_detected} å€‹")
    print(f"   è¼¸å‡ºç›®éŒ„ï¼š{output_dir}")
    
    if total_detected > 0:
        print(f"\nâœ… å·²ç”Ÿæˆå¾…ä¿®æ­£æ¸…å–®ï¼Œè«‹æª¢æŸ¥ä¸¦ç·¨è¼¯å¾ŒåŸ·è¡Œ script_02_apply_fixes.py")
    else:
        print("âœ… æ‰€æœ‰èªè¨€éƒ½æ²’æœ‰æª¢æ¸¬åˆ°æ•æ„Ÿè©")


if __name__ == "__main__":
    main()