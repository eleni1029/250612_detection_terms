#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
script_01_generate_xlsx.py

æƒæ messages.po èˆ‡ zh-TW.jsonï¼Œåµæ¸¬æ­§ç¾©é—œéµå­—ï¼Œè¼¸å‡º tobemodified.xlsx
æ¬„ä½ï¼š
  â€¢ source / key / value
  â€¢ æ•æ„Ÿè©
  â€¢ ä¿®æ­£æ–¹æ¡ˆ(ä¼æ¥­) / ä¿®æ­£çµæœ(ä¼æ¥­)
  â€¢ ä¿®æ­£æ–¹æ¡ˆ(å…¬éƒ¨é–€) / ä¿®æ­£çµæœ(å…¬éƒ¨é–€)
  â€¢ ä¿®æ­£æ–¹æ¡ˆ(åŸ¹è¨“æ©Ÿæ§‹) / ä¿®æ­£çµæœ(åŸ¹è¨“æ©Ÿæ§‹)

æ”¹é€²é»ï¼š
1. ä¿®æ­£æª”åå¼•ç”¨éŒ¯èª¤
2. æ”¹é€²æ•æ„Ÿè©å°æ‡‰æ–¹æ¡ˆçš„é‚è¼¯
3. å¢åŠ éŒ¯èª¤è™•ç†å’Œæ—¥å¿—
4. å„ªåŒ–æ›¿æ›é‚è¼¯
5. å¢åŠ çµ±è¨ˆè³‡è¨Š
"""

# â”€â”€ StdLib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from pathlib import Path
import json
import re
import itertools
import sys
from collections import defaultdict

# â”€â”€ 3rd-party â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    import polib                       # pip install polib
    from openpyxl import Workbook      # pip install openpyxl
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install polib openpyxl")
    sys.exit(1)

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ç”Ÿæˆ tobemodified.xlsx")
    
    # â”€â”€ æª”æ¡ˆè·¯å¾‘æª¢æŸ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    PO_PATH = Path("messages.po")
    JSON_PATH = Path("zh-TW.json")
    OUT_XLSX = Path("tobemodified.xlsx")
    
    # â”€â”€ è¼‰å…¥å­—å…¸æª”æ¡ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def load_detection_terms():
        """è¼‰å…¥æ‰€æœ‰æª¢æ¸¬è©å…¸ï¼Œä¸¦é€²è¡ŒéŒ¯èª¤è™•ç†"""
        try:
            from detection_terms import DETECTION_TERMS
            # ä¿®æ­£ï¼šçµ±ä¸€æª”å
            from detection_terms_enterprises import DETECTION_TERMS as ENT_TERMS
            from detection_terms_public_sector import DETECTION_TERMS as GOV_TERMS
            from detection_terms_training_institutions import DETECTION_TERMS as EDU_TERMS
            
            print(f"âœ… æˆåŠŸè¼‰å…¥æª¢æ¸¬è©å…¸")
            print(f"   åŸºç¤æ•æ„Ÿè©: {len(DETECTION_TERMS)} é¡åˆ¥")
            print(f"   ä¼æ¥­æ–¹æ¡ˆ: {len(ENT_TERMS)} é¡åˆ¥")
            print(f"   å…¬éƒ¨é–€æ–¹æ¡ˆ: {len(GOV_TERMS)} é¡åˆ¥")
            print(f"   åŸ¹è¨“æ©Ÿæ§‹æ–¹æ¡ˆ: {len(EDU_TERMS)} é¡åˆ¥")
            
            return DETECTION_TERMS, ENT_TERMS, GOV_TERMS, EDU_TERMS
            
        except ImportError as e:
            print(f"âŒ ç„¡æ³•è¼‰å…¥æª¢æ¸¬è©å…¸ï¼š{e}")
            print("è«‹ç¢ºèªä»¥ä¸‹æª”æ¡ˆå­˜åœ¨ä¸”æ ¼å¼æ­£ç¢ºï¼š")
            print("  - detection_terms.py")
            print("  - detection_terms_enterprises.py") 
            print("  - detection_terms_public_sector.py")
            print("  - detection_terms_training_institutions.py")
            sys.exit(1)
    
    DETECTION_TERMS, ENT_TERMS, GOV_TERMS, EDU_TERMS = load_detection_terms()

    # â”€â”€ å»ºç«‹é—œéµå­—åˆ°åˆ†é¡çš„æ˜ å°„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ” å»ºç«‹é—œéµå­—æ˜ å°„...")
    kw2cat = {}
    category_stats = defaultdict(int)
    
    for cat, words in DETECTION_TERMS.items():
        for w in words:
            if w in kw2cat:
                print(f"âš ï¸  é‡è¤‡é—œéµå­— '{w}' åœ¨åˆ†é¡ '{cat}' å’Œ '{kw2cat[w]}'")
            kw2cat[w] = cat
            category_stats[cat] += 1
    
    print(f"   ç¸½é—œéµå­—æ•¸ï¼š{len(kw2cat)}")
    print(f"   åˆ†é¡çµ±è¨ˆï¼š{dict(category_stats)}")

    # â”€â”€ æ”¹é€²ï¼šå»ºç«‹æ•æ„Ÿè©åˆ°æ–¹æ¡ˆçš„æ˜ å°„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def build_keyword_to_solution_mapping(solution_terms: dict, solution_name: str):
        """
        å»ºç«‹å¾æ•æ„Ÿè©åˆ°è§£æ±ºæ–¹æ¡ˆçš„æ˜ å°„
        
        é‚è¼¯ï¼š
        1. å°æ¯å€‹æ•æ„Ÿè©ï¼Œæ‰¾åˆ°å…¶åˆ†é¡
        2. åœ¨è©²åˆ†é¡çš„è§£æ±ºæ–¹æ¡ˆä¸­æŒ‰ç´¢å¼•å°æ‡‰
        3. å¦‚æœæ²’æœ‰å°æ‡‰æ–¹æ¡ˆï¼Œä¿æŒåŸè©
        """
        keyword_to_solution = {}
        mapping_stats = {'mapped': 0, 'fallback': 0, 'missing_category': 0}
        
        for keyword, category in kw2cat.items():
            solutions = solution_terms.get(category, [])
            
            if not solutions:
                # è©²åˆ†é¡æ²’æœ‰è§£æ±ºæ–¹æ¡ˆ
                keyword_to_solution[keyword] = keyword
                mapping_stats['missing_category'] += 1
                continue
            
            # æ‰¾åˆ°è©²é—œéµå­—åœ¨åŸºç¤è©å…¸ä¸­çš„ç´¢å¼•
            base_keywords = DETECTION_TERMS.get(category, [])
            try:
                keyword_index = base_keywords.index(keyword)
                if keyword_index < len(solutions):
                    # æœ‰å°æ‡‰çš„è§£æ±ºæ–¹æ¡ˆ
                    keyword_to_solution[keyword] = solutions[keyword_index]
                    mapping_stats['mapped'] += 1
                else:
                    # ç´¢å¼•è¶…å‡ºæ–¹æ¡ˆç¯„åœ
                    keyword_to_solution[keyword] = keyword
                    mapping_stats['fallback'] += 1
            except ValueError:
                # é—œéµå­—ä¸åœ¨åŸºç¤è©å…¸ä¸­ï¼ˆç†è«–ä¸Šä¸æ‡‰è©²ç™¼ç”Ÿï¼‰
                keyword_to_solution[keyword] = keyword
                mapping_stats['fallback'] += 1
        
        print(f"   {solution_name}: {mapping_stats['mapped']} å€‹æœ‰æ–¹æ¡ˆ, {mapping_stats['fallback']} å€‹å›é€€, {mapping_stats['missing_category']} å€‹ç„¡åˆ†é¡æ–¹æ¡ˆ")
        return keyword_to_solution

    print("\nğŸ”„ å»ºç«‹æ•æ„Ÿè©åˆ°æ–¹æ¡ˆæ˜ å°„...")
    ENT_MAPPING = build_keyword_to_solution_mapping(ENT_TERMS, "ä¼æ¥­æ–¹æ¡ˆ")
    GOV_MAPPING = build_keyword_to_solution_mapping(GOV_TERMS, "å…¬éƒ¨é–€æ–¹æ¡ˆ")
    EDU_MAPPING = build_keyword_to_solution_mapping(EDU_TERMS, "åŸ¹è¨“æ©Ÿæ§‹æ–¹æ¡ˆ")

    # â”€â”€ æ”¹é€²ï¼šé—œéµå­—æª¢æ¸¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æŒ‰é•·åº¦æ’åºï¼Œå„ªå…ˆåŒ¹é…é•·è©é¿å…éƒ¨åˆ†åŒ¹é…å•é¡Œ
    _kw_sorted = sorted(kw2cat.keys(), key=len, reverse=True)
    KW_RE = re.compile("|".join(map(re.escape, _kw_sorted)))

    def find_keywords(text: str) -> list[str]:
        """åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°æ‰€æœ‰æ•æ„Ÿè©ï¼Œé¿å…é‡è¤‡"""
        if not text:
            return []
        
        seen = set()
        keywords = []
        for match in KW_RE.finditer(text):
            word = match.group(0)
            if word not in seen:
                seen.add(word)
                keywords.append(word)
        return keywords

    def apply_replacements(text: str, mapping: dict) -> str:
        """æ‡‰ç”¨é—œéµå­—æ›¿æ›"""
        if not text:
            return text
        return KW_RE.sub(lambda m: mapping.get(m.group(0), m.group(0)), text)

    def build_replacement_plan(keywords: list[str], mapping: dict) -> str:
        """å»ºç«‹æ›¿æ›æ–¹æ¡ˆèªªæ˜"""
        replacements = []
        for kw in keywords:
            replacement = mapping.get(kw, kw)
            if replacement != kw:
                replacements.append(f"{kw}â†’{replacement}")
        return "ã€".join(replacements)

    # â”€â”€ æ”¹é€²ï¼šæª”æ¡ˆè®€å–å‡½æ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def iter_po_entries(po_path: Path):
        """è¿­ä»£ PO æª”æ¡ˆæ¢ç›®ï¼Œå¢åŠ éŒ¯èª¤è™•ç†"""
        if not po_path.exists():
            print(f"âš ï¸  {po_path} ä¸å­˜åœ¨ï¼Œè·³é")
            return
        
        try:
            po_file = polib.pofile(str(po_path))
            count = 0
            for entry in po_file:
                msgid = entry.msgid or ""
                msgstr = entry.msgstr or ""
                yield ("po", msgid, msgstr)
                count += 1
            print(f"   PO æª”æ¡ˆ: {count} å€‹æ¢ç›®")
        except Exception as e:
            print(f"âŒ è®€å– {po_path} å¤±æ•—ï¼š{e}")

    def iter_json_entries(json_path: Path):
        """è¿­ä»£ JSON æª”æ¡ˆæ¢ç›®ï¼Œæ”¹é€²è·¯å¾‘è¡¨ç¤º"""
        if not json_path.exists():
            print(f"âš ï¸  {json_path} ä¸å­˜åœ¨ï¼Œè·³é")
            return
        
        try:
            data = json.loads(json_path.read_text("utf-8"))
            
            def walk_json(node, path=""):
                """éè¿´éæ­· JSON çµæ§‹"""
                if isinstance(node, dict):
                    for key, value in node.items():
                        new_path = f"{path}.{key}" if path else key
                        yield from walk_json(value, new_path)
                elif isinstance(node, list):
                    for index, value in enumerate(node):
                        new_path = f"{path}[{index}]"
                        yield from walk_json(value, new_path)
                else:
                    yield ("json", path, str(node))
            
            count = 0
            for entry in walk_json(data):
                yield entry
                count += 1
            print(f"   JSON æª”æ¡ˆ: {count} å€‹æ¢ç›®")
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON æ ¼å¼éŒ¯èª¤ï¼š{e}")
        except Exception as e:
            print(f"âŒ è®€å– {json_path} å¤±æ•—ï¼š{e}")

    # â”€â”€ æƒææª”æ¡ˆä¸¦æ”¶é›†è³‡æ–™ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ“– æƒææª”æ¡ˆ...")
    rows = []
    detection_stats = defaultdict(int)

    for source, key, value in itertools.chain(
        iter_po_entries(PO_PATH),
        iter_json_entries(JSON_PATH)
    ):
        # å¦‚æœ value ç‚ºç©ºï¼Œä½¿ç”¨ key
        display_value = value if value else key
        
        # æª¢æ¸¬ key å’Œ value ä¸­çš„æ•æ„Ÿè©
        key_keywords = find_keywords(key)
        value_keywords = find_keywords(display_value)
        
        # åˆä½µé—œéµå­—ï¼Œé¿å…é‡è¤‡
        all_keywords = key_keywords + [kw for kw in value_keywords if kw not in key_keywords]
        
        if all_keywords:
            detection_stats[source] += 1
            detection_stats['total_entries'] += 1
            
            # å»ºç«‹ä¿®æ­£æ–¹æ¡ˆå’Œçµæœ
            rows.append([
                source,
                key,
                display_value,
                "ã€".join(all_keywords),  # æ•æ„Ÿè©åˆ—è¡¨
                build_replacement_plan(all_keywords, ENT_MAPPING),  # ä¼æ¥­ä¿®æ­£æ–¹æ¡ˆ
                apply_replacements(display_value, ENT_MAPPING),     # ä¼æ¥­ä¿®æ­£çµæœ
                build_replacement_plan(all_keywords, GOV_MAPPING),  # å…¬éƒ¨é–€ä¿®æ­£æ–¹æ¡ˆ
                apply_replacements(display_value, GOV_MAPPING),     # å…¬éƒ¨é–€ä¿®æ­£çµæœ
                build_replacement_plan(all_keywords, EDU_MAPPING),  # åŸ¹è¨“æ©Ÿæ§‹ä¿®æ­£æ–¹æ¡ˆ
                apply_replacements(display_value, EDU_MAPPING),     # åŸ¹è¨“æ©Ÿæ§‹ä¿®æ­£çµæœ
            ])

    print(f"   æª¢æ¸¬çµ±è¨ˆï¼š{dict(detection_stats)}")

    if not rows:
        print("âœ… æœªåµæ¸¬åˆ°æ­§ç¾©è©ï¼Œæœªç”¢ç”Ÿ xlsx")
        return

    # â”€â”€ è¼¸å‡º Excel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ“ ç”Ÿæˆ Excel æª”æ¡ˆ...")
    
    try:
        wb = Workbook()
        ws = wb.active
        ws.title = "tobemodified"
        
        # æ¨™é¡Œåˆ—
        headers = [
            "source", "key", "value", "æ•æ„Ÿè©",
            "ä¿®æ­£æ–¹æ¡ˆ(ä¼æ¥­)", "ä¿®æ­£çµæœ(ä¼æ¥­)",
            "ä¿®æ­£æ–¹æ¡ˆ(å…¬éƒ¨é–€)", "ä¿®æ­£çµæœ(å…¬éƒ¨é–€)",
            "ä¿®æ­£æ–¹æ¡ˆ(åŸ¹è¨“æ©Ÿæ§‹)", "ä¿®æ­£çµæœ(åŸ¹è¨“æ©Ÿæ§‹)"
        ]
        ws.append(headers)

        # è³‡æ–™åˆ—
        for row in rows:
            ws.append(row)

        # è‡ªå‹•èª¿æ•´æ¬„å¯¬
        for col in ws.columns:
            max_length = 0
            column_letter = col[0].column_letter
            
            for cell in col:
                try:
                    cell_length = len(str(cell.value or ""))
                    if cell_length > max_length:
                        max_length = cell_length
                except:
                    pass
            
            # è¨­å®šæ¬„å¯¬ï¼Œæœ€å°10ï¼Œæœ€å¤§80
            adjusted_width = min(max(max_length + 4, 10), 80)
            ws.column_dimensions[column_letter].width = adjusted_width

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        OUT_XLSX.parent.mkdir(exist_ok=True)
        wb.save(OUT_XLSX)
        
        print(f"âœ… å·²è¼¸å‡º {OUT_XLSX.resolve()}")
        print(f"ğŸ“„ æª”æ¡ˆå¤§å°ï¼š{OUT_XLSX.stat().st_size / 1024:.1f} KB")
        print(f"ğŸ“Š ç¸½å…±è™•ç†ï¼š{len(rows)} å€‹åŒ…å«æ•æ„Ÿè©çš„æ¢ç›®")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆ Excel æª”æ¡ˆå¤±æ•—ï¼š{e}")
        sys.exit(1)

    # â”€â”€ ç”Ÿæˆçµ±è¨ˆå ±å‘Š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ“ˆ è™•ç†å ±å‘Šï¼š")
    
    # çµ±è¨ˆå„åˆ†é¡çš„æ•æ„Ÿè©å‡ºç¾æ¬¡æ•¸
    category_detections = defaultdict(int)
    keyword_detections = defaultdict(int)
    
    for row in rows:
        keywords = row[3].split("ã€") if row[3] else []
        for kw in keywords:
            if kw in kw2cat:
                category_detections[kw2cat[kw]] += 1
                keyword_detections[kw] += 1
    
    print(f"   æœ€å¸¸å‡ºç¾çš„åˆ†é¡ï¼š")
    for cat, count in sorted(category_detections.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"     {cat}: {count} æ¬¡")
    
    print(f"   æœ€å¸¸å‡ºç¾çš„æ•æ„Ÿè©ï¼š")
    for kw, count in sorted(keyword_detections.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"     {kw}: {count} æ¬¡")


if __name__ == "__main__":
    main()