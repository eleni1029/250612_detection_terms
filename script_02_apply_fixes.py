#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
script_02_apply_fixes.py

ä¾æ“š tobemodified.xlsxï¼ŒæŠŠã€Œä¿®æ­£çµæœã€å¯«å›ç¿»è­¯æª”ã€‚
æ”¹é€²é»ï¼šä¿®æ­£æª”åå¾Œç¶´ä¸€è‡´æ€§ã€å¢åŠ æ—¥èªŒè¨˜éŒ„ã€ç°¡åŒ–çµ‚ç«¯è¼¸å‡º
"""

from pathlib import Path
import json
import sys
import shutil
import re
import datetime
from collections import defaultdict

try:
    import openpyxl
    import polib
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install openpyxl polib")
    sys.exit(1)


def main():
    print("ğŸš€ é–‹å§‹å¥—ç”¨ä¿®æ­£çµæœ")
    
    backup_dir = Path("backup")
    backup_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = backup_dir / f"apply_fixes_{timestamp}.log"
    
    def log_detail(message: str):
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"{datetime.datetime.now().strftime('%H:%M:%S')} - {message}\n")

    ORIG_PO = Path("messages.po")
    ORIG_JSON = Path("zh-TW.json")
    XLSX = Path("tobemodified.xlsx")
    
    missing_files = []
    if not ORIG_PO.exists():
        missing_files.append(str(ORIG_PO))
    if not ORIG_JSON.exists():
        missing_files.append(str(ORIG_JSON))
    if not XLSX.exists():
        missing_files.append(str(XLSX))
    
    if missing_files:
        print(f"âŒ æ‰¾ä¸åˆ°å¿…è¦æª”æ¡ˆï¼š{', '.join(missing_files)}")
        if str(XLSX) in missing_files:
            print("è«‹å…ˆåŸ·è¡Œ script_01_generate_xlsx.py ç”Ÿæˆ tobemodified.xlsx")
        sys.exit(1)

    DOMAINS = {
        "ä¼æ¥­": {
            "suffix": "_enterprises",
            "xlsx_col": "ä¿®æ­£çµæœ(ä¼æ¥­)",
        },
        "å…¬éƒ¨é–€": {
            "suffix": "_public_sector",
            "xlsx_col": "ä¿®æ­£çµæœ(å…¬éƒ¨é–€)",
        },
        "åŸ¹è¨“æ©Ÿæ§‹": {
            "suffix": "_training_institutions",
            "xlsx_col": "ä¿®æ­£çµæœ(åŸ¹è¨“æ©Ÿæ§‹)",
        },
    }

    def choose_domain() -> list[str]:
        cli_arg = (sys.argv[1] if len(sys.argv) > 1 else "").strip()
        
        if cli_arg:
            if cli_arg == "å…¨éƒ¨":
                return list(DOMAINS.keys())
            if cli_arg in DOMAINS:
                return [cli_arg]
            print(f"âŒ ç„¡æ•ˆçš„åƒæ•¸ï¼š{cli_arg}")
            print("æœ‰æ•ˆåƒæ•¸ï¼šä¼æ¥­ / å…¬éƒ¨é–€ / åŸ¹è¨“æ©Ÿæ§‹ / å…¨éƒ¨")
            sys.exit(1)
        
        print("\nè«‹é¸æ“‡è¦å¥—ç”¨ä¿®æ­£çš„æ¥­æ…‹ï¼š")
        print("  1) ä¼æ¥­")
        print("  2) å…¬éƒ¨é–€") 
        print("  3) åŸ¹è¨“æ©Ÿæ§‹")
        print("  4) å…¨éƒ¨")
        
        mapping = {"1": "ä¼æ¥­", "2": "å…¬éƒ¨é–€", "3": "åŸ¹è¨“æ©Ÿæ§‹", "4": "å…¨éƒ¨"}
        
        while True:
            try:
                opt = input("\nè¼¸å…¥é¸é … (1-4)ï¼š").strip()
                if opt in mapping:
                    selected = mapping[opt]
                    if selected == "å…¨éƒ¨":
                        return list(DOMAINS.keys())
                    return [selected]
                print("âš ï¸  è«‹è¼¸å…¥ 1-4 ä¹‹é–“çš„æ•¸å­—")
            except KeyboardInterrupt:
                print("\nâŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                sys.exit(0)

    targets = choose_domain()
    print(f"\nğŸ‘‰ å°‡å¥—ç”¨è‡³ï¼š{', '.join(targets)}")

    # é å…ˆå‚™ä»½ç¾æœ‰çš„ç›®æ¨™æª”æ¡ˆ
    def backup_existing_files():
        print(f"ğŸ” æª¢æŸ¥ä¸¦å‚™ä»½ç¾æœ‰æª”æ¡ˆ...")
        backup_count = 0
        
        for domain in targets:
            suffix = DOMAINS[domain]["suffix"]
            po_target = ORIG_PO.with_name(f"{ORIG_PO.stem}{suffix}.po")
            json_target = ORIG_JSON.with_name(f"{ORIG_JSON.stem}{suffix}.json")
            
            # å‚™ä»½ PO æª”æ¡ˆ
            if po_target.exists():
                backup_filename = f"{po_target.stem}_{timestamp}{po_target.suffix}"
                backup_path = backup_dir / backup_filename
                shutil.copy2(po_target, backup_path)
                log_detail(f"é å‚™ä»½ç¾æœ‰æª”æ¡ˆ: {po_target.name} â†’ backup/{backup_path.name}")
                backup_count += 1
            
            # å‚™ä»½ JSON æª”æ¡ˆ
            if json_target.exists():
                backup_filename = f"{json_target.stem}_{timestamp}{json_target.suffix}"
                backup_path = backup_dir / backup_filename
                shutil.copy2(json_target, backup_path)
                log_detail(f"é å‚™ä»½ç¾æœ‰æª”æ¡ˆ: {json_target.name} â†’ backup/{backup_path.name}")
                backup_count += 1
        
        if backup_count > 0:
            print(f"âœ… å·²å‚™ä»½ {backup_count} å€‹ç¾æœ‰æª”æ¡ˆåˆ° backup/")
            log_detail(f"é å‚™ä»½å®Œæˆï¼Œå…±å‚™ä»½ {backup_count} å€‹ç¾æœ‰æª”æ¡ˆ")
        else:
            print(f"â„¹ï¸  ç„¡ç¾æœ‰ç›®æ¨™æª”æ¡ˆéœ€è¦å‚™ä»½")
            log_detail("ç„¡ç¾æœ‰ç›®æ¨™æª”æ¡ˆéœ€è¦å‚™ä»½")

    backup_existing_files()

    def read_and_validate_xlsx():
        try:
            print(f"ğŸ“– è®€å– {XLSX}...")
            log_detail(f"é–‹å§‹è®€å– Excel æª”æ¡ˆ: {XLSX}")
            wb = openpyxl.load_workbook(XLSX, data_only=True)
            ws = wb.active
            
            header_row = list(ws[1])
            header = {cell.value: idx for idx, cell in enumerate(header_row) if cell.value}
            
            log_detail(f"ç™¼ç¾æ¬„ä½: {list(header.keys())}")
            
            required_columns = ["source", "key", "value"]
            missing_columns = []
            
            for col in required_columns:
                if col not in header:
                    missing_columns.append(col)
            
            for domain in targets:
                col_name = DOMAINS[domain]["xlsx_col"]
                if col_name not in header:
                    missing_columns.append(col_name)
            
            if missing_columns:
                error_msg = f"Excel ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}"
                print(f"âŒ {error_msg}")
                log_detail(f"éŒ¯èª¤: {error_msg}")
                sys.exit(1)
            
            return wb, ws, header
            
        except Exception as e:
            error_msg = f"è®€å– Excel æª”æ¡ˆå¤±æ•—ï¼š{e}"
            print(f"âŒ {error_msg}")
            log_detail(f"éŒ¯èª¤: {error_msg}")
            sys.exit(1)

    wb, ws, header = read_and_validate_xlsx()

    def get_column_index(name: str) -> int:
        if name not in header:
            raise KeyError(f"Excel ç¼ºå°‘æ¬„ä½ï¼š{name}")
        return header[name]

    print(f"ğŸ” è§£æä¿®æ­£è³‡æ–™...")
    log_detail("é–‹å§‹è§£æ Excel ä¿®æ­£è³‡æ–™")
    updates = {domain: {"po": [], "json": []} for domain in targets}
    stats = defaultdict(int)

    for row_num, row in enumerate(ws.iter_rows(min_row=2, values_only=True), start=2):
        if not row or len(row) <= max(header.values()):
            continue
        
        try:
            source = row[get_column_index("source")]
            key = row[get_column_index("key")]
            
            if not source or not key:
                continue
            
            stats['total_rows'] += 1
            
            for domain in targets:
                col_name = DOMAINS[domain]["xlsx_col"]
                new_value = row[get_column_index(col_name)]
                
                if not (isinstance(new_value, str) and new_value.strip()):
                    continue
                
                new_value = new_value.strip()
                stats[f'{domain}_updates'] += 1
                
                if source == "po":
                    updates[domain]["po"].append((key, new_value))
                    log_detail(f"PO æ›´æ–° - {domain}: {key} â†’ {new_value}")
                elif source == "json":
                    updates[domain]["json"].append((key, new_value))
                    log_detail(f"JSON æ›´æ–° - {domain}: {key} â†’ {new_value}")
                else:
                    log_detail(f"è­¦å‘Š: ç¬¬ {row_num} è¡ŒæœªçŸ¥çš„ source é¡å‹ '{source}'")
            
        except Exception as e:
            log_detail(f"éŒ¯èª¤: ç¬¬ {row_num} è¡Œè™•ç†å¤±æ•—: {e}")
            continue

    print(f"âœ… è§£æå®Œæˆ - ç¸½è¡Œæ•¸: {stats['total_rows']}")
    for domain in targets:
        update_count = stats[f'{domain}_updates']
        print(f"   {domain}: {update_count} å€‹æ›´æ–°")
    
    log_detail(f"è§£æå®Œæˆçµ±è¨ˆ: {dict(stats)}")

    def create_backup_and_copy(src: Path, dest: Path) -> bool:
        try:
            if dest.exists():
                backup_filename = f"{dest.stem}_{timestamp}{dest.suffix}"
                backup_path = backup_dir / backup_filename
                
                shutil.copy2(dest, backup_path)
                log_detail(f"å‚™ä»½: {dest.name} â†’ backup/{backup_path.name}")
            
            shutil.copy2(src, dest)
            log_detail(f"è¤‡è£½: {src.name} â†’ {dest.name}")
            return True
            
        except Exception as e:
            error_msg = f"è¤‡è£½å¤±æ•—: {e}"
            log_detail(f"éŒ¯èª¤: {error_msg}")
            return False

    def update_po_file(po_path: Path, updates_list: list[tuple[str, str]]) -> dict:
        result = {"success": False, "updated": 0, "errors": []}
        
        if not updates_list:
            result["success"] = True
            return result
        
        try:
            log_detail(f"é–‹å§‹æ›´æ–° PO æª”æ¡ˆ: {po_path.name}")
            po_file = polib.pofile(str(po_path))
            
            for msgid, new_msgstr in updates_list:
                entry = po_file.find(msgid)
                if entry:
                    if entry.msgstr != new_msgstr:
                        old_value = entry.msgstr
                        entry.msgstr = new_msgstr
                        result["updated"] += 1
                        log_detail(f"PO æ›´æ–°: '{msgid}' å¾ '{old_value}' æ”¹ç‚º '{new_msgstr}'")
                else:
                    error_msg = f"æ‰¾ä¸åˆ°æ¢ç›®ï¼š{msgid}"
                    result["errors"].append(error_msg)
                    log_detail(f"PO éŒ¯èª¤: {error_msg}")
            
            if result["updated"] > 0:
                po_file.save(str(po_path))
                log_detail(f"PO æª”æ¡ˆå·²å„²å­˜: {po_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
            
            result["success"] = True
            
        except Exception as e:
            error_msg = f"PO æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
            result["errors"].append(error_msg)
            log_detail(f"PO éŒ¯èª¤: {error_msg}")
        
        return result

    def parse_json_path(path: str) -> list:
        parts = []
        current = ""
        in_bracket = False
        
        for char in path:
            if char == '[':
                if current:
                    parts.append(('key', current))
                    current = ""
                in_bracket = True
            elif char == ']':
                if in_bracket and current:
                    try:
                        parts.append(('index', int(current)))
                    except ValueError:
                        raise ValueError(f"ç„¡æ•ˆçš„é™£åˆ—ç´¢å¼•ï¼š{current}")
                    current = ""
                in_bracket = False
            elif char == '.' and not in_bracket:
                if current:
                    parts.append(('key', current))
                    current = ""
            else:
                current += char
        
        if current:
            parts.append(('key', current))
        
        return parts

    def set_json_value_by_path(data: dict, path: str, new_value: str) -> bool:
        try:
            path_parts = parse_json_path(path)
            current = data
            
            for i, (part_type, part_value) in enumerate(path_parts):
                is_last = (i == len(path_parts) - 1)
                
                if part_type == 'key':
                    if is_last:
                        current[part_value] = new_value
                    else:
                        if part_value not in current:
                            next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                            current[part_value] = [] if next_part_type == 'index' else {}
                        current = current[part_value]
                
                elif part_type == 'index':
                    if is_last:
                        while len(current) <= part_value:
                            current.append(None)
                        current[part_value] = new_value
                    else:
                        while len(current) <= part_value:
                            current.append(None)
                        if current[part_value] is None:
                            next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                            current[part_value] = [] if next_part_type == 'index' else {}
                        current = current[part_value]
            
            return True
            
        except Exception as e:
            log_detail(f"JSON è·¯å¾‘è§£æå¤±æ•— '{path}': {e}")
            return False

    def update_json_file(json_path: Path, updates_list: list[tuple[str, str]]) -> dict:
        result = {"success": False, "updated": 0, "errors": []}
        
        if not updates_list:
            result["success"] = True
            return result
        
        try:
            log_detail(f"é–‹å§‹æ›´æ–° JSON æª”æ¡ˆ: {json_path.name}")
            
            data = json.loads(json_path.read_text(encoding="utf-8"))
            
            for json_path_str, new_value in updates_list:
                if set_json_value_by_path(data, json_path_str, new_value):
                    result["updated"] += 1
                    log_detail(f"JSON æ›´æ–°: '{json_path_str}' â†’ '{new_value}'")
                else:
                    error_msg = f"ç„¡æ³•æ›´æ–°è·¯å¾‘ï¼š{json_path_str}"
                    result["errors"].append(error_msg)
                    log_detail(f"JSON éŒ¯èª¤: {error_msg}")
            
            if result["updated"] > 0:
                json_content = json.dumps(data, ensure_ascii=False, indent=2)
                json_path.write_text(json_content, encoding="utf-8")
                log_detail(f"JSON æª”æ¡ˆå·²å„²å­˜: {json_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
            
            result["success"] = True
            
        except json.JSONDecodeError as e:
            error_msg = f"JSON æ ¼å¼éŒ¯èª¤ï¼š{e}"
            result["errors"].append(error_msg)
            log_detail(f"JSON éŒ¯èª¤: {error_msg}")
        except Exception as e:
            error_msg = f"JSON æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
            result["errors"].append(error_msg)
            log_detail(f"JSON éŒ¯èª¤: {error_msg}")
        
        return result

    results = {}
    
    for domain in targets:
        suffix = DOMAINS[domain]["suffix"]
        po_dest = ORIG_PO.with_name(f"{ORIG_PO.stem}{suffix}.po")
        json_dest = ORIG_JSON.with_name(f"{ORIG_JSON.stem}{suffix}.json")

        print(f"\nğŸ“ è™•ç† {domain}...")
        log_detail(f"é–‹å§‹è™•ç†æ¥­æ…‹: {domain}")
        
        domain_result = {
            "po_file": str(po_dest),
            "json_file": str(json_dest),
            "po_result": {"success": False, "updated": 0, "errors": []},
            "json_result": {"success": False, "updated": 0, "errors": []}
        }
        
        po_copy_success = create_backup_and_copy(ORIG_PO, po_dest)
        json_copy_success = create_backup_and_copy(ORIG_JSON, json_dest)
        
        if not (po_copy_success and json_copy_success):
            error_msg = f"{domain} æª”æ¡ˆè¤‡è£½å¤±æ•—ï¼Œè·³éè™•ç†"
            print(f"  âŒ {error_msg}")
            log_detail(f"éŒ¯èª¤: {error_msg}")
            results[domain] = domain_result
            continue
        
        domain_result["po_result"] = update_po_file(po_dest, updates[domain]["po"])
        domain_result["json_result"] = update_json_file(json_dest, updates[domain]["json"])
        
        results[domain] = domain_result
        
        print(f"  âœ… å®Œæˆ - PO: {domain_result['po_result']['updated']} å€‹, JSON: {domain_result['json_result']['updated']} å€‹")
        
        log_detail(f"{domain} è™•ç†å®Œæˆ: PO æ›´æ–° {domain_result['po_result']['updated']} å€‹, JSON æ›´æ–° {domain_result['json_result']['updated']} å€‹")

    print(f"\nğŸ‰ è™•ç†å®Œç•¢ï¼")
    
    all_success = True
    total_updates = 0
    
    for domain, result in results.items():
        po_updated = result["po_result"]["updated"]
        json_updated = result["json_result"]["updated"]
        domain_total = po_updated + json_updated
        total_updates += domain_total
        
        po_success = result["po_result"]["success"]
        json_success = result["json_result"]["success"]
        domain_success = po_success and json_success
        
        if not domain_success:
            all_success = False
        
        status_icon = "âœ…" if domain_success else "âŒ"
        print(f"{status_icon} {domain}: {domain_total} å€‹æ›´æ–° ({result['po_file']}, {result['json_file']})")
        
        log_detail(f"æœ€çµ‚çµæœ - {domain}: PO={po_updated}, JSON={json_updated}, æˆåŠŸ={domain_success}")
        
        all_errors = result["po_result"]["errors"] + result["json_result"]["errors"]
        if all_errors:
            for error in all_errors:
                log_detail(f"éŒ¯èª¤è©³æƒ… - {domain}: {error}")
    
    print(f"\nğŸ“Š ç¸½è¨ˆ: {total_updates} å€‹æ›´æ–°ï¼Œç‹€æ…‹: {'âœ… æˆåŠŸ' if all_success else 'âš ï¸ éƒ¨åˆ†å¤±æ•—'}")
    print(f"ğŸ“„ è©³ç´°æ—¥èªŒ: {log_file}")
    
    log_detail(f"è™•ç†å®Œæˆ - ç¸½æ›´æ–°: {total_updates}, æ•´é«”æˆåŠŸ: {all_success}")
    
    if not all_success:
        sys.exit(1)


if __name__ == "__main__":
    main()