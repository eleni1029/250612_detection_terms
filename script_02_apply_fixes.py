#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
script_02_apply_fixes.py (v2.1 - Pure Excel Version)

ä¾æ“š tobemodified.xlsxï¼ŒæŠŠã€Œä¿®æ­£çµæœã€å¯«å›ç¿»è­¯æª”ã€‚
å®Œå…¨åŸºæ–¼ Excel æª”æ¡ˆï¼Œä¸å†ä¾è³´ä»»ä½• Python å­—å…¸æª”æ¡ˆã€‚

æ›´æ–°å…§å®¹ï¼š
- å®Œå…¨ç§»é™¤å° detection_terms.py çš„ä¾è³´
- å®Œå…¨åŸºæ–¼ Excel æª”æ¡ˆçš„å·¥ä½œæµç¨‹
- ç°¡åŒ–é…ç½®å’Œé‚è¼¯
- æ›´ç›´è§€çš„ç´” Excel æ–¹æ¡ˆ
"""

from pathlib import Path
import json
import sys
import shutil
import re
import datetime
import argparse
import glob
from collections import defaultdict
from config_loader import get_config

try:
    import openpyxl
    import polib
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install openpyxl polib")
    sys.exit(1)


def main():
    print("ğŸš€ é–‹å§‹å¥—ç”¨ä¿®æ­£çµæœ (v2.1 - Pure Excel Version)")
    print("ğŸ“Š å®Œå…¨åŸºæ–¼ Excel çš„ä¿®æ­£å¥—ç”¨ç³»çµ±")
    
    # è¼‰å…¥é…ç½®
    config = get_config()
    config.print_config_summary()
    
    # è¨­ç½®å‚™ä»½ç›®éŒ„
    backup_config = config.config.get('system', {}).get('backup', {})
    backup_dir = Path(config.get_base_files()['backup_dir'])
    backup_dir.mkdir(exist_ok=True)
    
    timestamp_format = backup_config.get('timestamp_format', '%Y%m%d_%H%M%S')
    timestamp = datetime.datetime.now().strftime(timestamp_format)
    log_file = backup_dir / f"apply_fixes_{timestamp}.log"
    
    def log_detail(message: str):
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"{datetime.datetime.now().strftime('%H:%M:%S')} - {message}\n")

    # è™•ç†å‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser(description='å¥—ç”¨æ•æ„Ÿè©ä¿®æ­£çµæœ')
    parser.add_argument('--language', '-l', 
                       choices=list(config.get_languages().keys()),
                       help='æŒ‡å®šè¦è™•ç†çš„èªè¨€ (è‹¥æœªæŒ‡å®šå°‡è‡ªå‹•æª¢æ¸¬)')
    parser.add_argument('--business-types', '-b',
                       nargs='+',
                       choices=list(config.get_business_types().keys()) + ['all'],
                       help='æŒ‡å®šè¦è™•ç†çš„æ¥­æ…‹ (å¯å¤šé¸ï¼Œæˆ–ä½¿ç”¨ all)')
    
    args = parser.parse_args()

    # è‡ªå‹•æª¢æ¸¬æˆ–é¸æ“‡èªè¨€
    def detect_or_choose_language():
        """æª¢æ¸¬æˆ–é¸æ“‡è¦è™•ç†çš„èªè¨€"""
        if args.language:
            return args.language
        
        # è‡ªå‹•æª¢æ¸¬ tobemodified æª”æ¡ˆ
        available_languages = config.get_languages()
        found_files = []
        
        output_template = config.config.get('file_generation', {}).get('tobemodified_template', 'tobemodified_{language}.xlsx')
        
        for lang_code in available_languages.keys():
            xlsx_file = Path(output_template.format(language=lang_code))
            if xlsx_file.exists():
                found_files.append((lang_code, xlsx_file))
        
        if not found_files:
            # æª¢æŸ¥æ˜¯å¦æœ‰é è¨­æª”æ¡ˆ
            default_xlsx = Path("tobemodified.xlsx")
            if default_xlsx.exists():
                default_lang = config.get_default_language()
                print(f"ğŸ” æ‰¾åˆ° tobemodified.xlsxï¼Œå‡è¨­ç‚º {default_lang} èªè¨€")
                return default_lang, default_xlsx
            
            print("âŒ æ‰¾ä¸åˆ°ä»»ä½• tobemodified æª”æ¡ˆ")
            print("è«‹å…ˆåŸ·è¡Œ script_01_generate_xlsx.py ç”Ÿæˆæª”æ¡ˆ")
            sys.exit(1)
        
        if len(found_files) == 1:
            lang_code, xlsx_file = found_files[0]
            print(f"ğŸ” è‡ªå‹•æª¢æ¸¬åˆ°èªè¨€ï¼š{lang_code} ({xlsx_file})")
            return lang_code, xlsx_file
        
        # å¤šå€‹æª”æ¡ˆï¼Œè®“ä½¿ç”¨è€…é¸æ“‡
        print("\nğŸŒ ç™¼ç¾å¤šå€‹èªè¨€çš„ tobemodified æª”æ¡ˆï¼š")
        for i, (lang_code, xlsx_file) in enumerate(found_files, 1):
            lang_name = available_languages[lang_code].get('description', lang_code)
            print(f"  {i}) {lang_code} - {lang_name} ({xlsx_file})")
        
        while True:
            try:
                choice = input(f"\nè«‹é¸æ“‡èªè¨€ (1-{len(found_files)})ï¼š").strip()
                idx = int(choice) - 1
                if 0 <= idx < len(found_files):
                    lang_code, xlsx_file = found_files[idx]
                    print(f"âœ… é¸æ“‡äº† {lang_code}")
                    return lang_code, xlsx_file
                else:
                    print(f"âš ï¸  è«‹è¼¸å…¥ 1-{len(found_files)} ä¹‹é–“çš„æ•¸å­—")
            except (ValueError, KeyboardInterrupt):
                print("\nâŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                sys.exit(0)

    # é¸æ“‡æˆ–æª¢æ¸¬èªè¨€
    if args.language:
        selected_language = args.language
        output_template = config.config.get('file_generation', {}).get('tobemodified_template', 'tobemodified_{language}.xlsx')
        XLSX = Path(output_template.format(language=selected_language))
        if not XLSX.exists():
            # å˜—è©¦é è¨­æª”å
            XLSX = Path("tobemodified.xlsx")
            if not XLSX.exists():
                print(f"âŒ æ‰¾ä¸åˆ° {selected_language} èªè¨€çš„ tobemodified æª”æ¡ˆ")
                sys.exit(1)
    else:
        selected_language, XLSX = detect_or_choose_language()

    print(f"\nğŸŒ è™•ç†èªè¨€ï¼š{selected_language}")
    print(f"ğŸ“„ Excel æª”æ¡ˆï¼š{XLSX}")

    # ç²å–èªè¨€æª”æ¡ˆ
    language_files = config.get_language_files(selected_language)
    ORIG_PO = Path(language_files['po_file'])
    ORIG_JSON = Path(language_files['json_file'])

    # æª¢æŸ¥å¿…è¦æª”æ¡ˆ
    missing_files = []
    if not ORIG_PO.exists():
        missing_files.append(str(ORIG_PO))
    if not ORIG_JSON.exists():
        missing_files.append(str(ORIG_JSON))
    if not XLSX.exists():
        missing_files.append(str(XLSX))
    
    if missing_files:
        print(f"âŒ æ‰¾ä¸åˆ°å¿…è¦æª”æ¡ˆï¼š{', '.join(missing_files)}")
        sys.exit(1)

    # æ¥­æ…‹é¸æ“‡
    def choose_business_types():
        """é¸æ“‡è¦è™•ç†çš„æ¥­æ…‹"""
        if args.business_types:
            if 'all' in args.business_types:
                return list(config.get_business_types().keys())
            return args.business_types
        
        # äº’å‹•å¼é¸æ“‡
        business_types = config.get_business_types()
        choices = list(business_types.items())
        
        print("\nè«‹é¸æ“‡è¦å¥—ç”¨ä¿®æ­£çš„æ¥­æ…‹ï¼š")
        for i, (bt_code, bt_config) in enumerate(choices, 1):
            print(f"  {i}) {bt_config['display_name']}")
        print(f"  {len(choices) + 1}) å…¨éƒ¨")
        
        while True:
            try:
                opt = input(f"\nè¼¸å…¥é¸é … (1-{len(choices) + 1})ï¼š").strip()
                choice_idx = int(opt) - 1
                
                if choice_idx == len(choices):  # å…¨éƒ¨
                    return list(business_types.keys())
                elif 0 <= choice_idx < len(choices):
                    bt_code = choices[choice_idx][0]
                    return [bt_code]
                else:
                    print(f"âš ï¸  è«‹è¼¸å…¥ 1-{len(choices) + 1} ä¹‹é–“çš„æ•¸å­—")
            except (ValueError, KeyboardInterrupt):
                print("\nâŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
                sys.exit(0)

    target_business_types = choose_business_types()
    business_types = config.get_business_types()
    
    print(f"\nğŸ‘‰ å°‡å¥—ç”¨è‡³ï¼š{', '.join([business_types[bt]['display_name'] for bt in target_business_types])}")

    # é å…ˆå‚™ä»½ç¾æœ‰çš„ç›®æ¨™æª”æ¡ˆ
    def backup_existing_files():
        print(f"ğŸ” æª¢æŸ¥ä¸¦å‚™ä»½ç¾æœ‰æª”æ¡ˆ...")
        backup_count = 0
        
        for bt_code in target_business_types:
            suffix = business_types[bt_code]['suffix']
            
            # ä½¿ç”¨é…ç½®ä¸­çš„æª”æ¡ˆå‘½åæ¨¡æ¿
            file_gen_config = config.config.get('file_generation', {}).get('output_files', {})
            po_template = file_gen_config.get('po_template', '{base_name}{suffix}.po')
            json_template = file_gen_config.get('json_template', '{base_name}{suffix}.json')
            
            po_target = Path(po_template.format(base_name=ORIG_PO.stem, suffix=suffix))
            json_target = Path(json_template.format(base_name=ORIG_JSON.stem, suffix=suffix))
            
            # å‚™ä»½ PO æª”æ¡ˆ
            if po_target.exists():
                backup_filename = f"{po_target.stem}_{timestamp}{po_target.suffix}"
                backup_path = backup_dir / backup_filename
                shutil.copy2(po_target, backup_path)
                log_detail(f"é å‚™ä»½ç¾æœ‰æª”æ¡ˆ: {po_target.name} â†’ backup/{backup_path.name}")
                backup_count += 1
            
            # å‚™ä»½ JSON æª”æ¡ˆ
            if json_target.exists():
                backup_filename = f"{json_target.stem}_{timestamp}{json_target.suffix}"
                backup_path = backup_dir / backup_filename
                shutil.copy2(json_target, backup_path)
                log_detail(f"é å‚™ä»½ç¾æœ‰æª”æ¡ˆ: {json_target.name} â†’ backup/{backup_path.name}")
                backup_count += 1
        
        if backup_count > 0:
            print(f"âœ… å·²å‚™ä»½ {backup_count} å€‹ç¾æœ‰æª”æ¡ˆåˆ° backup/")
            log_detail(f"é å‚™ä»½å®Œæˆï¼Œå…±å‚™ä»½ {backup_count} å€‹ç¾æœ‰æª”æ¡ˆ")
        else:
            print(f"â„¹ï¸  ç„¡ç¾æœ‰ç›®æ¨™æª”æ¡ˆéœ€è¦å‚™ä»½")
            log_detail("ç„¡ç¾æœ‰ç›®æ¨™æª”æ¡ˆéœ€è¦å‚™ä»½")

    backup_existing_files()

    # è®€å– Excel ä¸¦é©—è­‰
    def read_and_validate_xlsx():
        try:
            print(f"ğŸ“– è®€å– {XLSX}...")
            log_detail(f"é–‹å§‹è®€å– Excel æª”æ¡ˆ: {XLSX}")
            wb = openpyxl.load_workbook(XLSX, data_only=True)
            ws = wb.active
            
            header_row = list(ws[1])
            header = {cell.value: idx for idx, cell in enumerate(header_row) if cell.value}
            
            log_detail(f"ç™¼ç¾æ¬„ä½: {list(header.keys())}")
            
            required_columns = ["source", "key", "value"]
            missing_columns = []
            
            for col in required_columns:
                if col not in header:
                    missing_columns.append(col)
            
            # æª¢æŸ¥æ¥­æ…‹æ¬„ä½
            for bt_code in target_business_types:
                display_name = business_types[bt_code]['display_name']
                col_name = f"ä¿®æ­£çµæœ({display_name})"
                if col_name not in header:
                    missing_columns.append(col_name)
            
            if missing_columns:
                error_msg = f"Excel ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}"
                print(f"âŒ {error_msg}")
                log_detail(f"éŒ¯èª¤: {error_msg}")
                sys.exit(1)
            
            return wb, ws, header
            
        except Exception as e:
            error_msg = f"è®€å– Excel æª”æ¡ˆå¤±æ•—ï¼š{e}"
            print(f"âŒ {error_msg}")
            log_detail(f"éŒ¯èª¤: {error_msg}")
            sys.exit(1)

    wb, ws, header = read_and_validate_xlsx()

    def get_column_index(name: str) -> int:
        if name not in header:
            raise KeyError(f"Excel ç¼ºå°‘æ¬„ä½ï¼š{name}")
        return header[name]

    # è§£æ Excel è³‡æ–™
    print(f"ğŸ” è§£æä¿®æ­£è³‡æ–™...")
    log_detail("é–‹å§‹è§£æ Excel ä¿®æ­£è³‡æ–™")
    updates = {bt_code: {"po": [], "json": []} for bt_code in target_business_types}
    stats = defaultdict(int)

    for row_num, row in enumerate(ws.iter_rows(min_row=2, values_only=True), start=2):
        if not row or len(row) <= max(header.values()):
            continue
        
        try:
            source = row[get_column_index("source")]
            key = row[get_column_index("key")]
            
            if not source or not key:
                continue
            
            stats['total_rows'] += 1
            
            # è™•ç†æ¯å€‹ç›®æ¨™æ¥­æ…‹
            for bt_code in target_business_types:
                display_name = business_types[bt_code]['display_name']
                col_name = f"ä¿®æ­£çµæœ({display_name})"
                new_value = row[get_column_index(col_name)]
                
                if not (isinstance(new_value, str) and new_value.strip()):
                    continue
                
                new_value = new_value.strip()
                stats[f'{bt_code}_updates'] += 1
                
                if source == "po":
                    updates[bt_code]["po"].append((key, new_value))
                    log_detail(f"PO æ›´æ–° - {display_name}: {key} â†’ {new_value}")
                elif source == "json":
                    updates[bt_code]["json"].append((key, new_value))
                    log_detail(f"JSON æ›´æ–° - {display_name}: {key} â†’ {new_value}")
                else:
                    log_detail(f"è­¦å‘Š: ç¬¬ {row_num} è¡ŒæœªçŸ¥çš„ source é¡å‹ '{source}'")
            
        except Exception as e:
            log_detail(f"éŒ¯èª¤: ç¬¬ {row_num} è¡Œè™•ç†å¤±æ•—: {e}")
            continue

    print(f"âœ… è§£æå®Œæˆ - ç¸½è¡Œæ•¸: {stats['total_rows']}")
    for bt_code in target_business_types:
        display_name = business_types[bt_code]['display_name']
        update_count = stats[f'{bt_code}_updates']
        print(f"   {display_name}: {update_count} å€‹æ›´æ–°")
    
    log_detail(f"è§£æå®Œæˆçµ±è¨ˆ: {dict(stats)}")

    # æª”æ¡ˆæ“ä½œå‡½æ•¸
    def create_backup_and_copy(src: Path, dest: Path) -> bool:
        try:
            if dest.exists():
                backup_filename = f"{dest.stem}_{timestamp}{dest.suffix}"
                backup_path = backup_dir / backup_filename
                
                shutil.copy2(dest, backup_path)
                log_detail(f"å‚™ä»½: {dest.name} â†’ backup/{backup_path.name}")
            
            shutil.copy2(src, dest)
            log_detail(f"è¤‡è£½: {src.name} â†’ {dest.name}")
            return True
            
        except Exception as e:
            error_msg = f"è¤‡è£½å¤±æ•—: {e}"
            log_detail(f"éŒ¯èª¤: {error_msg}")
            return False

    def update_po_file(po_path: Path, updates_list: list[tuple[str, str]]) -> dict:
        result = {"success": False, "updated": 0, "errors": []}
        
        if not updates_list:
            result["success"] = True
            return result
        
        try:
            log_detail(f"é–‹å§‹æ›´æ–° PO æª”æ¡ˆ: {po_path.name}")
            po_file = polib.pofile(str(po_path))
            
            for msgid, new_msgstr in updates_list:
                entry = po_file.find(msgid)
                if entry:
                    if entry.msgstr != new_msgstr:
                        old_value = entry.msgstr
                        entry.msgstr = new_msgstr
                        result["updated"] += 1
                        log_detail(f"PO æ›´æ–°: '{msgid}' å¾ '{old_value}' æ”¹ç‚º '{new_msgstr}'")
                else:
                    error_msg = f"æ‰¾ä¸åˆ°æ¢ç›®ï¼š{msgid}"
                    result["errors"].append(error_msg)
                    log_detail(f"PO éŒ¯èª¤: {error_msg}")
            
            if result["updated"] > 0:
                po_file.save(str(po_path))
                log_detail(f"PO æª”æ¡ˆå·²å„²å­˜: {po_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
            
            result["success"] = True
            
        except Exception as e:
            error_msg = f"PO æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
            result["errors"].append(error_msg)
            log_detail(f"PO éŒ¯èª¤: {error_msg}")
        
        return result

    def parse_json_path(path: str) -> list:
        parts = []
        current = ""
        in_bracket = False
        
        for char in path:
            if char == '[':
                if current:
                    parts.append(('key', current))
                    current = ""
                in_bracket = True
            elif char == ']':
                if in_bracket and current:
                    try:
                        parts.append(('index', int(current)))
                    except ValueError:
                        raise ValueError(f"ç„¡æ•ˆçš„é™£åˆ—ç´¢å¼•ï¼š{current}")
                    current = ""
                in_bracket = False
            elif char == '.' and not in_bracket:
                if current:
                    parts.append(('key', current))
                    current = ""
            else:
                current += char
        
        if current:
            parts.append(('key', current))
        
        return parts

    def set_json_value_by_path(data: dict, path: str, new_value: str) -> bool:
        try:
            path_parts = parse_json_path(path)
            current = data
            
            for i, (part_type, part_value) in enumerate(path_parts):
                is_last = (i == len(path_parts) - 1)
                
                if part_type == 'key':
                    if is_last:
                        current[part_value] = new_value
                    else:
                        if part_value not in current:
                            next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                            current[part_value] = [] if next_part_type == 'index' else {}
                        current = current[part_value]
                
                elif part_type == 'index':
                    if is_last:
                        while len(current) <= part_value:
                            current.append(None)
                        current[part_value] = new_value
                    else:
                        while len(current) <= part_value:
                            current.append(None)
                        if current[part_value] is None:
                            next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                            current[part_value] = [] if next_part_type == 'index' else {}
                        current = current[part_value]
            
            return True
            
        except Exception as e:
            log_detail(f"JSON è·¯å¾‘è§£æå¤±æ•— '{path}': {e}")
            return False

    def update_json_file(json_path: Path, updates_list: list[tuple[str, str]]) -> dict:
        result = {"success": False, "updated": 0, "errors": []}
        
        if not updates_list:
            result["success"] = True
            return result
        
        try:
            log_detail(f"é–‹å§‹æ›´æ–° JSON æª”æ¡ˆ: {json_path.name}")
            
            data = json.loads(json_path.read_text(encoding="utf-8"))
            
            for json_path_str, new_value in updates_list:
                if set_json_value_by_path(data, json_path_str, new_value):
                    result["updated"] += 1
                    log_detail(f"JSON æ›´æ–°: '{json_path_str}' â†’ '{new_value}'")
                else:
                    error_msg = f"ç„¡æ³•æ›´æ–°è·¯å¾‘ï¼š{json_path_str}"
                    result["errors"].append(error_msg)
                    log_detail(f"JSON éŒ¯èª¤: {error_msg}")
            
            if result["updated"] > 0:
                json_content = json.dumps(data, ensure_ascii=False, indent=2)
                json_path.write_text(json_content, encoding="utf-8")
                log_detail(f"JSON æª”æ¡ˆå·²å„²å­˜: {json_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
            
            result["success"] = True
            
        except json.JSONDecodeError as e:
            error_msg = f"JSON æ ¼å¼éŒ¯èª¤ï¼š{e}"
            result["errors"].append(error_msg)
            log_detail(f"JSON éŒ¯èª¤: {error_msg}")
        except Exception as e:
            error_msg = f"JSON æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
            result["errors"].append(error_msg)
            log_detail(f"JSON éŒ¯èª¤: {error_msg}")
        
        return result

    # è™•ç†æ¯å€‹æ¥­æ…‹
    results = {}
    
    # ä½¿ç”¨é…ç½®ä¸­çš„æª”æ¡ˆå‘½åæ¨¡æ¿
    file_gen_config = config.config.get('file_generation', {}).get('output_files', {})
    po_template = file_gen_config.get('po_template', '{base_name}{suffix}.po')
    json_template = file_gen_config.get('json_template', '{base_name}{suffix}.json')
    
    for bt_code in target_business_types:
        bt_config = business_types[bt_code]
        suffix = bt_config['suffix']
        display_name = bt_config['display_name']
        
        po_dest = Path(po_template.format(base_name=ORIG_PO.stem, suffix=suffix))
        json_dest = Path(json_template.format(base_name=ORIG_JSON.stem, suffix=suffix))

        print(f"\nğŸ“ è™•ç† {display_name}...")
        log_detail(f"é–‹å§‹è™•ç†æ¥­æ…‹: {display_name}")
        
        domain_result = {
            "po_file": str(po_dest),
            "json_file": str(json_dest),
            "po_result": {"success": False, "updated": 0, "errors": []},
            "json_result": {"success": False, "updated": 0, "errors": []}
        }
        
        po_copy_success = create_backup_and_copy(ORIG_PO, po_dest)
        json_copy_success = create_backup_and_copy(ORIG_JSON, json_dest)
        
        if not (po_copy_success and json_copy_success):
            error_msg = f"{display_name} æª”æ¡ˆè¤‡è£½å¤±æ•—ï¼Œè·³éè™•ç†"
            print(f"  âŒ {error_msg}")
            log_detail(f"éŒ¯èª¤: {error_msg}")
            results[bt_code] = domain_result
            continue
        
        domain_result["po_result"] = update_po_file(po_dest, updates[bt_code]["po"])
        domain_result["json_result"] = update_json_file(json_dest, updates[bt_code]["json"])
        
        results[bt_code] = domain_result
        
        print(f"  âœ… å®Œæˆ - PO: {domain_result['po_result']['updated']} å€‹, JSON: {domain_result['json_result']['updated']} å€‹")
        
        log_detail(f"{display_name} è™•ç†å®Œæˆ: PO æ›´æ–° {domain_result['po_result']['updated']} å€‹, JSON æ›´æ–° {domain_result['json_result']['updated']} å€‹")

    # ç”Ÿæˆæœ€çµ‚å ±å‘Š
    print(f"\nğŸ‰ è™•ç†å®Œç•¢ï¼")
    
    all_success = True
    total_updates = 0
    
    for bt_code, result in results.items():
        display_name = business_types[bt_code]['display_name']
        po_updated = result["po_result"]["updated"]
        json_updated = result["json_result"]["updated"]
        domain_total = po_updated + json_updated
        total_updates += domain_total
        
        po_success = result["po_result"]["success"]
        json_success = result["json_result"]["success"]
        domain_success = po_success and json_success
        
        if not domain_success:
            all_success = False
        
        status_icon = "âœ…" if domain_success else "âŒ"
        print(f"{status_icon} {display_name}: {domain_total} å€‹æ›´æ–° ({result['po_file']}, {result['json_file']})")
        
        log_detail(f"æœ€çµ‚çµæœ - {display_name}: PO={po_updated}, JSON={json_updated}, æˆåŠŸ={domain_success}")
        
        all_errors = result["po_result"]["errors"] + result["json_result"]["errors"]
        if all_errors:
            for error in all_errors:
                log_detail(f"éŒ¯èª¤è©³æƒ… - {display_name}: {error}")
    
    print(f"\nğŸ“Š ç¸½è¨ˆ: {total_updates} å€‹æ›´æ–°ï¼Œç‹€æ…‹: {'âœ… æˆåŠŸ' if all_success else 'âš ï¸ éƒ¨åˆ†å¤±æ•—'}")
    print(f"ğŸ“„ è©³ç´°æ—¥èªŒ: {log_file}")
    
    print(f"\nâœ¨ ç´” Excel æ–¹æ¡ˆå„ªå‹¢ï¼š")
    print(f"   âœ… å®Œå…¨åŸºæ–¼ Excel æª”æ¡ˆ")
    print(f"   âœ… ç„¡éœ€ç¶­è­· Python å­—å…¸")
    print(f"   âœ… å·¥ä½œæµç¨‹æ¥µå…¶ç°¡å–®")
    print(f"   âœ… ä¿®æ”¹ Excel ç«‹å³ç”Ÿæ•ˆ")
    
    log_detail(f"è™•ç†å®Œæˆ - ç¸½æ›´æ–°: {total_updates}, æ•´é«”æˆåŠŸ: {all_success}")
    
    if not all_success:
        sys.exit(1)


if __name__ == "__main__":
    main()