#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
script_02_apply_fixes.py (v2.4 - åŒ…å®¹é—œä¿‚ç›¸å®¹ç‰ˆæœ¬)

ä¿®æ”¹å…§å®¹ï¼š
1. å¢å¼·Excelæ¬„ä½æª¢æ¸¬ï¼Œæ”¯æ´æ–°çš„ã€ŒåŒ¹é…ä½ç½®ã€æ¬„ä½
2. æ”¹å–„éŒ¯èª¤è™•ç†ï¼Œæ›´å¥½åœ°è™•ç†åŒ…å®¹é—œä¿‚æª¢æ¸¬ç”¢ç”Ÿçš„æ•¸æ“š
3. å¢åŠ èª¿è©¦ä¿¡æ¯è¼¸å‡º
4. ä¿æŒå‘å¾Œç›¸å®¹æ€§

ä¾æ“šå„èªè¨€çš„ tobemodified_{language}.xlsxï¼Œå°‡ä¿®æ­£çµæœå¯«å›ç¿»è­¯æª”ï¼Œ
ä¸¦è¼¸å‡ºåˆ° i18n_output/{language}_{timestamp}/ ç›®éŒ„ä¸­
"""

import json
import sys
import shutil
import datetime
import argparse
import glob
from pathlib import Path
from collections import defaultdict
from config_loader import get_config

try:
    import openpyxl
    import polib
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install openpyxl polib")
    sys.exit(1)


def read_and_validate_xlsx(xlsx_path: Path, config, target_business_types: list, log_detail) -> tuple:
    """è®€å–ä¸¦é©—è­‰ Excel æª”æ¡ˆ - å¢å¼·ç‰ˆï¼Œæ”¯æ´æ–°æ¬„ä½"""
    try:
        log_detail(f"é–‹å§‹è®€å– Excel æª”æ¡ˆ: {xlsx_path}")
        wb = openpyxl.load_workbook(xlsx_path, data_only=True)
        ws = wb.active
        
        header_row = list(ws[1])
        header = {cell.value: idx for idx, cell in enumerate(header_row) if cell.value}
        
        log_detail(f"ç™¼ç¾æ¬„ä½: {list(header.keys())}")
        
        # åŸºæœ¬æ¬„ä½æª¢æŸ¥
        required_columns = ["æª”æ¡ˆé¡å‹", "é …ç›®ID", "é …ç›®å…§å®¹", "æ•æ„Ÿè©"]
        missing_columns = []
        
        for col in required_columns:
            if col not in header:
                missing_columns.append(col)
        
        # æ–°å¢ï¼šæª¢æŸ¥å¯é¸çš„èª¿è©¦æ¬„ä½
        optional_columns = ["åŒ¹é…ä½ç½®", "æ•æ„Ÿè©åˆ†é¡"]
        found_optional = []
        for col in optional_columns:
            if col in header:
                found_optional.append(col)
        
        if found_optional:
            log_detail(f"ç™¼ç¾æ–°å¢çš„èª¿è©¦æ¬„ä½: {found_optional}")
        
        # æª¢æŸ¥æ¥­æ…‹æ›¿æ›çµæœæ¬„ä½
        business_types = config.get_business_types()
        business_result_columns = []
        
        for bt_code in target_business_types:
            display_name = business_types[bt_code]['display_name']
            result_col_name = f"{display_name}_æ›¿æ›çµæœ"
            if result_col_name not in header:
                missing_columns.append(result_col_name)
            else:
                business_result_columns.append(result_col_name)
        
        if missing_columns:
            error_msg = f"Excel ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}"
            print(f"âŒ {error_msg}")
            log_detail(f"éŒ¯èª¤: {error_msg}")
            return None, None, None
        
        log_detail(f"æ¥­æ…‹æ›¿æ›çµæœæ¬„ä½: {business_result_columns}")
        
        return wb, ws, header
        
    except Exception as e:
        error_msg = f"è®€å– Excel æª”æ¡ˆå¤±æ•—ï¼š{e}"
        print(f"âŒ {error_msg}")
        log_detail(f"éŒ¯èª¤: {error_msg}")
        return None, None, None


def parse_excel_updates(ws, header, config, target_business_types: list, log_detail) -> dict:
    """è§£æ Excel ä¸­çš„ä¿®æ­£è³‡æ–™ - ç²¾ç°¡ç‰ˆ"""
    log_detail("é–‹å§‹è§£æ Excel ä¿®æ­£è³‡æ–™")
    updates = {bt_code: {"po": [], "json": []} for bt_code in target_business_types}
    stats = defaultdict(int)
    
    def get_column_index(name: str) -> int:
        if name not in header:
            raise KeyError(f"Excel ç¼ºå°‘æ¬„ä½ï¼š{name}")
        return header[name]
    
    def get_optional_column_index(name: str) -> int:
        """ç²å–å¯é¸æ¬„ä½ç´¢å¼•ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› -1"""
        return header.get(name, -1)
    
    business_types = config.get_business_types()
    
    # ç²å–å¯é¸æ¬„ä½ç´¢å¼•
    match_pos_idx = get_optional_column_index("åŒ¹é…ä½ç½®")
    category_idx = get_optional_column_index("æ•æ„Ÿè©åˆ†é¡")
    
    for row_num, row in enumerate(ws.iter_rows(min_row=2, values_only=True), start=2):
        if not row or len(row) <= max(header.values()):
            continue
        
        try:
            file_type = row[get_column_index("æª”æ¡ˆé¡å‹")]
            entry_id = row[get_column_index("é …ç›®ID")]
            original_text = row[get_column_index("é …ç›®å…§å®¹")]
            sensitive_word = row[get_column_index("æ•æ„Ÿè©")]
            
            if not file_type or not entry_id:
                continue
            
            file_type = str(file_type).lower()
            stats['total_rows'] += 1
            
            # è®€å–èª¿è©¦ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰- åªè¨˜éŒ„åˆ°æ—¥èªŒ
            debug_info = {}
            if match_pos_idx >= 0 and match_pos_idx < len(row) and row[match_pos_idx]:
                debug_info['match_position'] = str(row[match_pos_idx])
            
            if category_idx >= 0 and category_idx < len(row) and row[category_idx]:
                debug_info['category'] = str(row[category_idx])
            
            # è™•ç†æ¯å€‹ç›®æ¨™æ¥­æ…‹
            for bt_code in target_business_types:
                display_name = business_types[bt_code]['display_name']
                result_col_name = f"{display_name}_æ›¿æ›çµæœ"
                
                try:
                    new_value = row[get_column_index(result_col_name)]
                except KeyError:
                    continue
                
                # åš´æ ¼çš„ç©ºå€¼æª¢æŸ¥ï¼Œè·³éç©ºç™½å€¼
                if not new_value or not str(new_value).strip():
                    continue
                
                new_value = str(new_value).strip()
                
                # ç°¡å–®é©—è­‰ - åªè¨˜éŒ„åˆ°æ—¥èªŒ
                if original_text and sensitive_word:
                    original_str = str(original_text)
                    sensitive_str = str(sensitive_word)
                    
                    if sensitive_str not in original_str:
                        log_detail(f"è­¦å‘Š: æ•æ„Ÿè© '{sensitive_str}' ä¸åœ¨åŸæ–‡ä¸­")
                    
                    if sensitive_str in new_value:
                        log_detail(f"è­¦å‘Š: æ›¿æ›çµæœä¸­ä»åŒ…å«æ•æ„Ÿè©")
                
                stats[f'{bt_code}_updates'] += 1
                
                # å‰µå»ºæ›´æ–°è¨˜éŒ„
                update_record = (str(entry_id), new_value, debug_info)
                
                if file_type == "po":
                    updates[bt_code]["po"].append(update_record)
                elif file_type == "json":
                    updates[bt_code]["json"].append(update_record)
        
        except Exception as e:
            log_detail(f"éŒ¯èª¤: ç¬¬ {row_num} è¡Œè™•ç†å¤±æ•—: {e}")
            continue
    
    # åªè¨˜éŒ„çµ±è¨ˆåˆ°æ—¥èªŒ
    total_updates = sum(stats[f'{bt_code}_updates'] for bt_code in target_business_types if f'{bt_code}_updates' in stats)
    log_detail(f"è§£æå®Œæˆ - ç¸½æ›´æ–°é …ç›®æ•¸: {total_updates}")
    
    return updates


def update_po_file(po_path: Path, updates_list: list, log_detail) -> dict:
    """æ›´æ–° PO æª”æ¡ˆ - ç²¾ç°¡ç‰ˆ"""
    result = {"success": False, "updated": 0, "errors": [], "details": []}
    
    if not updates_list:
        result["success"] = True
        return result
    
    try:
        po_file = polib.pofile(str(po_path))
        
        for update_record in updates_list:
            # å…¼å®¹èˆŠæ ¼å¼å’Œæ–°æ ¼å¼
            if len(update_record) == 2:
                msgid, new_msgstr = update_record
                debug_info = {}
            elif len(update_record) == 3:
                msgid, new_msgstr, debug_info = update_record
            else:
                continue
            
            entry = po_file.find(msgid)
            if entry:
                if entry.msgstr != new_msgstr:
                    old_value = entry.msgstr
                    entry.msgstr = new_msgstr
                    result["updated"] += 1
                    
                    # åªè¨˜éŒ„åˆ°æ—¥èªŒï¼Œä¸æ‰“å°åˆ°æ§åˆ¶å°
                    detail_msg = f"PO æ›´æ–°: '{msgid}' â†’ '{new_msgstr}'"
                    if debug_info and 'match_position' in debug_info:
                        detail_msg += f" [ä½ç½®:{debug_info['match_position']}]"
                    
                    result["details"].append(detail_msg)
                    log_detail(detail_msg)
            else:
                error_msg = f"æ‰¾ä¸åˆ°æ¢ç›®ï¼š{msgid}"
                result["errors"].append(error_msg)
                log_detail(f"PO éŒ¯èª¤: {error_msg}")
        
        if result["updated"] > 0:
            po_file.save(str(po_path))
            log_detail(f"PO æª”æ¡ˆå·²å„²å­˜: {po_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
        
        result["success"] = True
        
    except Exception as e:
        error_msg = f"PO æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
        result["errors"].append(error_msg)
        log_detail(f"PO éŒ¯èª¤: {error_msg}")
    
    return result


def update_json_file(json_path: Path, updates_list: list, log_detail) -> dict:
    """æ›´æ–° JSON æª”æ¡ˆ - ç²¾ç°¡ç‰ˆ"""
    result = {"success": False, "updated": 0, "errors": [], "details": []}
    
    if not updates_list:
        result["success"] = True
        return result
    
    try:
        data = json.loads(json_path.read_text(encoding="utf-8"))
        
        for update_record in updates_list:
            # å…¼å®¹èˆŠæ ¼å¼å’Œæ–°æ ¼å¼
            if len(update_record) == 2:
                json_path_str, new_value = update_record
                debug_info = {}
            elif len(update_record) == 3:
                json_path_str, new_value, debug_info = update_record
            else:
                continue
            
            if set_json_value_by_path(data, json_path_str, new_value):
                result["updated"] += 1
                
                # åªè¨˜éŒ„åˆ°æ—¥èªŒï¼Œä¸æ‰“å°åˆ°æ§åˆ¶å°
                detail_msg = f"JSON æ›´æ–°: '{json_path_str}' â†’ '{new_value}'"
                if debug_info and 'match_position' in debug_info:
                    detail_msg += f" [ä½ç½®:{debug_info['match_position']}]"
                
                result["details"].append(detail_msg)
                log_detail(detail_msg)
            else:
                error_msg = f"ç„¡æ³•æ›´æ–°è·¯å¾‘ï¼š{json_path_str}"
                result["errors"].append(error_msg)
                log_detail(f"JSON éŒ¯èª¤: {error_msg}")
        
        if result["updated"] > 0:
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            json_path.write_text(json_content, encoding="utf-8")
            log_detail(f"JSON æª”æ¡ˆå·²å„²å­˜: {json_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
        
        result["success"] = True
        
    except json.JSONDecodeError as e:
        error_msg = f"JSON æ ¼å¼éŒ¯èª¤ï¼š{e}"
        result["errors"].append(error_msg)
        log_detail(f"JSON éŒ¯èª¤: {error_msg}")
    except Exception as e:
        error_msg = f"JSON æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
        result["errors"].append(error_msg)
        log_detail(f"JSON éŒ¯èª¤: {error_msg}")
    
    return result


def parse_json_path(path: str) -> list:
    """è§£æ JSON è·¯å¾‘ - ä¿æŒåŸæœ‰é‚è¼¯"""
    parts = []
    current = ""
    in_bracket = False
    
    for char in path:
        if char == '[':
            if current:
                parts.append(('key', current))
                current = ""
            in_bracket = True
        elif char == ']':
            if in_bracket and current:
                try:
                    parts.append(('index', int(current)))
                except ValueError:
                    raise ValueError(f"ç„¡æ•ˆçš„é™£åˆ—ç´¢å¼•ï¼š{current}")
                current = ""
            in_bracket = False
        elif char == '.' and not in_bracket:
            if current:
                parts.append(('key', current))
                current = ""
        else:
            current += char
    
    if current:
        parts.append(('key', current))
    
    return parts


def set_json_value_by_path(data: dict, path: str, new_value: str) -> bool:
    """æŒ‰è·¯å¾‘è¨­ç½® JSON å€¼ - ä¿æŒåŸæœ‰é‚è¼¯"""
    try:
        path_parts = parse_json_path(path)
        current = data
        
        for i, (part_type, part_value) in enumerate(path_parts):
            is_last = (i == len(path_parts) - 1)
            
            if part_type == 'key':
                if is_last:
                    current[part_value] = new_value
                else:
                    if part_value not in current:
                        next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                        current[part_value] = [] if next_part_type == 'index' else {}
                    current = current[part_value]
            
            elif part_type == 'index':
                if is_last:
                    while len(current) <= part_value:
                        current.append(None)
                    current[part_value] = new_value
                else:
                    while len(current) <= part_value:
                        current.append(None)
                    if current[part_value] is None:
                        next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                        current[part_value] = [] if next_part_type == 'index' else {}
                    current = current[part_value]
        
        return True
        
    except Exception as e:
        return False


# ä¿æŒå…¶ä»–åŸæœ‰å‡½æ•¸ä¸è®Š
def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    print("ğŸš€ é–‹å§‹å¥—ç”¨å¤šèªè¨€ä¿®æ­£çµæœ (v2.4 - åŒ…å®¹é—œä¿‚ç›¸å®¹ç‰ˆæœ¬)")
    
    # è¼‰å…¥é…ç½®
    config = get_config()
    config.print_config_summary()
    
    # è™•ç†å‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser(description='å¥—ç”¨å¤šèªè¨€æ•æ„Ÿè©ä¿®æ­£çµæœ')
    parser.add_argument('--language', '-l', 
                       help='æŒ‡å®šè¦è™•ç†çš„èªè¨€ï¼ˆè‹¥æœªæŒ‡å®šå°‡è‡ªå‹•æª¢æ¸¬ï¼‰')
    parser.add_argument('--business-types', '-b',
                       nargs='+',
                       choices=list(config.get_business_types().keys()) + ['all'],
                       help='æŒ‡å®šè¦è™•ç†çš„æ¥­æ…‹ (å¯å¤šé¸ï¼Œæˆ–ä½¿ç”¨ all)')
    parser.add_argument('--list-files', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ tobemodified æª”æ¡ˆ')
    
    args = parser.parse_args()
    
    # æª¢æ¸¬å¯ç”¨çš„ tobemodified æª”æ¡ˆ
    available_files = detect_tobemodified_files(config)
    
    if args.list_files:
        print(f"\nğŸ“„ å¯ç”¨çš„ tobemodified æª”æ¡ˆï¼š")
        for lang, filepath in available_files.items():
            print(f"   {lang}: {filepath}")
        return
    
    if not available_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• tobemodified æª”æ¡ˆ")
        print("è«‹å…ˆåŸ·è¡Œ script_01_generate_xlsx.py ç”Ÿæˆæª”æ¡ˆ")
        sys.exit(1)
    
    # é¸æ“‡è¦è™•ç†çš„èªè¨€
    if args.language:
        if args.language not in available_files:
            print(f"âŒ èªè¨€ '{args.language}' çš„ tobemodified æª”æ¡ˆä¸å­˜åœ¨")
            print(f"å¯ç”¨èªè¨€ï¼š{list(available_files.keys())}")
            sys.exit(1)
        target_languages = [args.language]
        print(f"\nğŸŒ å°‡è™•ç†æŒ‡å®šèªè¨€ï¼š{args.language}")
    else:
        target_languages = list(available_files.keys())
        print(f"\nğŸŒ å°‡è™•ç†æ‰€æœ‰èªè¨€ï¼š{', '.join(target_languages)}")
    
    # é¸æ“‡æ¥­æ…‹
    target_business_types = choose_business_types(config, args)
    
    # è™•ç†æ¯å€‹èªè¨€
    success_count = 0
    total_count = len(target_languages)
    
    for language in target_languages:
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ è™•ç†èªè¨€ï¼š{language}")
        
        if process_language(config, language, target_business_types):
            success_count += 1
        else:
            print(f"âŒ {language} è™•ç†å¤±æ•—")
    
    # æœ€çµ‚å ±å‘Š
    print(f"\nğŸ‰ è™•ç†å®Œç•¢ï¼")
    print(f"ğŸ“Š æˆåŠŸè™•ç†ï¼š{success_count}/{total_count} å€‹èªè¨€")
    
    if success_count < total_count:
        sys.exit(1)


def detect_tobemodified_files(config) -> dict:
    """æª¢æ¸¬å¯ç”¨çš„ tobemodified æª”æ¡ˆ - ä¿æŒåŸæœ‰é‚è¼¯"""
    available_files = {}
    
    # æª¢æ¸¬è¼¸å‡ºç›®éŒ„ä¸­çš„æª”æ¡ˆ
    try:
        if hasattr(config, 'get_output_dir'):
            output_dir = config.get_output_dir()
        elif hasattr(config, 'output_dir'):
            output_dir = config.output_dir
        elif hasattr(config, 'get_config'):
            config_data = config.get_config()
            output_dir = Path(config_data.get('output_dir', 'i18n_output'))
        else:
            output_dir = Path('i18n_output')
    except Exception:
        output_dir = Path('i18n_output')
    
    # æª¢æ¸¬æ¨™æº–å‘½åçš„æª”æ¡ˆ
    available_languages = config.detect_available_languages()
    
    for language in available_languages:
        tobemodified_path = output_dir / f"{language}_tobemodified.xlsx"
        if tobemodified_path.exists():
            available_files[language] = tobemodified_path
    
    # é¡å¤–æª¢æ¸¬ç•¶å‰ç›®éŒ„å’Œè¼¸å‡ºç›®éŒ„ä¸­çš„é€šé…ç¬¦æª”æ¡ˆ
    for search_dir in [Path('.'), output_dir]:
        if search_dir.exists():
            for file_path in search_dir.glob("*_tobemodified.xlsx"):
                # æå–èªè¨€ä»£ç¢¼
                filename = file_path.stem
                if filename.endswith('_tobemodified'):
                    language = filename[:-len('_tobemodified')]
                    if language not in available_files:
                        available_files[language] = file_path
    
    return available_files


def choose_business_types(config, args) -> list:
    """é¸æ“‡è¦è™•ç†çš„æ¥­æ…‹ - ä¿æŒåŸæœ‰é‚è¼¯"""
    if args.business_types:
        if 'all' in args.business_types:
            return list(config.get_business_types().keys())
        return args.business_types
    
    # äº’å‹•å¼é¸æ“‡
    business_types = config.get_business_types()
    choices = list(business_types.items())
    
    print("\nè«‹é¸æ“‡è¦å¥—ç”¨ä¿®æ­£çš„æ¥­æ…‹ï¼š")
    for i, (bt_code, bt_config) in enumerate(choices, 1):
        print(f"  {i}) {bt_config['display_name']}")
    print(f"  {len(choices) + 1}) å…¨éƒ¨")
    
    while True:
        try:
            opt = input(f"\nè¼¸å…¥é¸é … (1-{len(choices) + 1})ï¼š").strip()
            choice_idx = int(opt) - 1
            
            if choice_idx == len(choices):  # å…¨éƒ¨
                return list(business_types.keys())
            elif 0 <= choice_idx < len(choices):
                bt_code = choices[choice_idx][0]
                return [bt_code]
            else:
                print(f"âš ï¸  è«‹è¼¸å…¥ 1-{len(choices) + 1} ä¹‹é–“çš„æ•¸å­—")
        except (ValueError, KeyboardInterrupt):
            print("\nâŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
            sys.exit(0)


def process_language(config, language: str, target_business_types: list) -> bool:
    """è™•ç†å–®å€‹èªè¨€çš„ä¿®æ­£å¥—ç”¨ - ç²¾ç°¡ç‰ˆ"""
    
    # ç²å–æª”æ¡ˆè·¯å¾‘
    available_files = detect_tobemodified_files(config)
    tobemodified_path = available_files.get(language)
    
    if not tobemodified_path:
        print(f"âŒ æ‰¾ä¸åˆ° {language} çš„ tobemodified æª”æ¡ˆ")
        return False
    
    language_files = config.get_language_files(language)
    
    print(f"   ä¾†æº Excelï¼š{tobemodified_path.name}")
    
    # ç²å–è¼¸å‡ºè·¯å¾‘
    try:
        output_paths = config.get_output_paths(language)
        output_dir = output_paths['output_dir']
        timestamp = output_paths['timestamp']
    except Exception:
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        try:
            if hasattr(config, 'get_output_dir'):
                base_output_dir = config.get_output_dir()
            else:
                base_output_dir = Path('i18n_output')
        except Exception:
            base_output_dir = Path('i18n_output')
        
        output_dir = base_output_dir / f"{language}_{timestamp}"
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¨­ç½®æ—¥èªŒ - åªè¨˜éŒ„åˆ°æª”æ¡ˆï¼Œä¸æ‰“å°åˆ°æ§åˆ¶å°
    log_file = output_dir / f"apply_fixes_{timestamp}.log"
    
    def log_detail(message: str):
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"{datetime.datetime.now().strftime('%H:%M:%S')} - {message}\n")
    
    log_detail(f"é–‹å§‹è™•ç†èªè¨€: {language}")
    log_detail(f"ç›®æ¨™æ¥­æ…‹: {', '.join(target_business_types)}")
    log_detail(f"ä¾†æºæª”æ¡ˆ: {tobemodified_path}")
    
    # è®€å–ä¸¦é©—è­‰ Excel
    wb, ws, header = read_and_validate_xlsx(tobemodified_path, config, target_business_types, log_detail)
    if not wb:
        return False
    
    # è§£æä¿®æ­£è³‡æ–™
    updates = parse_excel_updates(ws, header, config, target_business_types, log_detail)
    
    # è™•ç†æ¯å€‹æ¥­æ…‹
    business_types = config.get_business_types()
    results = {}
    
    for bt_code in target_business_types:
        bt_config = business_types[bt_code]
        display_name = bt_config['display_name']
        
        print(f"   ğŸ“ è™•ç† {display_name}...")
        log_detail(f"é–‹å§‹è™•ç†æ¥­æ…‹: {display_name}")
        
        # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        output_files = generate_output_files(config, language, bt_code, language_files, output_dir)
        if not output_files:
            log_detail(f"éŒ¯èª¤: {display_name} è¼¸å‡ºæª”æ¡ˆç”Ÿæˆå¤±æ•—")
            continue
        
        # å¥—ç”¨ä¿®æ­£
        result = apply_fixes_to_business_type(
            config, bt_code, updates[bt_code], output_files, log_detail
        )
        
        results[bt_code] = result
        
        if result['success']:
            total_updates = result['po_updated'] + result['json_updated']
            print(f"     âœ… å®Œæˆ - PO: {result['po_updated']} å€‹, JSON: {result['json_updated']} å€‹")
            log_detail(f"{display_name} è™•ç†å®Œæˆ: ç¸½æ›´æ–° {total_updates} å€‹")
        else:
            print(f"     âŒ å¤±æ•—")
            log_detail(f"{display_name} è™•ç†å¤±æ•—")
            
            # è¨˜éŒ„éŒ¯èª¤è©³æƒ…åˆ°æ—¥èªŒ
            for error in result.get('errors', []):
                log_detail(f"  éŒ¯èª¤: {error}")
    
    # ç”Ÿæˆæœ€çµ‚å ±å‘Š - ç²¾ç°¡ç‰ˆ
    success_count = sum(1 for r in results.values() if r['success'])
    total_count = len(results)
    total_updates = sum(r['po_updated'] + r['json_updated'] for r in results.values())
    
    print(f"   ğŸ“Š è™•ç†çµæœï¼šæˆåŠŸ {success_count}/{total_count}ï¼Œç¸½æ›´æ–° {total_updates} å€‹")
    print(f"   ğŸ“ è¼¸å‡ºç›®éŒ„ï¼š{output_dir}")
    
    log_detail(f"èªè¨€ {language} è™•ç†å®Œæˆ: æˆåŠŸ {success_count}/{total_count} å€‹æ¥­æ…‹")
    
    # ç”Ÿæˆè™•ç†æ‘˜è¦
    generate_summary_report(results, output_dir, timestamp, log_detail)
    
    return success_count > 0
    # è®€å–ä¸¦é©—è­‰ Excel
    wb, ws, header = read_and_validate_xlsx(tobemodified_path, config, target_business_types, log_detail)
    if not wb:
        return False
    
    # è§£æä¿®æ­£è³‡æ–™
    updates = parse_excel_updates(ws, header, config, target_business_types, log_detail)
    
    # è™•ç†æ¯å€‹æ¥­æ…‹
    business_types = config.get_business_types()
    results = {}
    
    for bt_code in target_business_types:
        bt_config = business_types[bt_code]
        display_name = bt_config['display_name']
        
        print(f"\nğŸ“ è™•ç† {display_name}...")
        log_detail(f"é–‹å§‹è™•ç†æ¥­æ…‹: {display_name}")
        
        # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        output_files = generate_output_files(config, language, bt_code, language_files, output_dir)
        if not output_files:
            log_detail(f"éŒ¯èª¤: {display_name} è¼¸å‡ºæª”æ¡ˆç”Ÿæˆå¤±æ•—")
            continue
        
        # å¥—ç”¨ä¿®æ­£
        result = apply_fixes_to_business_type(
            config, bt_code, updates[bt_code], output_files, log_detail
        )
        
        results[bt_code] = result
        
        if result['success']:
            total_updates = result['po_updated'] + result['json_updated']
            print(f"  âœ… å®Œæˆ - PO: {result['po_updated']} å€‹, JSON: {result['json_updated']} å€‹")
            log_detail(f"{display_name} è™•ç†å®Œæˆ: ç¸½æ›´æ–° {total_updates} å€‹")
            
            # è©³ç´°è¨˜éŒ„æ¯å€‹æ›´æ–°
            if result.get('details'):
                for detail in result['details']:
                    log_detail(f"  {detail}")
        else:
            print(f"  âŒ å¤±æ•—")
            log_detail(f"{display_name} è™•ç†å¤±æ•—")
            
            # è¨˜éŒ„éŒ¯èª¤è©³æƒ…
            for error in result.get('errors', []):
                log_detail(f"  éŒ¯èª¤: {error}")
    
    # ç”Ÿæˆæœ€çµ‚å ±å‘Š
    success_count = sum(1 for r in results.values() if r['success'])
    total_count = len(results)
    
    print(f"\nğŸ“Š {language} è™•ç†çµæœï¼š")
    print(f"   æˆåŠŸæ¥­æ…‹ï¼š{success_count}/{total_count}")
    print(f"   è¼¸å‡ºç›®éŒ„ï¼š{output_dir}")
    print(f"   è©³ç´°æ—¥èªŒï¼š{log_file}")
    
    log_detail(f"èªè¨€ {language} è™•ç†å®Œæˆ: æˆåŠŸ {success_count}/{total_count} å€‹æ¥­æ…‹")
    
    # ç”Ÿæˆè™•ç†æ‘˜è¦
    generate_summary_report(results, output_dir, timestamp, log_detail)
    
    return success_count > 0


def generate_output_files(config, language: str, bt_code: str, language_files: dict, output_dir: Path) -> dict:
    """ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆ - ä¿æŒåŸæœ‰é‚è¼¯"""
    business_types = config.get_business_types()
    bt_config = business_types[bt_code]
    suffix = bt_config['suffix']
    
    output_files = {}
    
    # è™•ç† PO æª”æ¡ˆ
    if 'po_file' in language_files:
        original_po = language_files['po_file']
        output_po = output_dir / f"{original_po.stem}{suffix}{original_po.suffix}"
        
        # è¤‡è£½åŸå§‹æª”æ¡ˆ
        shutil.copy2(original_po, output_po)
        output_files['po_file'] = output_po
    
    # è™•ç† JSON æª”æ¡ˆ
    if 'json_file' in language_files:
        original_json = language_files['json_file']
        output_json = output_dir / f"{original_json.stem}{suffix}{original_json.suffix}"
        
        # è¤‡è£½åŸå§‹æª”æ¡ˆ
        shutil.copy2(original_json, output_json)
        output_files['json_file'] = output_json
    
    return output_files


def apply_fixes_to_business_type(config, bt_code: str, updates: dict, output_files: dict, log_detail) -> dict:
    """å¥—ç”¨ä¿®æ­£åˆ°æŒ‡å®šæ¥­æ…‹ - ä¿æŒåŸæœ‰é‚è¼¯"""
    result = {
        'success': True,
        'po_updated': 0,
        'json_updated': 0,
        'errors': [],
        'details': []
    }
    
    try:
        # è™•ç† PO æª”æ¡ˆ
        if 'po_file' in output_files and updates['po']:
            po_result = update_po_file(output_files['po_file'], updates['po'], log_detail)
            result['po_updated'] = po_result['updated']
            result['errors'].extend(po_result['errors'])
            result['details'].extend(po_result.get('details', []))
            if not po_result['success']:
                result['success'] = False
        
        # è™•ç† JSON æª”æ¡ˆ
        if 'json_file' in output_files and updates['json']:
            json_result = update_json_file(output_files['json_file'], updates['json'], log_detail)
            result['json_updated'] = json_result['updated']
            result['errors'].extend(json_result['errors'])
            result['details'].extend(json_result.get('details', []))
            if not json_result['success']:
                result['success'] = False
        
    except Exception as e:
        error_msg = f"å¥—ç”¨ä¿®æ­£å¤±æ•—ï¼š{e}"
        result['errors'].append(error_msg)
        result['success'] = False
        log_detail(f"éŒ¯èª¤: {error_msg}")
    
    return result


def generate_summary_report(results: dict, output_dir: Path, timestamp: str, log_detail):
    """ç”Ÿæˆè™•ç†æ‘˜è¦å ±å‘Š - å¢å¼·ç‰ˆï¼ŒåŒ…å«åŒ…å®¹é—œä¿‚ä¿¡æ¯"""
    summary_file = output_dir / f"processing_summary_{timestamp}.txt"
    
    try:
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"æ•æ„Ÿè©ä¿®æ­£è™•ç†æ‘˜è¦å ±å‘Š (åŒ…å®¹é—œä¿‚è™•ç†ç‰ˆæœ¬)\n")
            f.write(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"{'='*50}\n\n")
            
            total_po_updates = 0
            total_json_updates = 0
            successful_business_types = []
            failed_business_types = []
            
            # çµ±è¨ˆåŒ…å®¹é—œä¿‚ç›¸é—œä¿¡æ¯
            inclusion_related_updates = 0
            position_info_count = 0
            category_info_count = 0
            
            for bt_code, result in results.items():
                f.write(f"æ¥­æ…‹ï¼š{bt_code}\n")
                f.write(f"ç‹€æ…‹ï¼š{'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}\n")
                f.write(f"PO æ›´æ–°æ•¸é‡ï¼š{result['po_updated']}\n")
                f.write(f"JSON æ›´æ–°æ•¸é‡ï¼š{result['json_updated']}\n")
                
                if result['success']:
                    successful_business_types.append(bt_code)
                    total_po_updates += result['po_updated']
                    total_json_updates += result['json_updated']
                else:
                    failed_business_types.append(bt_code)
                
                if result.get('errors'):
                    f.write(f"éŒ¯èª¤ï¼š\n")
                    for error in result['errors']:
                        f.write(f"  - {error}\n")
                
                if result.get('details'):
                    f.write(f"è©³ç´°æ›´æ–°è¨˜éŒ„ï¼š\n")
                    for detail in result['details'][:20]:  # é™åˆ¶é¡¯ç¤ºå‰20æ¢
                        f.write(f"  - {detail}\n")
                        
                        # çµ±è¨ˆåŒ…å®¹é—œä¿‚ç›¸é—œä¿¡æ¯
                        if '[ä½ç½®:' in detail:
                            position_info_count += 1
                        if '[åˆ†é¡:' in detail:
                            category_info_count += 1
                        if '[ä½ç½®:' in detail or '[åˆ†é¡:' in detail:
                            inclusion_related_updates += 1
                            
                    if len(result['details']) > 20:
                        f.write(f"  ... é‚„æœ‰ {len(result['details']) - 20} æ¢è¨˜éŒ„\n")
                
                f.write(f"\n{'-'*30}\n\n")
            
            # ç¸½è¨ˆçµ±è¨ˆ
            f.write(f"è™•ç†ç¸½çµï¼š\n")
            f.write(f"æˆåŠŸæ¥­æ…‹ï¼š{len(successful_business_types)}\n")
            f.write(f"å¤±æ•—æ¥­æ…‹ï¼š{len(failed_business_types)}\n")
            f.write(f"ç¸½ PO æ›´æ–°ï¼š{total_po_updates}\n")
            f.write(f"ç¸½ JSON æ›´æ–°ï¼š{total_json_updates}\n")
            f.write(f"ç¸½æ›´æ–°é …ç›®ï¼š{total_po_updates + total_json_updates}\n")
            
            # æ–°å¢ï¼šåŒ…å®¹é—œä¿‚è™•ç†çµ±è¨ˆ
            f.write(f"\nåŒ…å®¹é—œä¿‚è™•ç†çµ±è¨ˆï¼š\n")
            f.write(f"åŒ…å«èª¿è©¦ä¿¡æ¯çš„æ›´æ–°ï¼š{inclusion_related_updates}\n")
            f.write(f"åŒ…å«ä½ç½®ä¿¡æ¯çš„æ›´æ–°ï¼š{position_info_count}\n")
            f.write(f"åŒ…å«åˆ†é¡ä¿¡æ¯çš„æ›´æ–°ï¼š{category_info_count}\n")
            
            if inclusion_related_updates > 0:
                f.write(f"åŒ…å®¹é—œä¿‚æª¢æ¸¬è¦†è“‹ç‡ï¼š{inclusion_related_updates}/{total_po_updates + total_json_updates} ({inclusion_related_updates/(total_po_updates + total_json_updates)*100:.1f}%)\n")
            
            if successful_business_types:
                f.write(f"\næˆåŠŸçš„æ¥­æ…‹ï¼š{', '.join(successful_business_types)}\n")
            
            if failed_business_types:
                f.write(f"å¤±æ•—çš„æ¥­æ…‹ï¼š{', '.join(failed_business_types)}\n")
        
        log_detail(f"æ‘˜è¦å ±å‘Šå·²ç”Ÿæˆï¼š{summary_file}")
        
    except Exception as e:
        log_detail(f"ç”Ÿæˆæ‘˜è¦å ±å‘Šå¤±æ•—ï¼š{e}")


if __name__ == "__main__":
    main()