#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
script_02_apply_fixes.py (v2.5 - å¤šé‡æ•æ„Ÿè©å¢å¼·ç‰ˆ)

ä¿®æ”¹å…§å®¹ï¼š
1. âœ… æ”¯æ´æ–°çš„å¤šé‡æ•æ„Ÿè©æ ¼å¼ï¼ˆæ•æ„Ÿè©æ¬„ä½å¯èƒ½åŒ…å«å¤šå€‹è©ï¼Œä»¥é€—è™Ÿåˆ†éš”ï¼‰
2. âœ… æ”¯æ´æ–°çš„æ›¿æ›æ–¹æ¡ˆæ ¼å¼ï¼ˆkeyword1â†’replacement1; keyword2â†’replacement2ï¼‰
3. âœ… è‡ªå‹•è·³éç©ºçš„æ›¿æ›çµæœï¼Œé¿å…ç„¡æ„ç¾©çš„è™•ç†å’Œé¢¨éšª
4. âœ… å¢å¼·å®‰å…¨æª¢æŸ¥ï¼Œè·³éèˆ‡åŸæ–‡ç›¸åŒçš„æ›¿æ›çµæœ
5. âœ… æ”¹å–„éŒ¯èª¤è™•ç†å’Œçµ±è¨ˆå ±å‘Š
6. âœ… ä¿æŒå‘å¾Œç›¸å®¹æ€§

ä¾æ“šå„èªè¨€çš„ tobemodified_{language}.xlsxï¼Œå°‡ä¿®æ­£çµæœå¯«å›ç¿»è­¯æª”ï¼Œ
ä¸¦è¼¸å‡ºåˆ° i18n_output/{language}_{timestamp}/ ç›®éŒ„ä¸­
"""

import json
import sys
import shutil
import datetime
import argparse
import glob
from pathlib import Path
from collections import defaultdict
from config_loader import get_config

try:
    import openpyxl
    import polib
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦å¥—ä»¶ï¼š{e}")
    print("è«‹åŸ·è¡Œï¼špip install openpyxl polib")
    sys.exit(1)


def read_and_validate_xlsx(xlsx_path: Path, config, target_business_types: list, log_detail) -> tuple:
    """è®€å–ä¸¦é©—è­‰ Excel æª”æ¡ˆ - å¢å¼·ç‰ˆï¼Œæ”¯æ´æ–°æ¬„ä½å’Œå¤šé‡æ•æ„Ÿè©æ ¼å¼"""
    try:
        log_detail(f"é–‹å§‹è®€å– Excel æª”æ¡ˆ: {xlsx_path}")
        wb = openpyxl.load_workbook(xlsx_path, data_only=True)
        ws = wb.active
        
        header_row = list(ws[1])
        header = {cell.value: idx for idx, cell in enumerate(header_row) if cell.value}
        
        log_detail(f"ç™¼ç¾æ¬„ä½: {list(header.keys())}")
        
        # åŸºæœ¬æ¬„ä½æª¢æŸ¥
        required_columns = ["æª”æ¡ˆé¡å‹", "é …ç›®ID", "é …ç›®å…§å®¹", "æ•æ„Ÿè©"]
        missing_columns = []
        
        for col in required_columns:
            if col not in header:
                missing_columns.append(col)
        
        # æ–°å¢ï¼šæª¢æŸ¥å¯é¸çš„èª¿è©¦æ¬„ä½
        optional_columns = ["åŒ¹é…ä½ç½®", "æ•æ„Ÿè©åˆ†é¡"]
        found_optional = []
        for col in optional_columns:
            if col in header:
                found_optional.append(col)
        
        if found_optional:
            log_detail(f"ç™¼ç¾æ–°å¢çš„èª¿è©¦æ¬„ä½: {found_optional}")
        
        # æª¢æŸ¥æ¥­æ…‹æ›¿æ›çµæœæ¬„ä½
        business_types = config.get_business_types()
        business_result_columns = []
        
        for bt_code in target_business_types:
            display_name = business_types[bt_code]['display_name']
            result_col_name = f"{display_name}_æ›¿æ›çµæœ"
            if result_col_name not in header:
                missing_columns.append(result_col_name)
            else:
                business_result_columns.append(result_col_name)
        
        if missing_columns:
            error_msg = f"Excel ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}"
            print(f"âŒ {error_msg}")
            log_detail(f"éŒ¯èª¤: {error_msg}")
            return None, None, None
        
        log_detail(f"æ¥­æ…‹æ›¿æ›çµæœæ¬„ä½: {business_result_columns}")
        
        return wb, ws, header
        
    except Exception as e:
        error_msg = f"è®€å– Excel æª”æ¡ˆå¤±æ•—ï¼š{e}"
        print(f"âŒ {error_msg}")
        log_detail(f"éŒ¯èª¤: {error_msg}")
        return None, None, None


def parse_excel_updates(ws, header, config, target_business_types: list, log_detail) -> dict:
    """è§£æ Excel ä¸­çš„ä¿®æ­£è³‡æ–™ - å¢å¼·ç‰ˆï¼Œæ”¯æ´å¤šé‡æ•æ„Ÿè©å’Œå®‰å…¨æª¢æŸ¥"""
    log_detail("é–‹å§‹è§£æ Excel ä¿®æ­£è³‡æ–™")
    updates = {bt_code: {"po": [], "json": []} for bt_code in target_business_types}
    stats = defaultdict(int)
    
    def get_column_index(name: str) -> int:
        if name not in header:
            raise KeyError(f"Excel ç¼ºå°‘æ¬„ä½ï¼š{name}")
        return header[name]
    
    def get_optional_column_index(name: str) -> int:
        """ç²å–å¯é¸æ¬„ä½ç´¢å¼•ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› -1"""
        return header.get(name, -1)
    
    business_types = config.get_business_types()
    
    # ç²å–å¯é¸æ¬„ä½ç´¢å¼•
    match_pos_idx = get_optional_column_index("åŒ¹é…ä½ç½®")
    category_idx = get_optional_column_index("æ•æ„Ÿè©åˆ†é¡")
    
    # ã€æ–°å¢ã€‘çµ±è¨ˆè®Šæ•¸
    skipped_empty_replacements = 0
    skipped_same_as_original = 0
    
    for row_num, row in enumerate(ws.iter_rows(min_row=2, values_only=True), start=2):
        if not row or len(row) <= max(header.values()):
            continue
        
        try:
            file_type = row[get_column_index("æª”æ¡ˆé¡å‹")]
            entry_id = row[get_column_index("é …ç›®ID")]
            original_text = row[get_column_index("é …ç›®å…§å®¹")]
            sensitive_word = row[get_column_index("æ•æ„Ÿè©")]
            
            if not file_type or not entry_id:
                continue
            
            file_type = str(file_type).lower()
            stats['total_rows'] += 1
            
            # è®€å–èª¿è©¦ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰- åªè¨˜éŒ„åˆ°æ—¥èªŒ
            debug_info = {}
            if match_pos_idx >= 0 and match_pos_idx < len(row) and row[match_pos_idx]:
                debug_info['match_position'] = str(row[match_pos_idx])
            
            if category_idx >= 0 and category_idx < len(row) and row[category_idx]:
                debug_info['category'] = str(row[category_idx])
            
            # ã€æ–°å¢ã€‘è§£æå¤šé‡æ•æ„Ÿè©ï¼ˆä»¥é€—è™Ÿåˆ†éš”ï¼‰
            if sensitive_word:
                sensitive_words_list = [w.strip() for w in str(sensitive_word).split(',') if w.strip()]
                debug_info['multiple_sensitive_words'] = sensitive_words_list
                log_detail(f"è¡Œ {row_num}: æª¢æ¸¬åˆ° {len(sensitive_words_list)} å€‹æ•æ„Ÿè©: {sensitive_words_list}")
            
            # è™•ç†æ¯å€‹ç›®æ¨™æ¥­æ…‹
            for bt_code in target_business_types:
                display_name = business_types[bt_code]['display_name']
                result_col_name = f"{display_name}_æ›¿æ›çµæœ"
                
                try:
                    new_value = row[get_column_index(result_col_name)]
                except KeyError:
                    continue
                
                # ã€ä¿®å¾©ã€‘åš´æ ¼çš„ç©ºå€¼æª¢æŸ¥ï¼Œè·³éç©ºç™½å€¼
                if not new_value or not str(new_value).strip():
                    skipped_empty_replacements += 1
                    log_detail(f"è¡Œ {row_num}: è·³éç©ºçš„æ›¿æ›çµæœ ({display_name})")
                    continue
                
                new_value = str(new_value).strip()
                
                # ã€æ–°å¢ã€‘å®‰å…¨æª¢æŸ¥ï¼šè·³éèˆ‡åŸæ–‡ç›¸åŒçš„æ›¿æ›çµæœ
                if original_text and str(original_text).strip() == new_value:
                    skipped_same_as_original += 1
                    log_detail(f"è¡Œ {row_num}: è·³éèˆ‡åŸæ–‡ç›¸åŒçš„æ›¿æ›çµæœ ({display_name})")
                    continue
                
                # ã€å¢å¼·ã€‘å¤šé‡æ•æ„Ÿè©é©—è­‰ - åªè¨˜éŒ„åˆ°æ—¥èªŒ
                if original_text and sensitive_word:
                    original_str = str(original_text)
                    
                    # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰æ•æ„Ÿè©éƒ½åœ¨åŸæ–‡ä¸­
                    if 'multiple_sensitive_words' in debug_info:
                        missing_words = []
                        for word in debug_info['multiple_sensitive_words']:
                            if word not in original_str:
                                missing_words.append(word)
                        
                        if missing_words:
                            log_detail(f"è­¦å‘Š: è¡Œ {row_num} éƒ¨åˆ†æ•æ„Ÿè©ä¸åœ¨åŸæ–‡ä¸­: {missing_words}")
                    
                    # æª¢æŸ¥æ›¿æ›çµæœæ˜¯å¦é‚„åŒ…å«æ•æ„Ÿè©
                    if 'multiple_sensitive_words' in debug_info:
                        remaining_words = []
                        for word in debug_info['multiple_sensitive_words']:
                            if word in new_value:
                                remaining_words.append(word)
                        
                        if remaining_words:
                            log_detail(f"è­¦å‘Š: è¡Œ {row_num} æ›¿æ›çµæœä¸­ä»åŒ…å«æ•æ„Ÿè©: {remaining_words}")
                
                stats[f'{bt_code}_updates'] += 1
                
                # å‰µå»ºæ›´æ–°è¨˜éŒ„ï¼ˆå¢å¼·ç‰ˆï¼ŒåŒ…å«æ›´å¤šèª¿è©¦ä¿¡æ¯ï¼‰
                update_record = (str(entry_id), new_value, debug_info)
                
                if file_type == "po":
                    updates[bt_code]["po"].append(update_record)
                elif file_type == "json":
                    updates[bt_code]["json"].append(update_record)
        
        except Exception as e:
            log_detail(f"éŒ¯èª¤: ç¬¬ {row_num} è¡Œè™•ç†å¤±æ•—: {e}")
            continue
    
    # ã€å¢å¼·ã€‘çµ±è¨ˆå ±å‘Š
    total_updates = sum(stats[f'{bt_code}_updates'] for bt_code in target_business_types if f'{bt_code}_updates' in stats)
    log_detail(f"è§£æå®Œæˆ - ç¸½æ›´æ–°é …ç›®æ•¸: {total_updates}")
    log_detail(f"è·³éçµ±è¨ˆ - ç©ºæ›¿æ›çµæœ: {skipped_empty_replacements}, èˆ‡åŸæ–‡ç›¸åŒ: {skipped_same_as_original}")
    
    # ã€æ–°å¢ã€‘åœ¨æ§åˆ¶å°é¡¯ç¤ºé—œéµçµ±è¨ˆ
    if skipped_empty_replacements > 0 or skipped_same_as_original > 0:
        print(f"   ğŸ“Š å®‰å…¨è·³éï¼šç©ºæ›¿æ› {skipped_empty_replacements} å€‹ï¼Œç„¡è®ŠåŒ– {skipped_same_as_original} å€‹")
    
    return updates


def update_po_file(po_path: Path, updates_list: list, log_detail) -> dict:
    """æ›´æ–° PO æª”æ¡ˆ - å¢å¼·ç‰ˆï¼Œæ”¯æ´å¤šé‡æ•æ„Ÿè©èª¿è©¦ä¿¡æ¯"""
    result = {"success": False, "updated": 0, "errors": [], "details": []}
    
    if not updates_list:
        result["success"] = True
        return result
    
    try:
        po_file = polib.pofile(str(po_path))
        
        for update_record in updates_list:
            # å…¼å®¹èˆŠæ ¼å¼å’Œæ–°æ ¼å¼
            if len(update_record) == 2:
                msgid, new_msgstr = update_record
                debug_info = {}
            elif len(update_record) == 3:
                msgid, new_msgstr, debug_info = update_record
            else:
                continue
            
            entry = po_file.find(msgid)
            if entry:
                # ã€æ–°å¢ã€‘é¡å¤–çš„å®‰å…¨æª¢æŸ¥
                if entry.msgstr == new_msgstr:
                    log_detail(f"PO è·³é: '{msgid}' å…§å®¹ç„¡è®ŠåŒ–")
                    continue
                
                if entry.msgstr != new_msgstr:
                    old_value = entry.msgstr
                    entry.msgstr = new_msgstr
                    result["updated"] += 1
                    
                    # ã€å¢å¼·ã€‘è©³ç´°çš„æ—¥èªŒè¨˜éŒ„ï¼ŒåŒ…å«å¤šé‡æ•æ„Ÿè©ä¿¡æ¯
                    detail_msg = f"PO æ›´æ–°: '{msgid}'"
                    
                    if debug_info.get('multiple_sensitive_words'):
                        sensitive_count = len(debug_info['multiple_sensitive_words'])
                        detail_msg += f" [æ•æ„Ÿè©:{sensitive_count}å€‹]"
                    
                    if debug_info.get('match_position'):
                        detail_msg += f" [ä½ç½®:{debug_info['match_position']}]"
                    
                    if debug_info.get('category'):
                        detail_msg += f" [åˆ†é¡:{debug_info['category']}]"
                    
                    detail_msg += f" â†’ '{new_msgstr[:50]}{'...' if len(new_msgstr) > 50 else ''}'"
                    
                    result["details"].append(detail_msg)
                    log_detail(detail_msg)
            else:
                error_msg = f"æ‰¾ä¸åˆ°æ¢ç›®ï¼š{msgid}"
                result["errors"].append(error_msg)
                log_detail(f"PO éŒ¯èª¤: {error_msg}")
        
        if result["updated"] > 0:
            po_file.save(str(po_path))
            log_detail(f"PO æª”æ¡ˆå·²å„²å­˜: {po_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
        
        result["success"] = True
        
    except Exception as e:
        error_msg = f"PO æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
        result["errors"].append(error_msg)
        log_detail(f"PO éŒ¯èª¤: {error_msg}")
    
    return result


def update_json_file(json_path: Path, updates_list: list, log_detail) -> dict:
    """æ›´æ–° JSON æª”æ¡ˆ - å¢å¼·ç‰ˆï¼Œæ”¯æ´å¤šé‡æ•æ„Ÿè©èª¿è©¦ä¿¡æ¯"""
    result = {"success": False, "updated": 0, "errors": [], "details": []}
    
    if not updates_list:
        result["success"] = True
        return result
    
    try:
        data = json.loads(json_path.read_text(encoding="utf-8"))
        
        for update_record in updates_list:
            # å…¼å®¹èˆŠæ ¼å¼å’Œæ–°æ ¼å¼
            if len(update_record) == 2:
                json_path_str, new_value = update_record
                debug_info = {}
            elif len(update_record) == 3:
                json_path_str, new_value, debug_info = update_record
            else:
                continue
            
            # ã€æ–°å¢ã€‘ç²å–ç•¶å‰å€¼é€²è¡Œæ¯”è¼ƒ
            current_value = get_json_value_by_path(data, json_path_str)
            
            # ã€æ–°å¢ã€‘é¡å¤–çš„å®‰å…¨æª¢æŸ¥
            if current_value == new_value:
                log_detail(f"JSON è·³é: '{json_path_str}' å…§å®¹ç„¡è®ŠåŒ–")
                continue
            
            if set_json_value_by_path(data, json_path_str, new_value):
                result["updated"] += 1
                
                # ã€å¢å¼·ã€‘è©³ç´°çš„æ—¥èªŒè¨˜éŒ„ï¼ŒåŒ…å«å¤šé‡æ•æ„Ÿè©ä¿¡æ¯
                detail_msg = f"JSON æ›´æ–°: '{json_path_str}'"
                
                if debug_info.get('multiple_sensitive_words'):
                    sensitive_count = len(debug_info['multiple_sensitive_words'])
                    detail_msg += f" [æ•æ„Ÿè©:{sensitive_count}å€‹]"
                
                if debug_info.get('match_position'):
                    detail_msg += f" [ä½ç½®:{debug_info['match_position']}]"
                
                if debug_info.get('category'):
                    detail_msg += f" [åˆ†é¡:{debug_info['category']}]"
                
                detail_msg += f" â†’ '{new_value[:50]}{'...' if len(new_value) > 50 else ''}'"
                
                result["details"].append(detail_msg)
                log_detail(detail_msg)
            else:
                error_msg = f"ç„¡æ³•æ›´æ–°è·¯å¾‘ï¼š{json_path_str}"
                result["errors"].append(error_msg)
                log_detail(f"JSON éŒ¯èª¤: {error_msg}")
        
        if result["updated"] > 0:
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            json_path.write_text(json_content, encoding="utf-8")
            log_detail(f"JSON æª”æ¡ˆå·²å„²å­˜: {json_path.name}, æ›´æ–° {result['updated']} å€‹æ¢ç›®")
        
        result["success"] = True
        
    except json.JSONDecodeError as e:
        error_msg = f"JSON æ ¼å¼éŒ¯èª¤ï¼š{e}"
        result["errors"].append(error_msg)
        log_detail(f"JSON éŒ¯èª¤: {error_msg}")
    except Exception as e:
        error_msg = f"JSON æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{e}"
        result["errors"].append(error_msg)
        log_detail(f"JSON éŒ¯èª¤: {error_msg}")
    
    return result


def get_json_value_by_path(data: dict, path: str):
    """ã€æ–°å¢ã€‘æŒ‰è·¯å¾‘ç²å– JSON å€¼ï¼Œç”¨æ–¼æ¯”è¼ƒ"""
    try:
        path_parts = parse_json_path(path)
        current = data
        
        for part_type, part_value in path_parts:
            if part_type == 'key':
                if part_value not in current:
                    return None
                current = current[part_value]
            elif part_type == 'index':
                if not isinstance(current, list) or len(current) <= part_value:
                    return None
                current = current[part_value]
        
        return current
        
    except Exception:
        return None


def parse_json_path(path: str) -> list:
    """è§£æ JSON è·¯å¾‘ - ä¿æŒåŸæœ‰é‚è¼¯"""
    parts = []
    current = ""
    in_bracket = False
    
    for char in path:
        if char == '[':
            if current:
                parts.append(('key', current))
                current = ""
            in_bracket = True
        elif char == ']':
            if in_bracket and current:
                try:
                    parts.append(('index', int(current)))
                except ValueError:
                    raise ValueError(f"ç„¡æ•ˆçš„é™£åˆ—ç´¢å¼•ï¼š{current}")
                current = ""
            in_bracket = False
        elif char == '.' and not in_bracket:
            if current:
                parts.append(('key', current))
                current = ""
        else:
            current += char
    
    if current:
        parts.append(('key', current))
    
    return parts


def set_json_value_by_path(data: dict, path: str, new_value: str) -> bool:
    """æŒ‰è·¯å¾‘è¨­ç½® JSON å€¼ - ä¿æŒåŸæœ‰é‚è¼¯"""
    try:
        path_parts = parse_json_path(path)
        current = data
        
        for i, (part_type, part_value) in enumerate(path_parts):
            is_last = (i == len(path_parts) - 1)
            
            if part_type == 'key':
                if is_last:
                    current[part_value] = new_value
                else:
                    if part_value not in current:
                        next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                        current[part_value] = [] if next_part_type == 'index' else {}
                    current = current[part_value]
            
            elif part_type == 'index':
                if is_last:
                    while len(current) <= part_value:
                        current.append(None)
                    current[part_value] = new_value
                else:
                    while len(current) <= part_value:
                        current.append(None)
                    if current[part_value] is None:
                        next_part_type = path_parts[i + 1][0] if i + 1 < len(path_parts) else 'key'
                        current[part_value] = [] if next_part_type == 'index' else {}
                    current = current[part_value]
        
        return True
        
    except Exception as e:
        return False


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸ - å¢å¼·ç‰ˆ"""
    print("ğŸš€ é–‹å§‹å¥—ç”¨å¤šèªè¨€ä¿®æ­£çµæœ (v2.5 - å¤šé‡æ•æ„Ÿè©å¢å¼·ç‰ˆ)")
    
    # è¼‰å…¥é…ç½®
    config = get_config()
    config.print_config_summary()
    
    # è™•ç†å‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser(description='å¥—ç”¨å¤šèªè¨€æ•æ„Ÿè©ä¿®æ­£çµæœ')
    parser.add_argument('--language', '-l', 
                       help='æŒ‡å®šè¦è™•ç†çš„èªè¨€ï¼ˆè‹¥æœªæŒ‡å®šå°‡è‡ªå‹•æª¢æ¸¬ï¼‰')
    parser.add_argument('--business-types', '-b',
                       nargs='+',
                       choices=list(config.get_business_types().keys()) + ['all'],
                       help='æŒ‡å®šè¦è™•ç†çš„æ¥­æ…‹ (å¯å¤šé¸ï¼Œæˆ–ä½¿ç”¨ all)')
    parser.add_argument('--list-files', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ tobemodified æª”æ¡ˆ')
    
    args = parser.parse_args()
    
    # æª¢æ¸¬å¯ç”¨çš„ tobemodified æª”æ¡ˆ
    available_files = detect_tobemodified_files(config)
    
    if args.list_files:
        print(f"\nğŸ“„ å¯ç”¨çš„ tobemodified æª”æ¡ˆï¼š")
        for lang, filepath in available_files.items():
            print(f"   {lang}: {filepath}")
        return
    
    if not available_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• tobemodified æª”æ¡ˆ")
        print("è«‹å…ˆåŸ·è¡Œ script_01_generate_xlsx.py ç”Ÿæˆæª”æ¡ˆ")
        sys.exit(1)
    
    # é¸æ“‡è¦è™•ç†çš„èªè¨€
    if args.language:
        if args.language not in available_files:
            print(f"âŒ èªè¨€ '{args.language}' çš„ tobemodified æª”æ¡ˆä¸å­˜åœ¨")
            print(f"å¯ç”¨èªè¨€ï¼š{list(available_files.keys())}")
            sys.exit(1)
        target_languages = [args.language]
        print(f"\nğŸŒ å°‡è™•ç†æŒ‡å®šèªè¨€ï¼š{args.language}")
    else:
        target_languages = list(available_files.keys())
        print(f"\nğŸŒ å°‡è™•ç†æ‰€æœ‰èªè¨€ï¼š{', '.join(target_languages)}")
    
    # é¸æ“‡æ¥­æ…‹
    target_business_types = choose_business_types(config, args)
    
    # è™•ç†æ¯å€‹èªè¨€
    success_count = 0
    total_count = len(target_languages)
    
    for language in target_languages:
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ è™•ç†èªè¨€ï¼š{language}")
        
        if process_language(config, language, target_business_types):
            success_count += 1
        else:
            print(f"âŒ {language} è™•ç†å¤±æ•—")
    
    # æœ€çµ‚å ±å‘Š
    print(f"\nğŸ‰ è™•ç†å®Œç•¢ï¼")
    print(f"ğŸ“Š æˆåŠŸè™•ç†ï¼š{success_count}/{total_count} å€‹èªè¨€")
    
    if success_count < total_count:
        sys.exit(1)


def detect_tobemodified_files(config) -> dict:
    """æª¢æ¸¬å¯ç”¨çš„ tobemodified æª”æ¡ˆ - ä¿®æ­£ç‰ˆï¼Œéæ¿¾ç³»çµ±è‡¨æ™‚æª”æ¡ˆ"""
    available_files = {}
    
    # æª¢æ¸¬è¼¸å‡ºç›®éŒ„ä¸­çš„æª”æ¡ˆ
    try:
        if hasattr(config, 'get_output_dir'):
            output_dir = config.get_output_dir()
        elif hasattr(config, 'output_dir'):
            output_dir = config.output_dir
        elif hasattr(config, 'get_config'):
            config_data = config.get_config()
            output_dir = Path(config_data.get('output_dir', 'i18n_output'))
        else:
            output_dir = Path('i18n_output')
    except Exception:
        output_dir = Path('i18n_output')
    
    # ã€ä¿®æ­£ã€‘ä½¿ç”¨é…ç½®è¼‰å…¥å™¨çš„èªè¨€æª¢æ¸¬ï¼Œè€Œä¸æ˜¯ç›´æ¥æƒææª”æ¡ˆ
    # é€™æ¨£å¯ä»¥ç¢ºä¿ä½¿ç”¨ç›¸åŒçš„éæ¿¾é‚è¼¯
    try:
        available_languages = config.detect_available_languages()
    except Exception as e:
        print(f"âš ï¸  èªè¨€æª¢æ¸¬å¤±æ•—ï¼š{e}")
        available_languages = []
    
    # æª¢æ¸¬æ¨™æº–å‘½åçš„æª”æ¡ˆ - åªæª¢æŸ¥æœ‰æ•ˆèªè¨€
    for language in available_languages:
        tobemodified_path = output_dir / f"{language}_tobemodified.xlsx"
        if tobemodified_path.exists():
            available_files[language] = tobemodified_path
    
    # é¡å¤–æª¢æ¸¬ç•¶å‰ç›®éŒ„ä¸­çš„é€šé…ç¬¦æª”æ¡ˆï¼ˆä½†è¦éæ¿¾ç³»çµ±æª”æ¡ˆï¼‰
    def should_ignore_language_code(language: str) -> bool:
        """æª¢æŸ¥èªè¨€ä»£ç¢¼æ˜¯å¦æ‡‰è©²è¢«å¿½ç•¥"""
        import fnmatch
        
        ignore_patterns = [
            '~$*',           # Excel/Word è‡¨æ™‚æª”æ¡ˆå‰ç¶´
            '.*',            # éš±è—æª”æ¡ˆï¼ˆä»¥é»é–‹é ­ï¼‰
            '__*',           # Python ç‰¹æ®Šæª”æ¡ˆ
            'Thumbs',        # Windows ç¸®åœ–å¿«å–
            '.DS_Store',     # macOS ç³»çµ±æª”æ¡ˆ
        ]
        
        for pattern in ignore_patterns:
            if fnmatch.fnmatch(language, pattern):
                return True
        return False
    
    # åœ¨ç•¶å‰ç›®éŒ„å’Œè¼¸å‡ºç›®éŒ„ä¸­æŸ¥æ‰¾é¡å¤–çš„ tobemodified æª”æ¡ˆ
    for search_dir in [output_dir]:
        if search_dir.exists():
            for file_path in search_dir.glob("*_tobemodified.xlsx"):
                # æå–èªè¨€ä»£ç¢¼
                filename = file_path.stem
                if filename.endswith('_tobemodified'):
                    language = filename[:-len('_tobemodified')]
                    
                    # ã€æ–°å¢ã€‘éæ¿¾ç³»çµ±è‡¨æ™‚æª”æ¡ˆ
                    if should_ignore_language_code(language):
                        print(f"âš ï¸  è·³éç³»çµ±è‡¨æ™‚æª”æ¡ˆï¼š{file_path.name}")
                        continue
                    
                    # å¦‚æœèªè¨€ä¸åœ¨å·²æª¢æ¸¬åˆ—è¡¨ä¸­ï¼Œä¹Ÿè¦é€²è¡ŒåŸºæœ¬é©—è­‰
                    if language not in available_languages:
                        # åŸºæœ¬èªè¨€ä»£ç¢¼æ ¼å¼é©—è­‰
                        if not _is_valid_language_code_simple(language):
                            print(f"âš ï¸  è·³éç„¡æ•ˆèªè¨€ä»£ç¢¼ï¼š{language}")
                            continue
                    
                    if language not in available_files:
                        available_files[language] = file_path

    return available_files


def _is_valid_language_code_simple(language: str) -> bool:
    """
    ç°¡å–®çš„èªè¨€ä»£ç¢¼æ ¼å¼é©—è­‰ï¼ˆç”¨æ–¼ tobemodified æª”æ¡ˆæª¢æ¸¬ï¼‰
    
    Args:
        language: èªè¨€ä»£ç¢¼å­—ç¬¦ä¸²
        
    Returns:
        bool: æ˜¯å¦ç‚ºæœ‰æ•ˆçš„èªè¨€ä»£ç¢¼
    """
    import re
    
    # å¸¸è¦‹çš„èªè¨€ä»£ç¢¼æ ¼å¼
    valid_patterns = [
        r'^[a-zA-Z]{2}$',                    # en, zh
        r'^[a-zA-Z]{2}[-_][a-zA-Z]{2}$',    # en-US, zh-TW, zh_CN
        r'^[a-zA-Z]{2}[-_][a-zA-Z]{2,4}$',  # en-US, zh-Hans
        r'^[a-zA-Z]{3}$',                    # 3å­—æ¯èªè¨€ä»£ç¢¼
    ]
    
    for pattern in valid_patterns:
        if re.match(pattern, language, re.IGNORECASE):
            return True
    
    # å¦‚æœä¸ç¬¦åˆæ¨™æº–æ ¼å¼ï¼Œä½†ä¸æ˜¯ç³»çµ±æª”æ¡ˆï¼Œä¹Ÿå…è¨±ï¼ˆå‘å¾Œç›¸å®¹ï¼‰
    if not language.startswith(('~$', '.', '__')):
        return True
    
    return False


def choose_business_types(config, args) -> list:
    """é¸æ“‡è¦è™•ç†çš„æ¥­æ…‹ - ä¿æŒåŸæœ‰é‚è¼¯"""
    if args.business_types:
        if 'all' in args.business_types:
            return list(config.get_business_types().keys())
        return args.business_types
    
    # äº’å‹•å¼é¸æ“‡
    business_types = config.get_business_types()
    choices = list(business_types.items())
    
    print("\nè«‹é¸æ“‡è¦å¥—ç”¨ä¿®æ­£çš„æ¥­æ…‹ï¼š")
    for i, (bt_code, bt_config) in enumerate(choices, 1):
        print(f"  {i}) {bt_config['display_name']}")
    print(f"  {len(choices) + 1}) å…¨éƒ¨")
    
    while True:
        try:
            opt = input(f"\nè¼¸å…¥é¸é … (1-{len(choices) + 1})ï¼š").strip()
            choice_idx = int(opt) - 1
            
            if choice_idx == len(choices):  # å…¨éƒ¨
                return list(business_types.keys())
            elif 0 <= choice_idx < len(choices):
                bt_code = choices[choice_idx][0]
                return [bt_code]
            else:
                print(f"âš ï¸  è«‹è¼¸å…¥ 1-{len(choices) + 1} ä¹‹é–“çš„æ•¸å­—")
        except (ValueError, KeyboardInterrupt):
            print("\nâŒ ä½¿ç”¨è€…å–æ¶ˆæ“ä½œ")
            sys.exit(0)


def process_language(config, language: str, target_business_types: list) -> bool:
    """è™•ç†å–®å€‹èªè¨€çš„ä¿®æ­£å¥—ç”¨ - å¢å¼·ç‰ˆ"""
    
    # ç²å–æª”æ¡ˆè·¯å¾‘
    available_files = detect_tobemodified_files(config)
    tobemodified_path = available_files.get(language)
    
    if not tobemodified_path:
        print(f"âŒ æ‰¾ä¸åˆ° {language} çš„ tobemodified æª”æ¡ˆ")
        return False
    
    language_files = config.get_language_files(language)
    
    print(f"   ä¾†æº Excelï¼š{tobemodified_path.name}")
    
    # ç²å–è¼¸å‡ºè·¯å¾‘
    try:
        output_paths = config.get_output_paths(language)
        output_dir = output_paths['output_dir']
        timestamp = output_paths['timestamp']
    except Exception:
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        try:
            if hasattr(config, 'get_output_dir'):
                base_output_dir = config.get_output_dir()
            else:
                base_output_dir = Path('i18n_output')
        except Exception:
            base_output_dir = Path('i18n_output')
        
        output_dir = base_output_dir / f"{language}_{timestamp}"
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¨­ç½®æ—¥èªŒ - åªè¨˜éŒ„åˆ°æª”æ¡ˆï¼Œä¸æ‰“å°åˆ°æ§åˆ¶å°
    log_file = output_dir / f"apply_fixes_{timestamp}.log"
    
    def log_detail(message: str):
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"{datetime.datetime.now().strftime('%H:%M:%S')} - {message}\n")
    
    log_detail(f"é–‹å§‹è™•ç†èªè¨€: {language}")
    log_detail(f"ç›®æ¨™æ¥­æ…‹: {', '.join(target_business_types)}")
    log_detail(f"ä¾†æºæª”æ¡ˆ: {tobemodified_path}")
    
    # è®€å–ä¸¦é©—è­‰ Excel
    wb, ws, header = read_and_validate_xlsx(tobemodified_path, config, target_business_types, log_detail)
    if not wb:
        return False
    
    # è§£æä¿®æ­£è³‡æ–™
    updates = parse_excel_updates(ws, header, config, target_business_types, log_detail)
    
    # è™•ç†æ¯å€‹æ¥­æ…‹
    business_types = config.get_business_types()
    results = {}
    
    for bt_code in target_business_types:
        bt_config = business_types[bt_code]
        display_name = bt_config['display_name']
        
        print(f"   ğŸ“ è™•ç† {display_name}...")
        log_detail(f"é–‹å§‹è™•ç†æ¥­æ…‹: {display_name}")
        
        # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        output_files = generate_output_files(config, language, bt_code, language_files, output_dir)
        if not output_files:
            log_detail(f"éŒ¯èª¤: {display_name} è¼¸å‡ºæª”æ¡ˆç”Ÿæˆå¤±æ•—")
            continue
        
        # å¥—ç”¨ä¿®æ­£
        result = apply_fixes_to_business_type(
            config, bt_code, updates[bt_code], output_files, log_detail
        )
        
        results[bt_code] = result
        
        if result['success']:
            total_updates = result['po_updated'] + result['json_updated']
            print(f"     âœ… å®Œæˆ - PO: {result['po_updated']} å€‹, JSON: {result['json_updated']} å€‹")
            log_detail(f"{display_name} è™•ç†å®Œæˆ: ç¸½æ›´æ–° {total_updates} å€‹")
        else:
            print(f"     âŒ å¤±æ•—")
            log_detail(f"{display_name} è™•ç†å¤±æ•—")
            
            # è¨˜éŒ„éŒ¯èª¤è©³æƒ…åˆ°æ—¥èªŒ
            for error in result.get('errors', []):
                log_detail(f"  éŒ¯èª¤: {error}")
    
    # ç”Ÿæˆæœ€çµ‚å ±å‘Š - ç²¾ç°¡ç‰ˆ
    success_count = sum(1 for r in results.values() if r['success'])
    total_count = len(results)
    total_updates = sum(r['po_updated'] + r['json_updated'] for r in results.values())
    
    print(f"   ğŸ“Š è™•ç†çµæœï¼šæˆåŠŸ {success_count}/{total_count}ï¼Œç¸½æ›´æ–° {total_updates} å€‹")
    print(f"   ğŸ“ è¼¸å‡ºç›®éŒ„ï¼š{output_dir}")
    
    log_detail(f"èªè¨€ {language} è™•ç†å®Œæˆ: æˆåŠŸ {success_count}/{total_count} å€‹æ¥­æ…‹")
    
    # ç”Ÿæˆè™•ç†æ‘˜è¦
    generate_summary_report(results, output_dir, timestamp, log_detail)
    
    return success_count > 0


def generate_output_files(config, language: str, bt_code: str, language_files: dict, output_dir: Path) -> dict:
    """ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆ - ä¿æŒåŸæœ‰é‚è¼¯"""
    business_types = config.get_business_types()
    bt_config = business_types[bt_code]
    suffix = bt_config['suffix']
    
    output_files = {}
    
    # è™•ç† PO æª”æ¡ˆ
    if 'po_file' in language_files:
        original_po = language_files['po_file']
        output_po = output_dir / f"{original_po.stem}{suffix}{original_po.suffix}"
        
        # è¤‡è£½åŸå§‹æª”æ¡ˆ
        shutil.copy2(original_po, output_po)
        output_files['po_file'] = output_po
    
    # è™•ç† JSON æª”æ¡ˆ
    if 'json_file' in language_files:
        original_json = language_files['json_file']
        output_json = output_dir / f"{original_json.stem}{suffix}{original_json.suffix}"
        
        # è¤‡è£½åŸå§‹æª”æ¡ˆ
        shutil.copy2(original_json, output_json)
        output_files['json_file'] = output_json
    
    return output_files


def apply_fixes_to_business_type(config, bt_code: str, updates: dict, output_files: dict, log_detail) -> dict:
    """å¥—ç”¨ä¿®æ­£åˆ°æŒ‡å®šæ¥­æ…‹ - ä¿æŒåŸæœ‰é‚è¼¯"""
    result = {
        'success': True,
        'po_updated': 0,
        'json_updated': 0,
        'errors': [],
        'details': []
    }
    
    try:
        # è™•ç† PO æª”æ¡ˆ
        if 'po_file' in output_files and updates['po']:
            po_result = update_po_file(output_files['po_file'], updates['po'], log_detail)
            result['po_updated'] = po_result['updated']
            result['errors'].extend(po_result['errors'])
            result['details'].extend(po_result.get('details', []))
            if not po_result['success']:
                result['success'] = False
        
        # è™•ç† JSON æª”æ¡ˆ
        if 'json_file' in output_files and updates['json']:
            json_result = update_json_file(output_files['json_file'], updates['json'], log_detail)
            result['json_updated'] = json_result['updated']
            result['errors'].extend(json_result['errors'])
            result['details'].extend(json_result.get('details', []))
            if not json_result['success']:
                result['success'] = False
        
    except Exception as e:
        error_msg = f"å¥—ç”¨ä¿®æ­£å¤±æ•—ï¼š{e}"
        result['errors'].append(error_msg)
        result['success'] = False
        log_detail(f"éŒ¯èª¤: {error_msg}")
    
    return result


def generate_summary_report(results: dict, output_dir: Path, timestamp: str, log_detail):
    """ç”Ÿæˆè™•ç†æ‘˜è¦å ±å‘Š - å¢å¼·ç‰ˆï¼ŒåŒ…å«å¤šé‡æ•æ„Ÿè©è™•ç†ä¿¡æ¯"""
    summary_file = output_dir / f"processing_summary_{timestamp}.txt"
    
    try:
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"æ•æ„Ÿè©ä¿®æ­£è™•ç†æ‘˜è¦å ±å‘Š (å¤šé‡æ•æ„Ÿè©å¢å¼·ç‰ˆ)\n")
            f.write(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"{'='*50}\n\n")
            
            total_po_updates = 0
            total_json_updates = 0
            successful_business_types = []
            failed_business_types = []
            
            # çµ±è¨ˆå¤šé‡æ•æ„Ÿè©ç›¸é—œä¿¡æ¯
            multiple_sensitive_words_updates = 0
            position_info_count = 0
            category_info_count = 0
            
            for bt_code, result in results.items():
                f.write(f"æ¥­æ…‹ï¼š{bt_code}\n")
                f.write(f"ç‹€æ…‹ï¼š{'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}\n")
                f.write(f"PO æ›´æ–°æ•¸é‡ï¼š{result['po_updated']}\n")
                f.write(f"JSON æ›´æ–°æ•¸é‡ï¼š{result['json_updated']}\n")
                
                if result['success']:
                    successful_business_types.append(bt_code)
                    total_po_updates += result['po_updated']
                    total_json_updates += result['json_updated']
                else:
                    failed_business_types.append(bt_code)
                
                if result.get('errors'):
                    f.write(f"éŒ¯èª¤ï¼š\n")
                    for error in result['errors']:
                        f.write(f"  - {error}\n")
                
                if result.get('details'):
                    f.write(f"è©³ç´°æ›´æ–°è¨˜éŒ„ï¼š\n")
                    for detail in result['details'][:20]:  # é™åˆ¶é¡¯ç¤ºå‰20æ¢
                        f.write(f"  - {detail}\n")
                        
                        # çµ±è¨ˆå¤šé‡æ•æ„Ÿè©ç›¸é—œä¿¡æ¯
                        if '[æ•æ„Ÿè©:' in detail and 'å€‹]' in detail:
                            multiple_sensitive_words_updates += 1
                        if '[ä½ç½®:' in detail:
                            position_info_count += 1
                        if '[åˆ†é¡:' in detail:
                            category_info_count += 1
                            
                    if len(result['details']) > 20:
                        f.write(f"  ... é‚„æœ‰ {len(result['details']) - 20} æ¢è¨˜éŒ„\n")
                
                f.write(f"\n{'-'*30}\n\n")
            
            # ç¸½è¨ˆçµ±è¨ˆ
            f.write(f"è™•ç†ç¸½çµï¼š\n")
            f.write(f"æˆåŠŸæ¥­æ…‹ï¼š{len(successful_business_types)}\n")
            f.write(f"å¤±æ•—æ¥­æ…‹ï¼š{len(failed_business_types)}\n")
            f.write(f"ç¸½ PO æ›´æ–°ï¼š{total_po_updates}\n")
            f.write(f"ç¸½ JSON æ›´æ–°ï¼š{total_json_updates}\n")
            f.write(f"ç¸½æ›´æ–°é …ç›®ï¼š{total_po_updates + total_json_updates}\n")
            
            # æ–°å¢ï¼šå¤šé‡æ•æ„Ÿè©è™•ç†çµ±è¨ˆ
            f.write(f"\nå¤šé‡æ•æ„Ÿè©è™•ç†çµ±è¨ˆï¼š\n")
            f.write(f"å¤šé‡æ•æ„Ÿè©æ›´æ–°ï¼š{multiple_sensitive_words_updates}\n")
            f.write(f"åŒ…å«ä½ç½®ä¿¡æ¯çš„æ›´æ–°ï¼š{position_info_count}\n")
            f.write(f"åŒ…å«åˆ†é¡ä¿¡æ¯çš„æ›´æ–°ï¼š{category_info_count}\n")
            
            total_updates = total_po_updates + total_json_updates
            if total_updates > 0:
                f.write(f"å¤šé‡æ•æ„Ÿè©æª¢æ¸¬è¦†è“‹ç‡ï¼š{multiple_sensitive_words_updates}/{total_updates} ({multiple_sensitive_words_updates/total_updates*100:.1f}%)\n")
            
            # ã€æ–°å¢ã€‘å®‰å…¨çµ±è¨ˆéƒ¨åˆ†
            f.write(f"\nå®‰å…¨è™•ç†çµ±è¨ˆï¼š\n")
            f.write(f"èªªæ˜ï¼šæœ¬ç‰ˆæœ¬è‡ªå‹•è·³éç©ºçš„æ›¿æ›çµæœå’Œèˆ‡åŸæ–‡ç›¸åŒçš„æ›¿æ›çµæœ\n")
            f.write(f"é€™æ¨£å¯ä»¥é¿å…ç„¡æ„ç¾©çš„è™•ç†ï¼Œé™ä½æ“ä½œé¢¨éšª\n")
            
            if successful_business_types:
                f.write(f"\næˆåŠŸçš„æ¥­æ…‹ï¼š{', '.join(successful_business_types)}\n")
            
            if failed_business_types:
                f.write(f"å¤±æ•—çš„æ¥­æ…‹ï¼š{', '.join(failed_business_types)}\n")
            
            # ã€æ–°å¢ã€‘å¤šé‡æ•æ„Ÿè©åŠŸèƒ½èªªæ˜
            f.write(f"\nå¤šé‡æ•æ„Ÿè©åŠŸèƒ½èªªæ˜ï¼š\n")
            f.write(f"- æ”¯æ´åŒä¸€æ–‡æœ¬ä¸­åŒ…å«å¤šå€‹æ•æ„Ÿè©çš„æƒ…æ³\n")
            f.write(f"- è‡ªå‹•è™•ç†æ•æ„Ÿè©çš„åŒ…å«é—œä¿‚ï¼ˆå¦‚ã€Œåœ¨æ ¡ç”Ÿã€vsã€Œåœ¨æ ¡ã€ï¼‰\n")
            f.write(f"- æä¾›è©³ç´°çš„åŒ¹é…ä½ç½®å’Œåˆ†é¡ä¿¡æ¯\n")
            f.write(f"- å®‰å…¨è·³éç„¡æ•ˆæˆ–é¢¨éšªæ›¿æ›\n")
            
            # ã€æ–°å¢ã€‘ä½¿ç”¨å»ºè­°
            f.write(f"\nä½¿ç”¨å»ºè­°ï¼š\n")
            f.write(f"- æª¢æŸ¥é»ƒè‰²åº•è‰²çš„é …ç›®ï¼šåªæœ‰é€™äº›æœƒè¢«è™•ç†\n")
            f.write(f"- ç©ºç™½æ›¿æ›çµæœæœƒè‡ªå‹•è·³éï¼Œæ¸›å°‘é¢¨éšª\n")
            f.write(f"- å¤šé‡æ•æ„Ÿè©æœƒæŒ‰å„ªå…ˆé †åºè™•ç†ï¼Œé¿å…è¡çª\n")
            f.write(f"- å»ºè­°å®šæœŸæª¢æŸ¥æ—¥èªŒæª”æ¡ˆä»¥äº†è§£è©³ç´°è™•ç†éç¨‹\n")
        
        log_detail(f"æ‘˜è¦å ±å‘Šå·²ç”Ÿæˆï¼š{summary_file}")
        
    except Exception as e:
        log_detail(f"ç”Ÿæˆæ‘˜è¦å ±å‘Šå¤±æ•—ï¼š{e}")


if __name__ == "__main__":
    main()